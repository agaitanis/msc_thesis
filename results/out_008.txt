I0915 16:13:16.424403 139818557888320 train.py:65] Reading the config file.
I0915 16:13:16.429808 139818557888320 train.py:69] Starting the experiment.
2022-09-15 16:13:16.430847: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-15 16:13:17.717454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0915 16:13:17.722028 139818557888320 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0915 16:13:17.875855 139818557888320 deeplab.py:57] Synchronized Batchnorm is used.
I0915 16:13:17.876878 139818557888320 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0915 16:13:17.977396 139818557888320 deeplab.py:96] Setting pooling size to (33, 33)
I0915 16:13:17.977517 139818557888320 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 16:13:20.903316 139818557888320 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0915 16:13:20.930115 139818557888320 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0915 16:13:20.941928 139818557888320 controller.py:399] initialized model.
I0915 16:13:21.563485 139818557888320 api.py:447] Eval with scales ListWrapper([1.0])
I0915 16:13:22.426726 139818557888320 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 16:13:22.444566 139818557888320 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0915 16:13:25.369531 139818557888320 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 16:13:25.757365 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-0.
I0915 16:13:25.757952 139818557888320 controller.py:241] train | step:      0 | training until step 4000...
2022-09-15 16:13:48.282142: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0915 16:15:23.155542 139818557888320 controller.py:466] train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.1019423,
     'losses/train_total_loss': 1.1019423}
I0915 16:16:55.207840 139818557888320 controller.py:466] train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 0.9602015,
     'losses/train_total_loss': 0.9602015}
I0915 16:18:26.478680 139818557888320 controller.py:466] train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.9252136,
     'losses/train_total_loss': 0.9252136}
I0915 16:19:57.514485 139818557888320 controller.py:466] train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.8665168,
     'losses/train_total_loss': 0.8665168}
I0915 16:21:29.362014 139818557888320 controller.py:466] train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.8503559,
     'losses/train_total_loss': 0.8503559}
I0915 16:23:00.928386 139818557888320 controller.py:466] train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.8165038,
     'losses/train_total_loss': 0.8165038}
I0915 16:24:32.083283 139818557888320 controller.py:466] train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.82584757,
     'losses/train_total_loss': 0.82584757}
I0915 16:26:03.638990 139818557888320 controller.py:466] train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.78293395,
     'losses/train_total_loss': 0.78293395}
I0915 16:27:35.712233 139818557888320 controller.py:466] train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.80410904,
     'losses/train_total_loss': 0.80410904}
I0915 16:29:07.824068 139818557888320 controller.py:466] train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.78613716,
     'losses/train_total_loss': 0.78613716}
I0915 16:29:08.724869 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-1000.
I0915 16:30:40.396690 139818557888320 controller.py:466] train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.766827,
     'losses/train_total_loss': 0.766827}
I0915 16:32:11.551962 139818557888320 controller.py:466] train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.76378024,
     'losses/train_total_loss': 0.76378024}
I0915 16:33:42.884942 139818557888320 controller.py:466] train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.7434427,
     'losses/train_total_loss': 0.7434427}
I0915 16:35:14.509808 139818557888320 controller.py:466] train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.78564745,
     'losses/train_total_loss': 0.78564745}
I0915 16:36:45.880955 139818557888320 controller.py:466] train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.75548846,
     'losses/train_total_loss': 0.75548846}
I0915 16:38:17.339806 139818557888320 controller.py:466] train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.7227299,
     'losses/train_total_loss': 0.7227299}
I0915 16:39:48.783440 139818557888320 controller.py:466] train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.7411185,
     'losses/train_total_loss': 0.7411185}
I0915 16:41:20.121136 139818557888320 controller.py:466] train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.7240772,
     'losses/train_total_loss': 0.7240772}
I0915 16:42:51.490674 139818557888320 controller.py:466] train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.7191837,
     'losses/train_total_loss': 0.7191837}
I0915 16:44:23.177687 139818557888320 controller.py:466] train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.73913527,
     'losses/train_total_loss': 0.73913527}
I0915 16:44:23.993844 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-2000.
I0915 16:45:55.167800 139818557888320 controller.py:466] train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.731729,
     'losses/train_total_loss': 0.731729}
I0915 16:47:25.816097 139818557888320 controller.py:466] train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.74106836,
     'losses/train_total_loss': 0.74106836}
I0915 16:48:57.261557 139818557888320 controller.py:466] train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.71367335,
     'losses/train_total_loss': 0.71367335}
I0915 16:50:29.099066 139818557888320 controller.py:466] train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.7206767,
     'losses/train_total_loss': 0.7206767}
I0915 16:52:00.270587 139818557888320 controller.py:466] train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7227067,
     'losses/train_total_loss': 0.7227067}
I0915 16:53:31.995806 139818557888320 controller.py:466] train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.69213915,
     'losses/train_total_loss': 0.69213915}
I0915 16:55:03.211814 139818557888320 controller.py:466] train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.6696654,
     'losses/train_total_loss': 0.6696654}
I0915 16:56:34.596597 139818557888320 controller.py:466] train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.69461256,
     'losses/train_total_loss': 0.69461256}
I0915 16:58:06.149326 139818557888320 controller.py:466] train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.6851666,
     'losses/train_total_loss': 0.6851666}
I0915 16:59:37.602667 139818557888320 controller.py:466] train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7092318,
     'losses/train_total_loss': 0.7092318}
I0915 16:59:38.473484 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-3000.
I0915 17:01:10.351471 139818557888320 controller.py:466] train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.70790994,
     'losses/train_total_loss': 0.70790994}
I0915 17:02:42.642952 139818557888320 controller.py:466] train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.66324776,
     'losses/train_total_loss': 0.66324776}
I0915 17:04:14.162003 139818557888320 controller.py:466] train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.6650609,
     'losses/train_total_loss': 0.6650609}
I0915 17:05:46.709526 139818557888320 controller.py:466] train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.6658058,
     'losses/train_total_loss': 0.6658058}
I0915 17:07:18.396712 139818557888320 controller.py:466] train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.6707,
     'losses/train_total_loss': 0.6707}
I0915 17:08:49.541877 139818557888320 controller.py:466] train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.64897835,
     'losses/train_total_loss': 0.64897835}
I0915 17:10:21.446564 139818557888320 controller.py:466] train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.65084094,
     'losses/train_total_loss': 0.65084094}
I0915 17:11:53.507711 139818557888320 controller.py:466] train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.65699226,
     'losses/train_total_loss': 0.65699226}
I0915 17:13:25.612564 139818557888320 controller.py:466] train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.6725157,
     'losses/train_total_loss': 0.6725157}
I0915 17:14:57.182120 139818557888320 controller.py:466] train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.6818009,
     'losses/train_total_loss': 0.6818009}
I0915 17:14:58.024438 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-4000.
I0915 17:14:58.025434 139818557888320 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0915 17:15:00.659642 139818557888320 api.py:447] Eval with scales ListWrapper([1.0])
I0915 17:15:00.688031 139818557888320 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 17:15:00.713116 139818557888320 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0915 17:15:01.352145 139818557888320 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 17:15:37.132298 139818557888320 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 17:15:37.157130 139818557888320 controller.py:295]  eval | step:   4000 | eval time:   39.1 sec | output: 
    {'evaluation/iou/IoU': 0.5396532,
     'losses/eval_semantic_loss': 0.94018996,
     'losses/eval_total_loss': 0.94018996}
I0915 17:15:37.163209 139818557888320 controller.py:241] train | step:   4000 | training until step 8000...
I0915 17:17:08.526901 139818557888320 controller.py:466] train | step:   4100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.6629377,
     'losses/train_total_loss': 0.6629377}
I0915 17:18:40.432857 139818557888320 controller.py:466] train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.678876,
     'losses/train_total_loss': 0.678876}
I0915 17:20:12.405455 139818557888320 controller.py:466] train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.6372914,
     'losses/train_total_loss': 0.6372914}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_008/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.1019423,
     'losses/train_total_loss': 1.1019423}
train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 0.9602015,
     'losses/train_total_loss': 0.9602015}
train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.9252136,
     'losses/train_total_loss': 0.9252136}
train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.8665168,
     'losses/train_total_loss': 0.8665168}
train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.8503559,
     'losses/train_total_loss': 0.8503559}
train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.8165038,
     'losses/train_total_loss': 0.8165038}
train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.82584757,
     'losses/train_total_loss': 0.82584757}
train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.78293395,
     'losses/train_total_loss': 0.78293395}
train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.80410904,
     'losses/train_total_loss': 0.80410904}
train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.78613716,
     'losses/train_total_loss': 0.78613716}
saved checkpoint to results/exp_008/ckpt-1000.
train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.766827,
     'losses/train_total_loss': 0.766827}
train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.76378024,
     'losses/train_total_loss': 0.76378024}
train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.7434427,
     'losses/train_total_loss': 0.7434427}
train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.78564745,
     'losses/train_total_loss': 0.78564745}
train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.75548846,
     'losses/train_total_loss': 0.75548846}
train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.7227299,
     'losses/train_total_loss': 0.7227299}
train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.7411185,
     'losses/train_total_loss': 0.7411185}
train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.7240772,
     'losses/train_total_loss': 0.7240772}
train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.7191837,
     'losses/train_total_loss': 0.7191837}
train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.73913527,
     'losses/train_total_loss': 0.73913527}
saved checkpoint to results/exp_008/ckpt-2000.
train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.731729,
     'losses/train_total_loss': 0.731729}
train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.74106836,
     'losses/train_total_loss': 0.74106836}
train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.71367335,
     'losses/train_total_loss': 0.71367335}
train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.7206767,
     'losses/train_total_loss': 0.7206767}
train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7227067,
     'losses/train_total_loss': 0.7227067}
train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.69213915,
     'losses/train_total_loss': 0.69213915}
train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.6696654,
     'losses/train_total_loss': 0.6696654}
train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.69461256,
     'losses/train_total_loss': 0.69461256}
train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.6851666,
     'losses/train_total_loss': 0.6851666}
train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7092318,
     'losses/train_total_loss': 0.7092318}
saved checkpoint to results/exp_008/ckpt-3000.
train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.70790994,
     'losses/train_total_loss': 0.70790994}
train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.66324776,
     'losses/train_total_loss': 0.66324776}
train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.6650609,
     'losses/train_total_loss': 0.6650609}
train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.6658058,
     'losses/train_total_loss': 0.6658058}
train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.6707,
     'losses/train_total_loss': 0.6707}
train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.64897835,
     'losses/train_total_loss': 0.64897835}
train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.65084094,
     'losses/train_total_loss': 0.65084094}
train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.65699226,
     'losses/train_total_loss': 0.65699226}
train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.6725157,
     'losses/train_total_loss': 0.6725157}
train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.6818009,
     'losses/train_total_loss': 0.6818009}
saved checkpoint to results/exp_008/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   39.1 sec | output: 
    {'evaluation/iou/IoU': 0.5396532,
     'losses/eval_semantic_loss': 0.94018996,
     'losses/eval_total_loss': 0.94018996}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.6629377,
     'losses/train_total_loss': 0.6629377}
train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.678876,
     'losses/train_total_loss': 0.678876}
train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.6372914,
     'losses/train_total_loss': 0.6372914}I0915 17:21:43.343332 139818557888320 controller.py:466] train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.6367784,
     'losses/train_total_loss': 0.6367784}
I0915 17:23:14.318335 139818557888320 controller.py:466] train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.6446666,
     'losses/train_total_loss': 0.6446666}
I0915 17:24:46.342644 139818557888320 controller.py:466] train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.66169477,
     'losses/train_total_loss': 0.66169477}
I0915 17:26:17.913765 139818557888320 controller.py:466] train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.6113392,
     'losses/train_total_loss': 0.6113392}
I0915 17:27:49.835122 139818557888320 controller.py:466] train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.6540535,
     'losses/train_total_loss': 0.6540535}
I0915 17:29:21.747028 139818557888320 controller.py:466] train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.6284874,
     'losses/train_total_loss': 0.6284874}
I0915 17:30:54.141024 139818557888320 controller.py:466] train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.62907445,
     'losses/train_total_loss': 0.62907445}
I0915 17:30:54.764856 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-5000.
I0915 17:32:26.411536 139818557888320 controller.py:466] train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.64572173,
     'losses/train_total_loss': 0.64572173}
I0915 17:33:58.602460 139818557888320 controller.py:466] train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.6247819,
     'losses/train_total_loss': 0.6247819}
I0915 17:35:29.913778 139818557888320 controller.py:466] train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.6246007,
     'losses/train_total_loss': 0.6246007}
I0915 17:37:01.111593 139818557888320 controller.py:466] train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.6088314,
     'losses/train_total_loss': 0.6088314}
I0915 17:38:33.805351 139818557888320 controller.py:466] train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.6317322,
     'losses/train_total_loss': 0.6317322}
I0915 17:40:05.821930 139818557888320 controller.py:466] train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.64545333,
     'losses/train_total_loss': 0.64545333}
I0915 17:41:37.548871 139818557888320 controller.py:466] train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.59103006,
     'losses/train_total_loss': 0.59103006}
I0915 17:43:08.705142 139818557888320 controller.py:466] train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.61553633,
     'losses/train_total_loss': 0.61553633}
I0915 17:44:40.815963 139818557888320 controller.py:466] train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.6235644,
     'losses/train_total_loss': 0.6235644}
I0915 17:46:13.214916 139818557888320 controller.py:466] train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.6132389,
     'losses/train_total_loss': 0.6132389}
I0915 17:46:13.873570 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-6000.
I0915 17:47:45.589906 139818557888320 controller.py:466] train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.6016522,
     'losses/train_total_loss': 0.6016522}
I0915 17:49:17.154835 139818557888320 controller.py:466] train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.59637,
     'losses/train_total_loss': 0.59637}
I0915 17:50:49.586360 139818557888320 controller.py:466] train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.60400164,
     'losses/train_total_loss': 0.60400164}
I0915 17:52:21.134804 139818557888320 controller.py:466] train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.61984944,
     'losses/train_total_loss': 0.61984944}
I0915 17:53:52.804320 139818557888320 controller.py:466] train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.62488973,
     'losses/train_total_loss': 0.62488973}
I0915 17:55:24.630658 139818557888320 controller.py:466] train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.58985126,
     'losses/train_total_loss': 0.58985126}
I0915 17:56:57.526791 139818557888320 controller.py:466] train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6024642,
     'losses/train_total_loss': 0.6024642}
I0915 17:58:29.515881 139818557888320 controller.py:466] train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.60486925,
     'losses/train_total_loss': 0.60486925}
I0915 18:00:00.727418 139818557888320 controller.py:466] train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.61542755,
     'losses/train_total_loss': 0.61542755}
I0915 18:01:33.209968 139818557888320 controller.py:466] train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.5987337,
     'losses/train_total_loss': 0.5987337}
I0915 18:01:33.878638 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-7000.
I0915 18:03:05.516406 139818557888320 controller.py:466] train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.6162104,
     'losses/train_total_loss': 0.6162104}
I0915 18:04:37.961451 139818557888320 controller.py:466] train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.601052,
     'losses/train_total_loss': 0.601052}
I0915 18:06:10.193752 139818557888320 controller.py:466] train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.59267193,
     'losses/train_total_loss': 0.59267193}
I0915 18:07:41.855534 139818557888320 controller.py:466] train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.5930766,
     'losses/train_total_loss': 0.5930766}
I0915 18:09:13.098415 139818557888320 controller.py:466] train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.59065336,
     'losses/train_total_loss': 0.59065336}
I0915 18:10:44.199593 139818557888320 controller.py:466] train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.5680052,
     'losses/train_total_loss': 0.5680052}
I0915 18:12:16.007171 139818557888320 controller.py:466] train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.5831048,
     'losses/train_total_loss': 0.5831048}
I0915 18:13:48.214754 139818557888320 controller.py:466] train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.5841988,
     'losses/train_total_loss': 0.5841988}
I0915 18:15:19.399981 139818557888320 controller.py:466] train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.60988307,
     'losses/train_total_loss': 0.60988307}
I0915 18:16:50.695633 139818557888320 controller.py:466] train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.57367045,
     'losses/train_total_loss': 0.57367045}
I0915 18:16:51.328777 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-8000.
I0915 18:16:51.329552 139818557888320 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0915 18:17:24.631003 139818557888320 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 18:17:24.635918 139818557888320 controller.py:295]  eval | step:   8000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.70891297,
     'losses/eval_semantic_loss': 0.52141166,
     'losses/eval_total_loss': 0.52141166}
I0915 18:17:24.641870 139818557888320 controller.py:241] train | step:   8000 | training until step 12000...
I0915 18:18:57.251470 139818557888320 controller.py:466] train | step:   8100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.5789514,
     'losses/train_total_loss': 0.5789514}
I0915 18:20:29.633541 139818557888320 controller.py:466] train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.56573284,
     'losses/train_total_loss': 0.56573284}
I0915 18:22:02.029474 139818557888320 controller.py:466] train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.5967197,
     'losses/train_total_loss': 0.5967197}
I0915 18:23:34.779458 139818557888320 controller.py:466] train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.57544684,
     'losses/train_total_loss': 0.57544684}
I0915 18:25:07.933144 139818557888320 controller.py:466] train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.5771436,
     'losses/train_total_loss': 0.5771436}
I0915 18:26:40.822483 139818557888320 controller.py:466] train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.59314173,
     'losses/train_total_loss': 0.59314173}
I0915 18:28:13.121847 139818557888320 controller.py:466] train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.56527036,
     'losses/train_total_loss': 0.56527036}

train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.6367784,
     'losses/train_total_loss': 0.6367784}
train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.6446666,
     'losses/train_total_loss': 0.6446666}
train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.66169477,
     'losses/train_total_loss': 0.66169477}
train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.6113392,
     'losses/train_total_loss': 0.6113392}
train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.6540535,
     'losses/train_total_loss': 0.6540535}
train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.6284874,
     'losses/train_total_loss': 0.6284874}
train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.62907445,
     'losses/train_total_loss': 0.62907445}
saved checkpoint to results/exp_008/ckpt-5000.
train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.64572173,
     'losses/train_total_loss': 0.64572173}
train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.6247819,
     'losses/train_total_loss': 0.6247819}
train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.6246007,
     'losses/train_total_loss': 0.6246007}
train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.6088314,
     'losses/train_total_loss': 0.6088314}
train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.6317322,
     'losses/train_total_loss': 0.6317322}
train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.64545333,
     'losses/train_total_loss': 0.64545333}
train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.59103006,
     'losses/train_total_loss': 0.59103006}
train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.61553633,
     'losses/train_total_loss': 0.61553633}
train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.6235644,
     'losses/train_total_loss': 0.6235644}
train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.6132389,
     'losses/train_total_loss': 0.6132389}
saved checkpoint to results/exp_008/ckpt-6000.
train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.6016522,
     'losses/train_total_loss': 0.6016522}
train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.59637,
     'losses/train_total_loss': 0.59637}
train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.60400164,
     'losses/train_total_loss': 0.60400164}
train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.61984944,
     'losses/train_total_loss': 0.61984944}
train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.62488973,
     'losses/train_total_loss': 0.62488973}
train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.58985126,
     'losses/train_total_loss': 0.58985126}
train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6024642,
     'losses/train_total_loss': 0.6024642}
train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.60486925,
     'losses/train_total_loss': 0.60486925}
train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.61542755,
     'losses/train_total_loss': 0.61542755}
train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.5987337,
     'losses/train_total_loss': 0.5987337}
saved checkpoint to results/exp_008/ckpt-7000.
train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.6162104,
     'losses/train_total_loss': 0.6162104}
train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.601052,
     'losses/train_total_loss': 0.601052}
train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.59267193,
     'losses/train_total_loss': 0.59267193}
train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.5930766,
     'losses/train_total_loss': 0.5930766}
train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.59065336,
     'losses/train_total_loss': 0.59065336}
train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.5680052,
     'losses/train_total_loss': 0.5680052}
train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.5831048,
     'losses/train_total_loss': 0.5831048}
train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.5841988,
     'losses/train_total_loss': 0.5841988}
train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.60988307,
     'losses/train_total_loss': 0.60988307}
train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.57367045,
     'losses/train_total_loss': 0.57367045}
saved checkpoint to results/exp_008/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.70891297,
     'losses/eval_semantic_loss': 0.52141166,
     'losses/eval_total_loss': 0.52141166}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.5789514,
     'losses/train_total_loss': 0.5789514}
train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.56573284,
     'losses/train_total_loss': 0.56573284}
train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.5967197,
     'losses/train_total_loss': 0.5967197}
train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.57544684,
     'losses/train_total_loss': 0.57544684}
train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.5771436,
     'losses/train_total_loss': 0.5771436}
train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.59314173,
     'losses/train_total_loss': 0.59314173}
train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.56527036,
     'losses/train_total_loss': 0.56527036}I0915 18:29:44.842162 139818557888320 controller.py:466] train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.56375796,
     'losses/train_total_loss': 0.56375796}
I0915 18:31:17.855339 139818557888320 controller.py:466] train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.57837456,
     'losses/train_total_loss': 0.57837456}
I0915 18:32:51.296794 139818557888320 controller.py:466] train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.5677496,
     'losses/train_total_loss': 0.5677496}
I0915 18:32:51.979833 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-9000.
I0915 18:34:24.068273 139818557888320 controller.py:466] train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.56979924,
     'losses/train_total_loss': 0.56979924}
I0915 18:35:55.342290 139818557888320 controller.py:466] train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.5620358,
     'losses/train_total_loss': 0.5620358}
I0915 18:37:26.306175 139818557888320 controller.py:466] train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.5700958,
     'losses/train_total_loss': 0.5700958}
I0915 18:38:58.548583 139818557888320 controller.py:466] train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.5728394,
     'losses/train_total_loss': 0.5728394}
I0915 18:40:29.791406 139818557888320 controller.py:466] train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.55506945,
     'losses/train_total_loss': 0.55506945}
I0915 18:42:00.897568 139818557888320 controller.py:466] train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.5449102,
     'losses/train_total_loss': 0.5449102}
I0915 18:43:32.493905 139818557888320 controller.py:466] train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.56609243,
     'losses/train_total_loss': 0.56609243}
I0915 18:45:05.391526 139818557888320 controller.py:466] train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.5812262,
     'losses/train_total_loss': 0.5812262}
I0915 18:46:36.290970 139818557888320 controller.py:466] train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.53743625,
     'losses/train_total_loss': 0.53743625}
I0915 18:48:07.635832 139818557888320 controller.py:466] train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.5541651,
     'losses/train_total_loss': 0.5541651}
I0915 18:48:08.296369 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-10000.
I0915 18:49:40.350501 139818557888320 controller.py:466] train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.5223119,
     'losses/train_total_loss': 0.5223119}
I0915 18:51:12.371726 139818557888320 controller.py:466] train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.55198675,
     'losses/train_total_loss': 0.55198675}
I0915 18:52:43.699979 139818557888320 controller.py:466] train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.5614976,
     'losses/train_total_loss': 0.5614976}
I0915 18:54:15.198387 139818557888320 controller.py:466] train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.55881,
     'losses/train_total_loss': 0.55881}
I0915 18:55:46.644490 139818557888320 controller.py:466] train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.5558536,
     'losses/train_total_loss': 0.5558536}
I0915 18:57:18.584321 139818557888320 controller.py:466] train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.5581438,
     'losses/train_total_loss': 0.5581438}
I0915 18:58:49.709598 139818557888320 controller.py:466] train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.54422045,
     'losses/train_total_loss': 0.54422045}
I0915 19:00:21.124454 139818557888320 controller.py:466] train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.536551,
     'losses/train_total_loss': 0.536551}
I0915 19:01:52.775324 139818557888320 controller.py:466] train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.5441718,
     'losses/train_total_loss': 0.5441718}
I0915 19:03:24.853711 139818557888320 controller.py:466] train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.54252476,
     'losses/train_total_loss': 0.54252476}
I0915 19:03:25.477539 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-11000.
I0915 19:04:56.886219 139818557888320 controller.py:466] train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.53837454,
     'losses/train_total_loss': 0.53837454}
I0915 19:06:28.274906 139818557888320 controller.py:466] train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.54201853,
     'losses/train_total_loss': 0.54201853}
I0915 19:07:59.200778 139818557888320 controller.py:466] train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.5613804,
     'losses/train_total_loss': 0.5613804}
I0915 19:09:31.320674 139818557888320 controller.py:466] train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.54468405,
     'losses/train_total_loss': 0.54468405}
I0915 19:11:03.442435 139818557888320 controller.py:466] train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.50334907,
     'losses/train_total_loss': 0.50334907}
I0915 19:12:34.767585 139818557888320 controller.py:466] train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.5339112,
     'losses/train_total_loss': 0.5339112}
I0915 19:14:05.920200 139818557888320 controller.py:466] train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.5279541,
     'losses/train_total_loss': 0.5279541}
I0915 19:15:37.889527 139818557888320 controller.py:466] train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.548118,
     'losses/train_total_loss': 0.548118}
I0915 19:17:08.831913 139818557888320 controller.py:466] train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.5573393,
     'losses/train_total_loss': 0.5573393}
I0915 19:18:40.458179 139818557888320 controller.py:466] train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.5337299,
     'losses/train_total_loss': 0.5337299}
I0915 19:18:41.290776 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-12000.
I0915 19:18:41.291643 139818557888320 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0915 19:19:14.561772 139818557888320 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 19:19:14.568505 139818557888320 controller.py:295]  eval | step:  12000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.7336447,
     'losses/eval_semantic_loss': 0.46553418,
     'losses/eval_total_loss': 0.46553418}
I0915 19:19:14.574687 139818557888320 controller.py:241] train | step:  12000 | training until step 16000...
I0915 19:20:46.566923 139818557888320 controller.py:466] train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.5529611,
     'losses/train_total_loss': 0.5529611}
I0915 19:22:18.886732 139818557888320 controller.py:466] train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.5335408,
     'losses/train_total_loss': 0.5335408}
I0915 19:23:51.556909 139818557888320 controller.py:466] train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.55235255,
     'losses/train_total_loss': 0.55235255}
I0915 19:25:23.733153 139818557888320 controller.py:466] train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.5310942,
     'losses/train_total_loss': 0.5310942}
I0915 19:26:56.223029 139818557888320 controller.py:466] train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.53714323,
     'losses/train_total_loss': 0.53714323}
I0915 19:28:28.372637 139818557888320 controller.py:466] train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.50925523,
     'losses/train_total_loss': 0.50925523}
I0915 19:30:01.351602 139818557888320 controller.py:466] train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.5406011,
     'losses/train_total_loss': 0.5406011}
I0915 19:31:34.051306 139818557888320 controller.py:466] train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.5159139,
     'losses/train_total_loss': 0.5159139}
I0915 19:33:06.599763 139818557888320 controller.py:466] train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.54894745,
     'losses/train_total_loss': 0.54894745}
I0915 19:34:38.909360 139818557888320 controller.py:466] train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5358691,
     'losses/train_total_loss': 0.5358691}
I0915 19:34:39.840744 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-13000.
I0915 19:36:11.992841 139818557888320 controller.py:466] train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.5066342,
     'losses/train_total_loss': 0.5066342}

train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.56375796,
     'losses/train_total_loss': 0.56375796}
train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.57837456,
     'losses/train_total_loss': 0.57837456}
train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.5677496,
     'losses/train_total_loss': 0.5677496}
saved checkpoint to results/exp_008/ckpt-9000.
train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.56979924,
     'losses/train_total_loss': 0.56979924}
train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.5620358,
     'losses/train_total_loss': 0.5620358}
train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.5700958,
     'losses/train_total_loss': 0.5700958}
train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.5728394,
     'losses/train_total_loss': 0.5728394}
train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.55506945,
     'losses/train_total_loss': 0.55506945}
train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.5449102,
     'losses/train_total_loss': 0.5449102}
train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.56609243,
     'losses/train_total_loss': 0.56609243}
train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.5812262,
     'losses/train_total_loss': 0.5812262}
train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.53743625,
     'losses/train_total_loss': 0.53743625}
train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.5541651,
     'losses/train_total_loss': 0.5541651}
saved checkpoint to results/exp_008/ckpt-10000.
train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.5223119,
     'losses/train_total_loss': 0.5223119}
train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.55198675,
     'losses/train_total_loss': 0.55198675}
train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.5614976,
     'losses/train_total_loss': 0.5614976}
train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.55881,
     'losses/train_total_loss': 0.55881}
train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.5558536,
     'losses/train_total_loss': 0.5558536}
train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.5581438,
     'losses/train_total_loss': 0.5581438}
train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.54422045,
     'losses/train_total_loss': 0.54422045}
train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.536551,
     'losses/train_total_loss': 0.536551}
train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.5441718,
     'losses/train_total_loss': 0.5441718}
train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.54252476,
     'losses/train_total_loss': 0.54252476}
saved checkpoint to results/exp_008/ckpt-11000.
train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.53837454,
     'losses/train_total_loss': 0.53837454}
train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.54201853,
     'losses/train_total_loss': 0.54201853}
train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.5613804,
     'losses/train_total_loss': 0.5613804}
train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.54468405,
     'losses/train_total_loss': 0.54468405}
train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.50334907,
     'losses/train_total_loss': 0.50334907}
train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.5339112,
     'losses/train_total_loss': 0.5339112}
train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.5279541,
     'losses/train_total_loss': 0.5279541}
train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.548118,
     'losses/train_total_loss': 0.548118}
train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.5573393,
     'losses/train_total_loss': 0.5573393}
train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.5337299,
     'losses/train_total_loss': 0.5337299}
saved checkpoint to results/exp_008/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.7336447,
     'losses/eval_semantic_loss': 0.46553418,
     'losses/eval_total_loss': 0.46553418}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.5529611,
     'losses/train_total_loss': 0.5529611}
train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.5335408,
     'losses/train_total_loss': 0.5335408}
train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.55235255,
     'losses/train_total_loss': 0.55235255}
train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.5310942,
     'losses/train_total_loss': 0.5310942}
train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.53714323,
     'losses/train_total_loss': 0.53714323}
train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.50925523,
     'losses/train_total_loss': 0.50925523}
train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.5406011,
     'losses/train_total_loss': 0.5406011}
train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.5159139,
     'losses/train_total_loss': 0.5159139}
train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.54894745,
     'losses/train_total_loss': 0.54894745}
train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5358691,
     'losses/train_total_loss': 0.5358691}
saved checkpoint to results/exp_008/ckpt-13000.
train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.5066342,
     'losses/train_total_loss': 0.5066342}I0915 19:37:43.360226 139818557888320 controller.py:466] train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.5126344,
     'losses/train_total_loss': 0.5126344}
I0915 19:39:14.515472 139818557888320 controller.py:466] train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.5019187,
     'losses/train_total_loss': 0.5019187}
I0915 19:40:46.047487 139818557888320 controller.py:466] train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.5287914,
     'losses/train_total_loss': 0.5287914}
I0915 19:42:18.029066 139818557888320 controller.py:466] train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.50345534,
     'losses/train_total_loss': 0.50345534}
I0915 19:43:50.792824 139818557888320 controller.py:466] train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.50480294,
     'losses/train_total_loss': 0.50480294}
I0915 19:45:22.657355 139818557888320 controller.py:466] train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.5401714,
     'losses/train_total_loss': 0.5401714}
I0915 19:46:53.790227 139818557888320 controller.py:466] train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.54856485,
     'losses/train_total_loss': 0.54856485}
I0915 19:48:25.838006 139818557888320 controller.py:466] train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.4970869,
     'losses/train_total_loss': 0.4970869}
I0915 19:49:58.151763 139818557888320 controller.py:466] train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.5300261,
     'losses/train_total_loss': 0.5300261}
I0915 19:49:58.811882 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-14000.
I0915 19:51:30.666177 139818557888320 controller.py:466] train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.5144936,
     'losses/train_total_loss': 0.5144936}
I0915 19:53:02.199140 139818557888320 controller.py:466] train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.50430685,
     'losses/train_total_loss': 0.50430685}
I0915 19:54:33.588431 139818557888320 controller.py:466] train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.48747078,
     'losses/train_total_loss': 0.48747078}
I0915 19:56:05.708462 139818557888320 controller.py:466] train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.5175321,
     'losses/train_total_loss': 0.5175321}
I0915 19:57:37.005431 139818557888320 controller.py:466] train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.5234135,
     'losses/train_total_loss': 0.5234135}
I0915 19:59:08.398473 139818557888320 controller.py:466] train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.51461196,
     'losses/train_total_loss': 0.51461196}
I0915 20:00:39.569759 139818557888320 controller.py:466] train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.5143633,
     'losses/train_total_loss': 0.5143633}
I0915 20:02:10.878472 139818557888320 controller.py:466] train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.5018664,
     'losses/train_total_loss': 0.5018664}
I0915 20:03:43.066288 139818557888320 controller.py:466] train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.553364,
     'losses/train_total_loss': 0.553364}
I0915 20:05:14.204175 139818557888320 controller.py:466] train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.46705285,
     'losses/train_total_loss': 0.46705285}
I0915 20:05:15.246791 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-15000.
I0915 20:06:47.122677 139818557888320 controller.py:466] train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.49713382,
     'losses/train_total_loss': 0.49713382}
I0915 20:08:18.474714 139818557888320 controller.py:466] train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.50027555,
     'losses/train_total_loss': 0.50027555}
I0915 20:09:49.915471 139818557888320 controller.py:466] train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.49391666,
     'losses/train_total_loss': 0.49391666}
I0915 20:11:21.559294 139818557888320 controller.py:466] train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.50969875,
     'losses/train_total_loss': 0.50969875}
I0915 20:12:52.791084 139818557888320 controller.py:466] train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.49021888,
     'losses/train_total_loss': 0.49021888}
I0915 20:14:24.978248 139818557888320 controller.py:466] train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.500391,
     'losses/train_total_loss': 0.500391}
I0915 20:15:56.928835 139818557888320 controller.py:466] train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.49376473,
     'losses/train_total_loss': 0.49376473}
I0915 20:17:27.987302 139818557888320 controller.py:466] train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.48190534,
     'losses/train_total_loss': 0.48190534}
I0915 20:18:59.846441 139818557888320 controller.py:466] train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.46731216,
     'losses/train_total_loss': 0.46731216}
I0915 20:20:31.262528 139818557888320 controller.py:466] train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.5073394,
     'losses/train_total_loss': 0.5073394}
I0915 20:20:32.054986 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-16000.
I0915 20:20:32.055848 139818557888320 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0915 20:21:05.315399 139818557888320 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 20:21:05.330137 139818557888320 controller.py:295]  eval | step:  16000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.74435985,
     'losses/eval_semantic_loss': 0.43345442,
     'losses/eval_total_loss': 0.43345442}
I0915 20:21:05.335556 139818557888320 controller.py:241] train | step:  16000 | training until step 20000...
I0915 20:22:37.147797 139818557888320 controller.py:466] train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.46078563,
     'losses/train_total_loss': 0.46078563}
I0915 20:24:08.057955 139818557888320 controller.py:466] train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.48976502,
     'losses/train_total_loss': 0.48976502}
I0915 20:25:39.838482 139818557888320 controller.py:466] train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.48753315,
     'losses/train_total_loss': 0.48753315}
I0915 20:27:11.994473 139818557888320 controller.py:466] train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.47193387,
     'losses/train_total_loss': 0.47193387}
I0915 20:28:43.329927 139818557888320 controller.py:466] train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.49592742,
     'losses/train_total_loss': 0.49592742}
I0915 20:30:15.091558 139818557888320 controller.py:466] train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.5011754,
     'losses/train_total_loss': 0.5011754}
I0915 20:31:46.772849 139818557888320 controller.py:466] train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.49762905,
     'losses/train_total_loss': 0.49762905}
I0915 20:33:19.085810 139818557888320 controller.py:466] train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.4971542,
     'losses/train_total_loss': 0.4971542}
I0915 20:34:50.549556 139818557888320 controller.py:466] train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.49303585,
     'losses/train_total_loss': 0.49303585}
I0915 20:36:22.193452 139818557888320 controller.py:466] train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.47228128,
     'losses/train_total_loss': 0.47228128}
I0915 20:36:22.826182 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-17000.
I0915 20:37:54.904031 139818557888320 controller.py:466] train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.4672451,
     'losses/train_total_loss': 0.4672451}
I0915 20:39:27.522725 139818557888320 controller.py:466] train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.47538254,
     'losses/train_total_loss': 0.47538254}
I0915 20:40:59.067314 139818557888320 controller.py:466] train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.48639068,
     'losses/train_total_loss': 0.48639068}
I0915 20:42:30.395561 139818557888320 controller.py:466] train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.48046985,
     'losses/train_total_loss': 0.48046985}
I0915 20:44:02.505362 139818557888320 controller.py:466] train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.46245193,
     'losses/train_total_loss': 0.46245193}

train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.5126344,
     'losses/train_total_loss': 0.5126344}
train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.5019187,
     'losses/train_total_loss': 0.5019187}
train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.5287914,
     'losses/train_total_loss': 0.5287914}
train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.50345534,
     'losses/train_total_loss': 0.50345534}
train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.50480294,
     'losses/train_total_loss': 0.50480294}
train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.5401714,
     'losses/train_total_loss': 0.5401714}
train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.54856485,
     'losses/train_total_loss': 0.54856485}
train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.4970869,
     'losses/train_total_loss': 0.4970869}
train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.5300261,
     'losses/train_total_loss': 0.5300261}
saved checkpoint to results/exp_008/ckpt-14000.
train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.5144936,
     'losses/train_total_loss': 0.5144936}
train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.50430685,
     'losses/train_total_loss': 0.50430685}
train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.48747078,
     'losses/train_total_loss': 0.48747078}
train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.5175321,
     'losses/train_total_loss': 0.5175321}
train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.5234135,
     'losses/train_total_loss': 0.5234135}
train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.51461196,
     'losses/train_total_loss': 0.51461196}
train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.5143633,
     'losses/train_total_loss': 0.5143633}
train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.5018664,
     'losses/train_total_loss': 0.5018664}
train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.553364,
     'losses/train_total_loss': 0.553364}
train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.46705285,
     'losses/train_total_loss': 0.46705285}
saved checkpoint to results/exp_008/ckpt-15000.
train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.49713382,
     'losses/train_total_loss': 0.49713382}
train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.50027555,
     'losses/train_total_loss': 0.50027555}
train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.49391666,
     'losses/train_total_loss': 0.49391666}
train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.50969875,
     'losses/train_total_loss': 0.50969875}
train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.49021888,
     'losses/train_total_loss': 0.49021888}
train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.500391,
     'losses/train_total_loss': 0.500391}
train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.49376473,
     'losses/train_total_loss': 0.49376473}
train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.48190534,
     'losses/train_total_loss': 0.48190534}
train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.46731216,
     'losses/train_total_loss': 0.46731216}
train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.5073394,
     'losses/train_total_loss': 0.5073394}
saved checkpoint to results/exp_008/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   33.3 sec | output: 
    {'evaluation/iou/IoU': 0.74435985,
     'losses/eval_semantic_loss': 0.43345442,
     'losses/eval_total_loss': 0.43345442}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.46078563,
     'losses/train_total_loss': 0.46078563}
train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.48976502,
     'losses/train_total_loss': 0.48976502}
train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.48753315,
     'losses/train_total_loss': 0.48753315}
train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.47193387,
     'losses/train_total_loss': 0.47193387}
train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.49592742,
     'losses/train_total_loss': 0.49592742}
train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.5011754,
     'losses/train_total_loss': 0.5011754}
train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.49762905,
     'losses/train_total_loss': 0.49762905}
train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.4971542,
     'losses/train_total_loss': 0.4971542}
train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.49303585,
     'losses/train_total_loss': 0.49303585}
train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.47228128,
     'losses/train_total_loss': 0.47228128}
saved checkpoint to results/exp_008/ckpt-17000.
train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.4672451,
     'losses/train_total_loss': 0.4672451}
train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.47538254,
     'losses/train_total_loss': 0.47538254}
train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.48639068,
     'losses/train_total_loss': 0.48639068}
train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.48046985,
     'losses/train_total_loss': 0.48046985}
train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.46245193,
     'losses/train_total_loss': 0.46245193}I0915 20:45:33.728502 139818557888320 controller.py:466] train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.48568618,
     'losses/train_total_loss': 0.48568618}
I0915 20:47:04.486278 139818557888320 controller.py:466] train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.48742694,
     'losses/train_total_loss': 0.48742694}
I0915 20:48:36.610076 139818557888320 controller.py:466] train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.47182083,
     'losses/train_total_loss': 0.47182083}
I0915 20:50:08.619529 139818557888320 controller.py:466] train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.45800078,
     'losses/train_total_loss': 0.45800078}
I0915 20:51:39.918448 139818557888320 controller.py:466] train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.47435218,
     'losses/train_total_loss': 0.47435218}
I0915 20:51:40.559143 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-18000.
I0915 20:53:12.954664 139818557888320 controller.py:466] train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.46945503,
     'losses/train_total_loss': 0.46945503}
I0915 20:54:44.079707 139818557888320 controller.py:466] train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.4844197,
     'losses/train_total_loss': 0.4844197}
I0915 20:56:15.763832 139818557888320 controller.py:466] train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.48695385,
     'losses/train_total_loss': 0.48695385}
I0915 20:57:47.543489 139818557888320 controller.py:466] train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.49101296,
     'losses/train_total_loss': 0.49101296}
I0915 20:59:18.560536 139818557888320 controller.py:466] train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.49529758,
     'losses/train_total_loss': 0.49529758}
I0915 21:00:50.265595 139818557888320 controller.py:466] train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.47053763,
     'losses/train_total_loss': 0.47053763}
I0915 21:02:22.360580 139818557888320 controller.py:466] train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.46605182,
     'losses/train_total_loss': 0.46605182}
I0915 21:03:53.901334 139818557888320 controller.py:466] train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.437852,
     'losses/train_total_loss': 0.437852}
I0915 21:05:24.938382 139818557888320 controller.py:466] train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.47900975,
     'losses/train_total_loss': 0.47900975}
I0915 21:06:56.172965 139818557888320 controller.py:466] train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.47403947,
     'losses/train_total_loss': 0.47403947}
I0915 21:06:56.934634 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-19000.
I0915 21:08:28.821554 139818557888320 controller.py:466] train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.46956906,
     'losses/train_total_loss': 0.46956906}
I0915 21:09:59.763779 139818557888320 controller.py:466] train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.48143172,
     'losses/train_total_loss': 0.48143172}
I0915 21:11:31.840315 139818557888320 controller.py:466] train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.45747578,
     'losses/train_total_loss': 0.45747578}
I0915 21:13:04.339154 139818557888320 controller.py:466] train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.46046573,
     'losses/train_total_loss': 0.46046573}
I0915 21:14:36.274985 139818557888320 controller.py:466] train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.46357927,
     'losses/train_total_loss': 0.46357927}
I0915 21:16:07.953781 139818557888320 controller.py:466] train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.46276015,
     'losses/train_total_loss': 0.46276015}
I0915 21:17:40.069613 139818557888320 controller.py:466] train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.44545066,
     'losses/train_total_loss': 0.44545066}
I0915 21:19:11.623692 139818557888320 controller.py:466] train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.4610496,
     'losses/train_total_loss': 0.4610496}
I0915 21:20:42.450679 139818557888320 controller.py:466] train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.4743169,
     'losses/train_total_loss': 0.4743169}
I0915 21:22:14.917394 139818557888320 controller.py:466] train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.43873662,
     'losses/train_total_loss': 0.43873662}
I0915 21:22:15.525826 139818557888320 controller.py:495] saved checkpoint to results/exp_008/ckpt-20000.
I0915 21:22:15.526335 139818557888320 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0915 21:22:48.117859 139818557888320 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 21:22:48.122526 139818557888320 controller.py:295]  eval | step:  20000 | eval time:   32.6 sec | output: 
    {'evaluation/iou/IoU': 0.75445276,
     'losses/eval_semantic_loss': 0.40634322,
     'losses/eval_total_loss': 0.40634322}

train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.48568618,
     'losses/train_total_loss': 0.48568618}
train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.48742694,
     'losses/train_total_loss': 0.48742694}
train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.47182083,
     'losses/train_total_loss': 0.47182083}
train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.45800078,
     'losses/train_total_loss': 0.45800078}
train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.47435218,
     'losses/train_total_loss': 0.47435218}
saved checkpoint to results/exp_008/ckpt-18000.
train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.46945503,
     'losses/train_total_loss': 0.46945503}
train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.4844197,
     'losses/train_total_loss': 0.4844197}
train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.48695385,
     'losses/train_total_loss': 0.48695385}
train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.49101296,
     'losses/train_total_loss': 0.49101296}
train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.49529758,
     'losses/train_total_loss': 0.49529758}
train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.47053763,
     'losses/train_total_loss': 0.47053763}
train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.46605182,
     'losses/train_total_loss': 0.46605182}
train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.437852,
     'losses/train_total_loss': 0.437852}
train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.47900975,
     'losses/train_total_loss': 0.47900975}
train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.47403947,
     'losses/train_total_loss': 0.47403947}
saved checkpoint to results/exp_008/ckpt-19000.
train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.46956906,
     'losses/train_total_loss': 0.46956906}
train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.48143172,
     'losses/train_total_loss': 0.48143172}
train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.45747578,
     'losses/train_total_loss': 0.45747578}
train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.46046573,
     'losses/train_total_loss': 0.46046573}
train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.46357927,
     'losses/train_total_loss': 0.46357927}
train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.46276015,
     'losses/train_total_loss': 0.46276015}
train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.44545066,
     'losses/train_total_loss': 0.44545066}
train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.4610496,
     'losses/train_total_loss': 0.4610496}
train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.4743169,
     'losses/train_total_loss': 0.4743169}
train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.43873662,
     'losses/train_total_loss': 0.43873662}
saved checkpoint to results/exp_008/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   32.6 sec | output: 
    {'evaluation/iou/IoU': 0.75445276,
     'losses/eval_semantic_loss': 0.40634322,
     'losses/eval_total_loss': 0.40634322}
