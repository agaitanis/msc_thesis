I0915 00:29:53.424425 140385095513920 train.py:65] Reading the config file.
I0915 00:29:53.426049 140385095513920 train.py:69] Starting the experiment.
2022-09-15 00:29:53.426442: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-15 00:29:53.865041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0915 00:29:53.866530 140385095513920 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0915 00:29:53.996504 140385095513920 deeplab.py:57] Synchronized Batchnorm is used.
I0915 00:29:53.997542 140385095513920 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 32, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0915 00:29:54.097320 140385095513920 deeplab.py:96] Setting pooling size to (17, 17)
I0915 00:29:54.097434 140385095513920 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 00:29:57.022382 140385095513920 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0915 00:29:57.036837 140385095513920 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0915 00:29:57.047944 140385095513920 controller.py:399] initialized model.
I0915 00:29:57.667981 140385095513920 api.py:447] Eval with scales ListWrapper([1.0])
I0915 00:29:58.532857 140385095513920 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 00:29:58.550577 140385095513920 api.py:447] Eval scale 1.0; setting pooling size to [17, 17]
I0915 00:30:01.441835 140385095513920 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 00:30:01.813420 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-0.
I0915 00:30:01.814035 140385095513920 controller.py:241] train | step:      0 | training until step 5000...
2022-09-15 00:30:25.506464: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0915 00:31:37.571988 140385095513920 controller.py:466] train | step:    100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.1064992,
     'losses/train_total_loss': 1.1064992}
I0915 00:32:48.128855 140385095513920 controller.py:466] train | step:    200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 1.0082535,
     'losses/train_total_loss': 1.0082535}
I0915 00:33:59.730440 140385095513920 controller.py:466] train | step:    300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.9391137,
     'losses/train_total_loss': 0.9391137}
I0915 00:35:12.416613 140385095513920 controller.py:466] train | step:    400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.9177974,
     'losses/train_total_loss': 0.9177974}
I0915 00:36:24.204678 140385095513920 controller.py:466] train | step:    500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.8801231,
     'losses/train_total_loss': 0.8801231}
I0915 00:37:37.224975 140385095513920 controller.py:466] train | step:    600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8840942,
     'losses/train_total_loss': 0.8840942}
I0915 00:38:49.730280 140385095513920 controller.py:466] train | step:    700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.81999224,
     'losses/train_total_loss': 0.81999224}
I0915 00:40:02.105438 140385095513920 controller.py:466] train | step:    800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.8106991,
     'losses/train_total_loss': 0.8106991}
I0915 00:41:14.557636 140385095513920 controller.py:466] train | step:    900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.82438993,
     'losses/train_total_loss': 0.82438993}
I0915 00:42:26.831519 140385095513920 controller.py:466] train | step:   1000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.7991314,
     'losses/train_total_loss': 0.7991314}
I0915 00:42:27.637295 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-1000.
I0915 00:43:40.149091 140385095513920 controller.py:466] train | step:   1100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7828276,
     'losses/train_total_loss': 0.7828276}
I0915 00:44:51.920580 140385095513920 controller.py:466] train | step:   1200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.75000787,
     'losses/train_total_loss': 0.75000787}
I0915 00:46:04.182273 140385095513920 controller.py:466] train | step:   1300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.78860414,
     'losses/train_total_loss': 0.78860414}
I0915 00:47:17.001485 140385095513920 controller.py:466] train | step:   1400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7510041,
     'losses/train_total_loss': 0.7510041}
I0915 00:48:29.651637 140385095513920 controller.py:466] train | step:   1500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7651837,
     'losses/train_total_loss': 0.7651837}
I0915 00:49:41.526086 140385095513920 controller.py:466] train | step:   1600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.7567853,
     'losses/train_total_loss': 0.7567853}
I0915 00:50:53.702033 140385095513920 controller.py:466] train | step:   1700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.7719207,
     'losses/train_total_loss': 0.7719207}
I0915 00:52:06.988235 140385095513920 controller.py:466] train | step:   1800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.754206,
     'losses/train_total_loss': 0.754206}
I0915 00:53:19.482353 140385095513920 controller.py:466] train | step:   1900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.777317,
     'losses/train_total_loss': 0.777317}
I0915 00:54:31.927426 140385095513920 controller.py:466] train | step:   2000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.748513,
     'losses/train_total_loss': 0.748513}
I0915 00:54:32.702318 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-2000.
I0915 00:55:45.606992 140385095513920 controller.py:466] train | step:   2100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.7338214,
     'losses/train_total_loss': 0.7338214}
I0915 00:56:57.225839 140385095513920 controller.py:466] train | step:   2200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.714656,
     'losses/train_total_loss': 0.714656}
I0915 00:58:09.331721 140385095513920 controller.py:466] train | step:   2300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.7144934,
     'losses/train_total_loss': 0.7144934}
I0915 00:59:21.427484 140385095513920 controller.py:466] train | step:   2400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.73299634,
     'losses/train_total_loss': 0.73299634}
I0915 01:00:33.257072 140385095513920 controller.py:466] train | step:   2500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.729439,
     'losses/train_total_loss': 0.729439}
I0915 01:01:46.212040 140385095513920 controller.py:466] train | step:   2600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.7037723,
     'losses/train_total_loss': 0.7037723}
I0915 01:02:58.710013 140385095513920 controller.py:466] train | step:   2700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.6948359,
     'losses/train_total_loss': 0.6948359}
I0915 01:04:10.913440 140385095513920 controller.py:466] train | step:   2800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.68995494,
     'losses/train_total_loss': 0.68995494}
I0915 01:05:22.862268 140385095513920 controller.py:466] train | step:   2900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.6844412,
     'losses/train_total_loss': 0.6844412}
I0915 01:06:35.130681 140385095513920 controller.py:466] train | step:   3000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.6863403,
     'losses/train_total_loss': 0.6863403}
I0915 01:06:35.919961 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-3000.
I0915 01:07:47.796930 140385095513920 controller.py:466] train | step:   3100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.71508044,
     'losses/train_total_loss': 0.71508044}
I0915 01:08:59.451377 140385095513920 controller.py:466] train | step:   3200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.69924355,
     'losses/train_total_loss': 0.69924355}
I0915 01:10:11.534772 140385095513920 controller.py:466] train | step:   3300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.7038935,
     'losses/train_total_loss': 0.7038935}
I0915 01:11:23.545423 140385095513920 controller.py:466] train | step:   3400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.7049966,
     'losses/train_total_loss': 0.7049966}
I0915 01:12:35.721264 140385095513920 controller.py:466] train | step:   3500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.72298276,
     'losses/train_total_loss': 0.72298276}
I0915 01:13:47.421670 140385095513920 controller.py:466] train | step:   3600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6830136,
     'losses/train_total_loss': 0.6830136}
I0915 01:14:59.915806 140385095513920 controller.py:466] train | step:   3700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6813044,
     'losses/train_total_loss': 0.6813044}
I0915 01:16:12.184444 140385095513920 controller.py:466] train | step:   3800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.7116846,
     'losses/train_total_loss': 0.7116846}
I0915 01:17:24.645318 140385095513920 controller.py:466] train | step:   3900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.67992747,
     'losses/train_total_loss': 0.67992747}
I0915 01:18:37.059392 140385095513920 controller.py:466] train | step:   4000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.6688093,
     'losses/train_total_loss': 0.6688093}
I0915 01:18:37.857742 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-4000.
I0915 01:19:50.521679 140385095513920 controller.py:466] train | step:   4100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6819875,
     'losses/train_total_loss': 0.6819875}
I0915 01:21:03.039891 140385095513920 controller.py:466] train | step:   4200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.6895991,
     'losses/train_total_loss': 0.6895991}
I0915 01:22:14.630482 140385095513920 controller.py:466] train | step:   4300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6910798,
     'losses/train_total_loss': 0.6910798}
I0915 01:23:26.866252 140385095513920 controller.py:466] train | step:   4400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.67020917,
     'losses/train_total_loss': 0.67020917}
I0915 01:24:38.974670 140385095513920 controller.py:466] train | step:   4500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.68605405,
     'losses/train_total_loss': 0.68605405}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_005/ckpt-0.
train | step:      0 | training until step 5000...
train | step:    100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.1064992,
     'losses/train_total_loss': 1.1064992}
train | step:    200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 1.0082535,
     'losses/train_total_loss': 1.0082535}
train | step:    300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.9391137,
     'losses/train_total_loss': 0.9391137}
train | step:    400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.9177974,
     'losses/train_total_loss': 0.9177974}
train | step:    500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.8801231,
     'losses/train_total_loss': 0.8801231}
train | step:    600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8840942,
     'losses/train_total_loss': 0.8840942}
train | step:    700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.81999224,
     'losses/train_total_loss': 0.81999224}
train | step:    800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.8106991,
     'losses/train_total_loss': 0.8106991}
train | step:    900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.82438993,
     'losses/train_total_loss': 0.82438993}
train | step:   1000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.7991314,
     'losses/train_total_loss': 0.7991314}
saved checkpoint to results/exp_005/ckpt-1000.
train | step:   1100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7828276,
     'losses/train_total_loss': 0.7828276}
train | step:   1200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.75000787,
     'losses/train_total_loss': 0.75000787}
train | step:   1300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.78860414,
     'losses/train_total_loss': 0.78860414}
train | step:   1400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7510041,
     'losses/train_total_loss': 0.7510041}
train | step:   1500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7651837,
     'losses/train_total_loss': 0.7651837}
train | step:   1600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.7567853,
     'losses/train_total_loss': 0.7567853}
train | step:   1700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.7719207,
     'losses/train_total_loss': 0.7719207}
train | step:   1800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.754206,
     'losses/train_total_loss': 0.754206}
train | step:   1900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.777317,
     'losses/train_total_loss': 0.777317}
train | step:   2000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.748513,
     'losses/train_total_loss': 0.748513}
saved checkpoint to results/exp_005/ckpt-2000.
train | step:   2100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.7338214,
     'losses/train_total_loss': 0.7338214}
train | step:   2200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.714656,
     'losses/train_total_loss': 0.714656}
train | step:   2300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.7144934,
     'losses/train_total_loss': 0.7144934}
train | step:   2400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.73299634,
     'losses/train_total_loss': 0.73299634}
train | step:   2500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.729439,
     'losses/train_total_loss': 0.729439}
train | step:   2600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.7037723,
     'losses/train_total_loss': 0.7037723}
train | step:   2700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.6948359,
     'losses/train_total_loss': 0.6948359}
train | step:   2800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.68995494,
     'losses/train_total_loss': 0.68995494}
train | step:   2900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.6844412,
     'losses/train_total_loss': 0.6844412}
train | step:   3000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.6863403,
     'losses/train_total_loss': 0.6863403}
saved checkpoint to results/exp_005/ckpt-3000.
train | step:   3100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.71508044,
     'losses/train_total_loss': 0.71508044}
train | step:   3200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.69924355,
     'losses/train_total_loss': 0.69924355}
train | step:   3300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.7038935,
     'losses/train_total_loss': 0.7038935}
train | step:   3400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.7049966,
     'losses/train_total_loss': 0.7049966}
train | step:   3500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.72298276,
     'losses/train_total_loss': 0.72298276}
train | step:   3600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6830136,
     'losses/train_total_loss': 0.6830136}
train | step:   3700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6813044,
     'losses/train_total_loss': 0.6813044}
train | step:   3800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.7116846,
     'losses/train_total_loss': 0.7116846}
train | step:   3900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.67992747,
     'losses/train_total_loss': 0.67992747}
train | step:   4000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.6688093,
     'losses/train_total_loss': 0.6688093}
saved checkpoint to results/exp_005/ckpt-4000.
train | step:   4100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6819875,
     'losses/train_total_loss': 0.6819875}
train | step:   4200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.6895991,
     'losses/train_total_loss': 0.6895991}
train | step:   4300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6910798,
     'losses/train_total_loss': 0.6910798}
train | step:   4400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.67020917,
     'losses/train_total_loss': 0.67020917}
train | step:   4500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.68605405,
     'losses/train_total_loss': 0.68605405}I0915 01:25:51.218696 140385095513920 controller.py:466] train | step:   4600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.65033716,
     'losses/train_total_loss': 0.65033716}
I0915 01:27:03.808350 140385095513920 controller.py:466] train | step:   4700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.6563505,
     'losses/train_total_loss': 0.6563505}
I0915 01:28:15.768462 140385095513920 controller.py:466] train | step:   4800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6690225,
     'losses/train_total_loss': 0.6690225}
I0915 01:29:28.929104 140385095513920 controller.py:466] train | step:   4900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.6501016,
     'losses/train_total_loss': 0.6501016}
I0915 01:30:41.397876 140385095513920 controller.py:466] train | step:   5000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6788404,
     'losses/train_total_loss': 0.6788404}
I0915 01:30:44.130865 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-5000.
I0915 01:30:44.131928 140385095513920 controller.py:282]  eval | step:   5000 | running complete evaluation...
I0915 01:30:44.846142 140385095513920 api.py:447] Eval with scales ListWrapper([1.0])
I0915 01:30:44.874541 140385095513920 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 01:30:44.899013 140385095513920 api.py:447] Eval scale 1.0; setting pooling size to [17, 17]
I0915 01:30:45.516058 140385095513920 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 01:31:14.654908 140385095513920 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 01:31:14.691018 140385095513920 controller.py:295]  eval | step:   5000 | eval time:   30.6 sec | output: 
    {'evaluation/iou/IoU': 0.658434,
     'losses/eval_semantic_loss': 0.6054183,
     'losses/eval_total_loss': 0.6054183}
I0915 01:31:14.696897 140385095513920 controller.py:241] train | step:   5000 | training until step 10000...
I0915 01:32:26.471186 140385095513920 controller.py:466] train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.649552,
     'losses/train_total_loss': 0.649552}
I0915 01:33:38.304786 140385095513920 controller.py:466] train | step:   5200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.64905465,
     'losses/train_total_loss': 0.64905465}
I0915 01:34:50.247673 140385095513920 controller.py:466] train | step:   5300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.6547187,
     'losses/train_total_loss': 0.6547187}
I0915 01:36:02.935470 140385095513920 controller.py:466] train | step:   5400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.6522107,
     'losses/train_total_loss': 0.6522107}
I0915 01:37:15.292164 140385095513920 controller.py:466] train | step:   5500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6449056,
     'losses/train_total_loss': 0.6449056}
I0915 01:38:26.779654 140385095513920 controller.py:466] train | step:   5600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6626424,
     'losses/train_total_loss': 0.6626424}
I0915 01:39:38.891354 140385095513920 controller.py:466] train | step:   5700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.63531137,
     'losses/train_total_loss': 0.63531137}
I0915 01:40:51.140217 140385095513920 controller.py:466] train | step:   5800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.6447857,
     'losses/train_total_loss': 0.6447857}
I0915 01:42:03.476145 140385095513920 controller.py:466] train | step:   5900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.64992696,
     'losses/train_total_loss': 0.64992696}
I0915 01:43:15.518248 140385095513920 controller.py:466] train | step:   6000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6433838,
     'losses/train_total_loss': 0.6433838}
I0915 01:43:16.346160 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-6000.
I0915 01:44:28.671308 140385095513920 controller.py:466] train | step:   6100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.6603926,
     'losses/train_total_loss': 0.6603926}
I0915 01:45:40.911321 140385095513920 controller.py:466] train | step:   6200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6469334,
     'losses/train_total_loss': 0.6469334}
I0915 01:46:52.528163 140385095513920 controller.py:466] train | step:   6300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.63122475,
     'losses/train_total_loss': 0.63122475}
I0915 01:48:04.767789 140385095513920 controller.py:466] train | step:   6400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.60238826,
     'losses/train_total_loss': 0.60238826}
I0915 01:49:17.188944 140385095513920 controller.py:466] train | step:   6500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.6278235,
     'losses/train_total_loss': 0.6278235}
I0915 01:50:29.075026 140385095513920 controller.py:466] train | step:   6600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6486612,
     'losses/train_total_loss': 0.6486612}
I0915 01:51:41.341841 140385095513920 controller.py:466] train | step:   6700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.62581503,
     'losses/train_total_loss': 0.62581503}
I0915 01:52:53.965189 140385095513920 controller.py:466] train | step:   6800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.59541464,
     'losses/train_total_loss': 0.59541464}
I0915 01:54:06.565622 140385095513920 controller.py:466] train | step:   6900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.6183932,
     'losses/train_total_loss': 0.6183932}
I0915 01:55:19.509415 140385095513920 controller.py:466] train | step:   7000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6280697,
     'losses/train_total_loss': 0.6280697}
I0915 01:55:20.329784 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-7000.
I0915 01:56:32.780620 140385095513920 controller.py:466] train | step:   7100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.63991565,
     'losses/train_total_loss': 0.63991565}
I0915 01:57:44.660793 140385095513920 controller.py:466] train | step:   7200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6142645,
     'losses/train_total_loss': 0.6142645}
I0915 01:58:57.089108 140385095513920 controller.py:466] train | step:   7300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.62483144,
     'losses/train_total_loss': 0.62483144}
I0915 02:00:09.584149 140385095513920 controller.py:466] train | step:   7400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.5856359,
     'losses/train_total_loss': 0.5856359}
I0915 02:01:22.115646 140385095513920 controller.py:466] train | step:   7500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.6184587,
     'losses/train_total_loss': 0.6184587}
I0915 02:02:33.890620 140385095513920 controller.py:466] train | step:   7600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.61819625,
     'losses/train_total_loss': 0.61819625}
I0915 02:03:46.592329 140385095513920 controller.py:466] train | step:   7700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.5948967,
     'losses/train_total_loss': 0.5948967}
I0915 02:04:58.466608 140385095513920 controller.py:466] train | step:   7800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.5964845,
     'losses/train_total_loss': 0.5964845}
I0915 02:06:10.983063 140385095513920 controller.py:466] train | step:   7900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.6059628,
     'losses/train_total_loss': 0.6059628}
I0915 02:07:23.260795 140385095513920 controller.py:466] train | step:   8000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.6233486,
     'losses/train_total_loss': 0.6233486}
I0915 02:07:24.067869 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-8000.
I0915 02:08:36.085513 140385095513920 controller.py:466] train | step:   8100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.60963047,
     'losses/train_total_loss': 0.60963047}
I0915 02:09:48.607924 140385095513920 controller.py:466] train | step:   8200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.62157786,
     'losses/train_total_loss': 0.62157786}
I0915 02:11:00.946583 140385095513920 controller.py:466] train | step:   8300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.5897745,
     'losses/train_total_loss': 0.5897745}
I0915 02:12:13.180047 140385095513920 controller.py:466] train | step:   8400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.5877671,
     'losses/train_total_loss': 0.5877671}
I0915 02:13:25.061505 140385095513920 controller.py:466] train | step:   8500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.6019276,
     'losses/train_total_loss': 0.6019276}
I0915 02:14:37.631158 140385095513920 controller.py:466] train | step:   8600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.5789034,
     'losses/train_total_loss': 0.5789034}
I0915 02:15:48.786336 140385095513920 controller.py:466] train | step:   8700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.61322916,
     'losses/train_total_loss': 0.61322916}
I0915 02:17:01.167618 140385095513920 controller.py:466] train | step:   8800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.60628134,
     'losses/train_total_loss': 0.60628134}
I0915 02:18:12.196172 140385095513920 controller.py:466] train | step:   8900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.6040731,
     'losses/train_total_loss': 0.6040731}

train | step:   4600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.65033716,
     'losses/train_total_loss': 0.65033716}
train | step:   4700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.6563505,
     'losses/train_total_loss': 0.6563505}
train | step:   4800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6690225,
     'losses/train_total_loss': 0.6690225}
train | step:   4900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.6501016,
     'losses/train_total_loss': 0.6501016}
train | step:   5000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6788404,
     'losses/train_total_loss': 0.6788404}
saved checkpoint to results/exp_005/ckpt-5000.
 eval | step:   5000 | running complete evaluation...
 eval | step:   5000 | eval time:   30.6 sec | output: 
    {'evaluation/iou/IoU': 0.658434,
     'losses/eval_semantic_loss': 0.6054183,
     'losses/eval_total_loss': 0.6054183}
train | step:   5000 | training until step 10000...
train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.649552,
     'losses/train_total_loss': 0.649552}
train | step:   5200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.64905465,
     'losses/train_total_loss': 0.64905465}
train | step:   5300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.6547187,
     'losses/train_total_loss': 0.6547187}
train | step:   5400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.6522107,
     'losses/train_total_loss': 0.6522107}
train | step:   5500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6449056,
     'losses/train_total_loss': 0.6449056}
train | step:   5600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6626424,
     'losses/train_total_loss': 0.6626424}
train | step:   5700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.63531137,
     'losses/train_total_loss': 0.63531137}
train | step:   5800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.6447857,
     'losses/train_total_loss': 0.6447857}
train | step:   5900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.64992696,
     'losses/train_total_loss': 0.64992696}
train | step:   6000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6433838,
     'losses/train_total_loss': 0.6433838}
saved checkpoint to results/exp_005/ckpt-6000.
train | step:   6100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.6603926,
     'losses/train_total_loss': 0.6603926}
train | step:   6200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6469334,
     'losses/train_total_loss': 0.6469334}
train | step:   6300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.63122475,
     'losses/train_total_loss': 0.63122475}
train | step:   6400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.60238826,
     'losses/train_total_loss': 0.60238826}
train | step:   6500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.6278235,
     'losses/train_total_loss': 0.6278235}
train | step:   6600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6486612,
     'losses/train_total_loss': 0.6486612}
train | step:   6700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.62581503,
     'losses/train_total_loss': 0.62581503}
train | step:   6800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.59541464,
     'losses/train_total_loss': 0.59541464}
train | step:   6900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.6183932,
     'losses/train_total_loss': 0.6183932}
train | step:   7000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6280697,
     'losses/train_total_loss': 0.6280697}
saved checkpoint to results/exp_005/ckpt-7000.
train | step:   7100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.63991565,
     'losses/train_total_loss': 0.63991565}
train | step:   7200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6142645,
     'losses/train_total_loss': 0.6142645}
train | step:   7300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.62483144,
     'losses/train_total_loss': 0.62483144}
train | step:   7400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.5856359,
     'losses/train_total_loss': 0.5856359}
train | step:   7500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.6184587,
     'losses/train_total_loss': 0.6184587}
train | step:   7600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.61819625,
     'losses/train_total_loss': 0.61819625}
train | step:   7700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.5948967,
     'losses/train_total_loss': 0.5948967}
train | step:   7800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.5964845,
     'losses/train_total_loss': 0.5964845}
train | step:   7900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.6059628,
     'losses/train_total_loss': 0.6059628}
train | step:   8000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.6233486,
     'losses/train_total_loss': 0.6233486}
saved checkpoint to results/exp_005/ckpt-8000.
train | step:   8100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.60963047,
     'losses/train_total_loss': 0.60963047}
train | step:   8200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.62157786,
     'losses/train_total_loss': 0.62157786}
train | step:   8300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.5897745,
     'losses/train_total_loss': 0.5897745}
train | step:   8400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.5877671,
     'losses/train_total_loss': 0.5877671}
train | step:   8500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.6019276,
     'losses/train_total_loss': 0.6019276}
train | step:   8600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.5789034,
     'losses/train_total_loss': 0.5789034}
train | step:   8700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.61322916,
     'losses/train_total_loss': 0.61322916}
train | step:   8800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.60628134,
     'losses/train_total_loss': 0.60628134}
train | step:   8900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.6040731,
     'losses/train_total_loss': 0.6040731}I0915 02:19:23.406893 140385095513920 controller.py:466] train | step:   9000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5623692,
     'losses/train_total_loss': 0.5623692}
I0915 02:19:24.260562 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-9000.
I0915 02:20:35.950530 140385095513920 controller.py:466] train | step:   9100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.5981652,
     'losses/train_total_loss': 0.5981652}
I0915 02:21:47.289189 140385095513920 controller.py:466] train | step:   9200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.6171109,
     'losses/train_total_loss': 0.6171109}
I0915 02:22:59.270649 140385095513920 controller.py:466] train | step:   9300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.58396536,
     'losses/train_total_loss': 0.58396536}
I0915 02:24:10.681961 140385095513920 controller.py:466] train | step:   9400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.6066018,
     'losses/train_total_loss': 0.6066018}
I0915 02:25:22.488950 140385095513920 controller.py:466] train | step:   9500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.5740759,
     'losses/train_total_loss': 0.5740759}
I0915 02:26:33.658123 140385095513920 controller.py:466] train | step:   9600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.6032822,
     'losses/train_total_loss': 0.6032822}
I0915 02:27:45.452106 140385095513920 controller.py:466] train | step:   9700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.5900768,
     'losses/train_total_loss': 0.5900768}
I0915 02:28:56.885710 140385095513920 controller.py:466] train | step:   9800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.5919728,
     'losses/train_total_loss': 0.5919728}
I0915 02:30:08.899495 140385095513920 controller.py:466] train | step:   9900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.5677893,
     'losses/train_total_loss': 0.5677893}
I0915 02:31:20.734229 140385095513920 controller.py:466] train | step:  10000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.58179843,
     'losses/train_total_loss': 0.58179843}
I0915 02:31:21.547352 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-10000.
I0915 02:31:21.548390 140385095513920 controller.py:282]  eval | step:  10000 | running complete evaluation...
I0915 02:31:49.999236 140385095513920 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 02:31:50.018800 140385095513920 controller.py:295]  eval | step:  10000 | eval time:   28.5 sec | output: 
    {'evaluation/iou/IoU': 0.65078664,
     'losses/eval_semantic_loss': 0.71713376,
     'losses/eval_total_loss': 0.71713376}
I0915 02:31:50.022885 140385095513920 controller.py:241] train | step:  10000 | training until step 15000...
I0915 02:33:02.233072 140385095513920 controller.py:466] train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.58845973,
     'losses/train_total_loss': 0.58845973}
I0915 02:34:13.562788 140385095513920 controller.py:466] train | step:  10200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5891111,
     'losses/train_total_loss': 0.5891111}
I0915 02:35:25.854296 140385095513920 controller.py:466] train | step:  10300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.57740194,
     'losses/train_total_loss': 0.57740194}
I0915 02:36:37.564530 140385095513920 controller.py:466] train | step:  10400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5869917,
     'losses/train_total_loss': 0.5869917}
I0915 02:37:49.840558 140385095513920 controller.py:466] train | step:  10500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.55052835,
     'losses/train_total_loss': 0.55052835}
I0915 02:39:01.407174 140385095513920 controller.py:466] train | step:  10600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.5787847,
     'losses/train_total_loss': 0.5787847}
I0915 02:40:13.283532 140385095513920 controller.py:466] train | step:  10700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5947246,
     'losses/train_total_loss': 0.5947246}
I0915 02:41:25.276942 140385095513920 controller.py:466] train | step:  10800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.57714075,
     'losses/train_total_loss': 0.57714075}
I0915 02:42:36.767018 140385095513920 controller.py:466] train | step:  10900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5635153,
     'losses/train_total_loss': 0.5635153}
I0915 02:43:48.186480 140385095513920 controller.py:466] train | step:  11000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5450383,
     'losses/train_total_loss': 0.5450383}
I0915 02:43:48.961338 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-11000.
I0915 02:45:00.639083 140385095513920 controller.py:466] train | step:  11100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.59011674,
     'losses/train_total_loss': 0.59011674}
I0915 02:46:12.963883 140385095513920 controller.py:466] train | step:  11200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5551856,
     'losses/train_total_loss': 0.5551856}
I0915 02:47:25.007263 140385095513920 controller.py:466] train | step:  11300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.55164707,
     'losses/train_total_loss': 0.55164707}
I0915 02:48:36.438161 140385095513920 controller.py:466] train | step:  11400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.55838424,
     'losses/train_total_loss': 0.55838424}
I0915 02:49:48.719910 140385095513920 controller.py:466] train | step:  11500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5819679,
     'losses/train_total_loss': 0.5819679}
I0915 02:51:01.041363 140385095513920 controller.py:466] train | step:  11600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5369332,
     'losses/train_total_loss': 0.5369332}
I0915 02:52:13.228846 140385095513920 controller.py:466] train | step:  11700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5687597,
     'losses/train_total_loss': 0.5687597}
I0915 02:53:25.382487 140385095513920 controller.py:466] train | step:  11800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.54100245,
     'losses/train_total_loss': 0.54100245}
I0915 02:54:37.167795 140385095513920 controller.py:466] train | step:  11900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.57203275,
     'losses/train_total_loss': 0.57203275}
I0915 02:55:48.442173 140385095513920 controller.py:466] train | step:  12000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.54908985,
     'losses/train_total_loss': 0.54908985}
I0915 02:55:49.312507 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-12000.
I0915 02:57:01.150007 140385095513920 controller.py:466] train | step:  12100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.5463384,
     'losses/train_total_loss': 0.5463384}
I0915 02:58:12.208094 140385095513920 controller.py:466] train | step:  12200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.56890774,
     'losses/train_total_loss': 0.56890774}
I0915 02:59:24.120127 140385095513920 controller.py:466] train | step:  12300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.54111636,
     'losses/train_total_loss': 0.54111636}
I0915 03:00:36.325224 140385095513920 controller.py:466] train | step:  12400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.55333966,
     'losses/train_total_loss': 0.55333966}
I0915 03:01:48.579903 140385095513920 controller.py:466] train | step:  12500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.5511771,
     'losses/train_total_loss': 0.5511771}
I0915 03:02:59.902483 140385095513920 controller.py:466] train | step:  12600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.5573406,
     'losses/train_total_loss': 0.5573406}
I0915 03:04:11.758903 140385095513920 controller.py:466] train | step:  12700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.5455449,
     'losses/train_total_loss': 0.5455449}
I0915 03:05:23.471553 140385095513920 controller.py:466] train | step:  12800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.5608589,
     'losses/train_total_loss': 0.5608589}
I0915 03:06:35.647537 140385095513920 controller.py:466] train | step:  12900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5401899,
     'losses/train_total_loss': 0.5401899}
I0915 03:07:47.920621 140385095513920 controller.py:466] train | step:  13000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.56071395,
     'losses/train_total_loss': 0.56071395}
I0915 03:07:48.759834 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-13000.
I0915 03:09:00.843684 140385095513920 controller.py:466] train | step:  13100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.5599258,
     'losses/train_total_loss': 0.5599258}
I0915 03:10:13.374497 140385095513920 controller.py:466] train | step:  13200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.55102575,
     'losses/train_total_loss': 0.55102575}

train | step:   9000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5623692,
     'losses/train_total_loss': 0.5623692}
saved checkpoint to results/exp_005/ckpt-9000.
train | step:   9100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.5981652,
     'losses/train_total_loss': 0.5981652}
train | step:   9200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.6171109,
     'losses/train_total_loss': 0.6171109}
train | step:   9300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.58396536,
     'losses/train_total_loss': 0.58396536}
train | step:   9400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.6066018,
     'losses/train_total_loss': 0.6066018}
train | step:   9500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.5740759,
     'losses/train_total_loss': 0.5740759}
train | step:   9600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.6032822,
     'losses/train_total_loss': 0.6032822}
train | step:   9700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.5900768,
     'losses/train_total_loss': 0.5900768}
train | step:   9800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.5919728,
     'losses/train_total_loss': 0.5919728}
train | step:   9900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.5677893,
     'losses/train_total_loss': 0.5677893}
train | step:  10000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.58179843,
     'losses/train_total_loss': 0.58179843}
saved checkpoint to results/exp_005/ckpt-10000.
 eval | step:  10000 | running complete evaluation...
 eval | step:  10000 | eval time:   28.5 sec | output: 
    {'evaluation/iou/IoU': 0.65078664,
     'losses/eval_semantic_loss': 0.71713376,
     'losses/eval_total_loss': 0.71713376}
train | step:  10000 | training until step 15000...
train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.58845973,
     'losses/train_total_loss': 0.58845973}
train | step:  10200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5891111,
     'losses/train_total_loss': 0.5891111}
train | step:  10300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.57740194,
     'losses/train_total_loss': 0.57740194}
train | step:  10400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5869917,
     'losses/train_total_loss': 0.5869917}
train | step:  10500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.55052835,
     'losses/train_total_loss': 0.55052835}
train | step:  10600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.5787847,
     'losses/train_total_loss': 0.5787847}
train | step:  10700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5947246,
     'losses/train_total_loss': 0.5947246}
train | step:  10800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.57714075,
     'losses/train_total_loss': 0.57714075}
train | step:  10900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5635153,
     'losses/train_total_loss': 0.5635153}
train | step:  11000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5450383,
     'losses/train_total_loss': 0.5450383}
saved checkpoint to results/exp_005/ckpt-11000.
train | step:  11100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.59011674,
     'losses/train_total_loss': 0.59011674}
train | step:  11200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5551856,
     'losses/train_total_loss': 0.5551856}
train | step:  11300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.55164707,
     'losses/train_total_loss': 0.55164707}
train | step:  11400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.55838424,
     'losses/train_total_loss': 0.55838424}
train | step:  11500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5819679,
     'losses/train_total_loss': 0.5819679}
train | step:  11600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5369332,
     'losses/train_total_loss': 0.5369332}
train | step:  11700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5687597,
     'losses/train_total_loss': 0.5687597}
train | step:  11800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.54100245,
     'losses/train_total_loss': 0.54100245}
train | step:  11900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.57203275,
     'losses/train_total_loss': 0.57203275}
train | step:  12000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.54908985,
     'losses/train_total_loss': 0.54908985}
saved checkpoint to results/exp_005/ckpt-12000.
train | step:  12100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.5463384,
     'losses/train_total_loss': 0.5463384}
train | step:  12200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.56890774,
     'losses/train_total_loss': 0.56890774}
train | step:  12300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.54111636,
     'losses/train_total_loss': 0.54111636}
train | step:  12400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.55333966,
     'losses/train_total_loss': 0.55333966}
train | step:  12500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.5511771,
     'losses/train_total_loss': 0.5511771}
train | step:  12600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.5573406,
     'losses/train_total_loss': 0.5573406}
train | step:  12700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.5455449,
     'losses/train_total_loss': 0.5455449}
train | step:  12800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.5608589,
     'losses/train_total_loss': 0.5608589}
train | step:  12900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5401899,
     'losses/train_total_loss': 0.5401899}
train | step:  13000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.56071395,
     'losses/train_total_loss': 0.56071395}
saved checkpoint to results/exp_005/ckpt-13000.
train | step:  13100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.5599258,
     'losses/train_total_loss': 0.5599258}
train | step:  13200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.55102575,
     'losses/train_total_loss': 0.55102575}I0915 03:11:25.459292 140385095513920 controller.py:466] train | step:  13300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.5445202,
     'losses/train_total_loss': 0.5445202}
I0915 03:12:37.617781 140385095513920 controller.py:466] train | step:  13400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.53470033,
     'losses/train_total_loss': 0.53470033}
I0915 03:13:50.257744 140385095513920 controller.py:466] train | step:  13500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.53765684,
     'losses/train_total_loss': 0.53765684}
I0915 03:15:02.055827 140385095513920 controller.py:466] train | step:  13600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.50770545,
     'losses/train_total_loss': 0.50770545}
I0915 03:16:14.666271 140385095513920 controller.py:466] train | step:  13700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.5461845,
     'losses/train_total_loss': 0.5461845}
I0915 03:17:26.569657 140385095513920 controller.py:466] train | step:  13800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.5407177,
     'losses/train_total_loss': 0.5407177}
I0915 03:18:38.126545 140385095513920 controller.py:466] train | step:  13900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.56013656,
     'losses/train_total_loss': 0.56013656}
I0915 03:19:50.090108 140385095513920 controller.py:466] train | step:  14000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.5465222,
     'losses/train_total_loss': 0.5465222}
I0915 03:19:51.312918 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-14000.
I0915 03:21:03.323130 140385095513920 controller.py:466] train | step:  14100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.55307084,
     'losses/train_total_loss': 0.55307084}
I0915 03:22:15.524961 140385095513920 controller.py:466] train | step:  14200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.5419487,
     'losses/train_total_loss': 0.5419487}
I0915 03:23:27.478432 140385095513920 controller.py:466] train | step:  14300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.5367075,
     'losses/train_total_loss': 0.5367075}
I0915 03:24:40.120100 140385095513920 controller.py:466] train | step:  14400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.5490895,
     'losses/train_total_loss': 0.5490895}
I0915 03:25:52.609730 140385095513920 controller.py:466] train | step:  14500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5463447,
     'losses/train_total_loss': 0.5463447}
I0915 03:27:04.325188 140385095513920 controller.py:466] train | step:  14600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.53110266,
     'losses/train_total_loss': 0.53110266}
I0915 03:28:15.589107 140385095513920 controller.py:466] train | step:  14700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.50587773,
     'losses/train_total_loss': 0.50587773}
I0915 03:29:27.770261 140385095513920 controller.py:466] train | step:  14800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.4968579,
     'losses/train_total_loss': 0.4968579}
I0915 03:30:39.843632 140385095513920 controller.py:466] train | step:  14900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5159394,
     'losses/train_total_loss': 0.5159394}
I0915 03:31:52.723210 140385095513920 controller.py:466] train | step:  15000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.5225394,
     'losses/train_total_loss': 0.5225394}
I0915 03:31:53.556430 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-15000.
I0915 03:31:53.557266 140385095513920 controller.py:282]  eval | step:  15000 | running complete evaluation...
I0915 03:32:23.106130 140385095513920 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 03:32:23.110883 140385095513920 controller.py:295]  eval | step:  15000 | eval time:   29.6 sec | output: 
    {'evaluation/iou/IoU': 0.7249265,
     'losses/eval_semantic_loss': 0.4709328,
     'losses/eval_total_loss': 0.4709328}
I0915 03:32:23.115537 140385095513920 controller.py:241] train | step:  15000 | training until step 20000...
I0915 03:33:34.289024 140385095513920 controller.py:466] train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.52228194,
     'losses/train_total_loss': 0.52228194}
I0915 03:34:45.493170 140385095513920 controller.py:466] train | step:  15200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.53555036,
     'losses/train_total_loss': 0.53555036}
I0915 03:35:56.301466 140385095513920 controller.py:466] train | step:  15300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.5446287,
     'losses/train_total_loss': 0.5446287}
I0915 03:37:07.470946 140385095513920 controller.py:466] train | step:  15400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.5369424,
     'losses/train_total_loss': 0.5369424}
I0915 03:38:18.805897 140385095513920 controller.py:466] train | step:  15500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.5502587,
     'losses/train_total_loss': 0.5502587}
I0915 03:39:30.483051 140385095513920 controller.py:466] train | step:  15600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.52496696,
     'losses/train_total_loss': 0.52496696}
I0915 03:40:41.973664 140385095513920 controller.py:466] train | step:  15700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.51173633,
     'losses/train_total_loss': 0.51173633}
I0915 03:41:53.354263 140385095513920 controller.py:466] train | step:  15800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.53409714,
     'losses/train_total_loss': 0.53409714}
I0915 03:43:04.417559 140385095513920 controller.py:466] train | step:  15900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.5148816,
     'losses/train_total_loss': 0.5148816}
I0915 03:44:15.954556 140385095513920 controller.py:466] train | step:  16000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.54316556,
     'losses/train_total_loss': 0.54316556}
I0915 03:44:16.956440 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-16000.
I0915 03:45:29.670736 140385095513920 controller.py:466] train | step:  16100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.49558076,
     'losses/train_total_loss': 0.49558076}
I0915 03:46:42.694061 140385095513920 controller.py:466] train | step:  16200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.51997495,
     'losses/train_total_loss': 0.51997495}
I0915 03:47:55.475746 140385095513920 controller.py:466] train | step:  16300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.49374053,
     'losses/train_total_loss': 0.49374053}
I0915 03:49:07.690741 140385095513920 controller.py:466] train | step:  16400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.49512702,
     'losses/train_total_loss': 0.49512702}
I0915 03:50:19.896630 140385095513920 controller.py:466] train | step:  16500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5333633,
     'losses/train_total_loss': 0.5333633}
I0915 03:51:32.466110 140385095513920 controller.py:466] train | step:  16600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.5485572,
     'losses/train_total_loss': 0.5485572}
I0915 03:52:44.966494 140385095513920 controller.py:466] train | step:  16700 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.5174481,
     'losses/train_total_loss': 0.5174481}
I0915 03:53:57.574761 140385095513920 controller.py:466] train | step:  16800 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.5162253,
     'losses/train_total_loss': 0.5162253}
I0915 03:55:10.583846 140385095513920 controller.py:466] train | step:  16900 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.5137225,
     'losses/train_total_loss': 0.5137225}
I0915 03:56:23.430787 140385095513920 controller.py:466] train | step:  17000 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.52410936,
     'losses/train_total_loss': 0.52410936}
I0915 03:56:24.385599 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-17000.
I0915 03:57:37.021003 140385095513920 controller.py:466] train | step:  17100 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.49707505,
     'losses/train_total_loss': 0.49707505}
I0915 03:58:48.900987 140385095513920 controller.py:466] train | step:  17200 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.50756365,
     'losses/train_total_loss': 0.50756365}
I0915 04:00:01.532746 140385095513920 controller.py:466] train | step:  17300 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.50850385,
     'losses/train_total_loss': 0.50850385}
I0915 04:01:14.224110 140385095513920 controller.py:466] train | step:  17400 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.5182993,
     'losses/train_total_loss': 0.5182993}
I0915 04:02:26.947103 140385095513920 controller.py:466] train | step:  17500 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.5076788,
     'losses/train_total_loss': 0.5076788}
I0915 04:03:39.458115 140385095513920 controller.py:466] train | step:  17600 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.5405957,
     'losses/train_total_loss': 0.5405957}

train | step:  13300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.5445202,
     'losses/train_total_loss': 0.5445202}
train | step:  13400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.53470033,
     'losses/train_total_loss': 0.53470033}
train | step:  13500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.53765684,
     'losses/train_total_loss': 0.53765684}
train | step:  13600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.50770545,
     'losses/train_total_loss': 0.50770545}
train | step:  13700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.5461845,
     'losses/train_total_loss': 0.5461845}
train | step:  13800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.5407177,
     'losses/train_total_loss': 0.5407177}
train | step:  13900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.56013656,
     'losses/train_total_loss': 0.56013656}
train | step:  14000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.5465222,
     'losses/train_total_loss': 0.5465222}
saved checkpoint to results/exp_005/ckpt-14000.
train | step:  14100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.55307084,
     'losses/train_total_loss': 0.55307084}
train | step:  14200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.5419487,
     'losses/train_total_loss': 0.5419487}
train | step:  14300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.5367075,
     'losses/train_total_loss': 0.5367075}
train | step:  14400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.5490895,
     'losses/train_total_loss': 0.5490895}
train | step:  14500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5463447,
     'losses/train_total_loss': 0.5463447}
train | step:  14600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.53110266,
     'losses/train_total_loss': 0.53110266}
train | step:  14700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.50587773,
     'losses/train_total_loss': 0.50587773}
train | step:  14800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.4968579,
     'losses/train_total_loss': 0.4968579}
train | step:  14900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5159394,
     'losses/train_total_loss': 0.5159394}
train | step:  15000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.5225394,
     'losses/train_total_loss': 0.5225394}
saved checkpoint to results/exp_005/ckpt-15000.
 eval | step:  15000 | running complete evaluation...
 eval | step:  15000 | eval time:   29.6 sec | output: 
    {'evaluation/iou/IoU': 0.7249265,
     'losses/eval_semantic_loss': 0.4709328,
     'losses/eval_total_loss': 0.4709328}
train | step:  15000 | training until step 20000...
train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.52228194,
     'losses/train_total_loss': 0.52228194}
train | step:  15200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.53555036,
     'losses/train_total_loss': 0.53555036}
train | step:  15300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.5446287,
     'losses/train_total_loss': 0.5446287}
train | step:  15400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.5369424,
     'losses/train_total_loss': 0.5369424}
train | step:  15500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.5502587,
     'losses/train_total_loss': 0.5502587}
train | step:  15600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.52496696,
     'losses/train_total_loss': 0.52496696}
train | step:  15700 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.51173633,
     'losses/train_total_loss': 0.51173633}
train | step:  15800 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.53409714,
     'losses/train_total_loss': 0.53409714}
train | step:  15900 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.5148816,
     'losses/train_total_loss': 0.5148816}
train | step:  16000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.54316556,
     'losses/train_total_loss': 0.54316556}
saved checkpoint to results/exp_005/ckpt-16000.
train | step:  16100 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.49558076,
     'losses/train_total_loss': 0.49558076}
train | step:  16200 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.51997495,
     'losses/train_total_loss': 0.51997495}
train | step:  16300 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.49374053,
     'losses/train_total_loss': 0.49374053}
train | step:  16400 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.49512702,
     'losses/train_total_loss': 0.49512702}
train | step:  16500 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5333633,
     'losses/train_total_loss': 0.5333633}
train | step:  16600 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.5485572,
     'losses/train_total_loss': 0.5485572}
train | step:  16700 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.5174481,
     'losses/train_total_loss': 0.5174481}
train | step:  16800 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.5162253,
     'losses/train_total_loss': 0.5162253}
train | step:  16900 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.5137225,
     'losses/train_total_loss': 0.5137225}
train | step:  17000 | steps/sec:    1.4 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.52410936,
     'losses/train_total_loss': 0.52410936}
saved checkpoint to results/exp_005/ckpt-17000.
train | step:  17100 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.49707505,
     'losses/train_total_loss': 0.49707505}
train | step:  17200 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.50756365,
     'losses/train_total_loss': 0.50756365}
train | step:  17300 | steps/sec:    1.4 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.50850385,
     'losses/train_total_loss': 0.50850385}
train | step:  17400 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.5182993,
     'losses/train_total_loss': 0.5182993}
train | step:  17500 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.5076788,
     'losses/train_total_loss': 0.5076788}
train | step:  17600 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.5405957,
     'losses/train_total_loss': 0.5405957}I0915 04:04:52.137985 140385095513920 controller.py:466] train | step:  17700 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.49656135,
     'losses/train_total_loss': 0.49656135}
I0915 04:06:04.240863 140385095513920 controller.py:466] train | step:  17800 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.503112,
     'losses/train_total_loss': 0.503112}
I0915 04:07:16.853863 140385095513920 controller.py:466] train | step:  17900 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.4967082,
     'losses/train_total_loss': 0.4967082}
I0915 04:08:29.290427 140385095513920 controller.py:466] train | step:  18000 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.5065643,
     'losses/train_total_loss': 0.5065643}
I0915 04:08:30.003895 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-18000.
I0915 04:09:42.852879 140385095513920 controller.py:466] train | step:  18100 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.5040548,
     'losses/train_total_loss': 0.5040548}
I0915 04:10:54.762457 140385095513920 controller.py:466] train | step:  18200 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.49786934,
     'losses/train_total_loss': 0.49786934}
I0915 04:12:07.117670 140385095513920 controller.py:466] train | step:  18300 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.48874485,
     'losses/train_total_loss': 0.48874485}
I0915 04:13:20.019684 140385095513920 controller.py:466] train | step:  18400 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.47776237,
     'losses/train_total_loss': 0.47776237}
I0915 04:14:32.594333 140385095513920 controller.py:466] train | step:  18500 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.5096834,
     'losses/train_total_loss': 0.5096834}
I0915 04:15:44.913221 140385095513920 controller.py:466] train | step:  18600 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.516327,
     'losses/train_total_loss': 0.516327}
I0915 04:16:58.010002 140385095513920 controller.py:466] train | step:  18700 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.48999214,
     'losses/train_total_loss': 0.48999214}
I0915 04:18:11.076057 140385095513920 controller.py:466] train | step:  18800 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.48310384,
     'losses/train_total_loss': 0.48310384}
I0915 04:19:24.153021 140385095513920 controller.py:466] train | step:  18900 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.50246406,
     'losses/train_total_loss': 0.50246406}
I0915 04:20:36.231087 140385095513920 controller.py:466] train | step:  19000 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.49830806,
     'losses/train_total_loss': 0.49830806}
I0915 04:20:36.974685 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-19000.
I0915 04:21:49.565595 140385095513920 controller.py:466] train | step:  19100 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.52229345,
     'losses/train_total_loss': 0.52229345}
I0915 04:23:02.246016 140385095513920 controller.py:466] train | step:  19200 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.48335752,
     'losses/train_total_loss': 0.48335752}
I0915 04:24:15.097479 140385095513920 controller.py:466] train | step:  19300 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.5041233,
     'losses/train_total_loss': 0.5041233}
I0915 04:25:27.789072 140385095513920 controller.py:466] train | step:  19400 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.47476047,
     'losses/train_total_loss': 0.47476047}
I0915 04:26:39.959288 140385095513920 controller.py:466] train | step:  19500 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.49895352,
     'losses/train_total_loss': 0.49895352}
I0915 04:27:52.477074 140385095513920 controller.py:466] train | step:  19600 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.50065196,
     'losses/train_total_loss': 0.50065196}
I0915 04:29:05.060149 140385095513920 controller.py:466] train | step:  19700 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.49873015,
     'losses/train_total_loss': 0.49873015}
I0915 04:30:17.595012 140385095513920 controller.py:466] train | step:  19800 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.49200857,
     'losses/train_total_loss': 0.49200857}
I0915 04:31:30.056085 140385095513920 controller.py:466] train | step:  19900 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.4966116,
     'losses/train_total_loss': 0.4966116}
I0915 04:32:42.461993 140385095513920 controller.py:466] train | step:  20000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5104495,
     'losses/train_total_loss': 0.5104495}
I0915 04:32:43.219447 140385095513920 controller.py:495] saved checkpoint to results/exp_005/ckpt-20000.
I0915 04:32:43.220298 140385095513920 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0915 04:33:11.384549 140385095513920 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 04:33:11.417138 140385095513920 controller.py:295]  eval | step:  20000 | eval time:   28.2 sec | output: 
    {'evaluation/iou/IoU': 0.7377705,
     'losses/eval_semantic_loss': 0.43770328,
     'losses/eval_total_loss': 0.43770328}

train | step:  17700 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.49656135,
     'losses/train_total_loss': 0.49656135}
train | step:  17800 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.503112,
     'losses/train_total_loss': 0.503112}
train | step:  17900 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.4967082,
     'losses/train_total_loss': 0.4967082}
train | step:  18000 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.5065643,
     'losses/train_total_loss': 0.5065643}
saved checkpoint to results/exp_005/ckpt-18000.
train | step:  18100 | steps/sec:    1.4 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.5040548,
     'losses/train_total_loss': 0.5040548}
train | step:  18200 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.49786934,
     'losses/train_total_loss': 0.49786934}
train | step:  18300 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.48874485,
     'losses/train_total_loss': 0.48874485}
train | step:  18400 | steps/sec:    1.4 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.47776237,
     'losses/train_total_loss': 0.47776237}
train | step:  18500 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.5096834,
     'losses/train_total_loss': 0.5096834}
train | step:  18600 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.516327,
     'losses/train_total_loss': 0.516327}
train | step:  18700 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.48999214,
     'losses/train_total_loss': 0.48999214}
train | step:  18800 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.48310384,
     'losses/train_total_loss': 0.48310384}
train | step:  18900 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.50246406,
     'losses/train_total_loss': 0.50246406}
train | step:  19000 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.49830806,
     'losses/train_total_loss': 0.49830806}
saved checkpoint to results/exp_005/ckpt-19000.
train | step:  19100 | steps/sec:    1.4 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.52229345,
     'losses/train_total_loss': 0.52229345}
train | step:  19200 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.48335752,
     'losses/train_total_loss': 0.48335752}
train | step:  19300 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.5041233,
     'losses/train_total_loss': 0.5041233}
train | step:  19400 | steps/sec:    1.4 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.47476047,
     'losses/train_total_loss': 0.47476047}
train | step:  19500 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.49895352,
     'losses/train_total_loss': 0.49895352}
train | step:  19600 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.50065196,
     'losses/train_total_loss': 0.50065196}
train | step:  19700 | steps/sec:    1.4 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.49873015,
     'losses/train_total_loss': 0.49873015}
train | step:  19800 | steps/sec:    1.4 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.49200857,
     'losses/train_total_loss': 0.49200857}
train | step:  19900 | steps/sec:    1.4 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.4966116,
     'losses/train_total_loss': 0.4966116}
train | step:  20000 | steps/sec:    1.4 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5104495,
     'losses/train_total_loss': 0.5104495}
saved checkpoint to results/exp_005/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   28.2 sec | output: 
    {'evaluation/iou/IoU': 0.7377705,
     'losses/eval_semantic_loss': 0.43770328,
     'losses/eval_total_loss': 0.43770328}
