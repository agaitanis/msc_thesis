I0915 11:04:08.143094 140135745832768 train.py:65] Reading the config file.
I0915 11:04:08.144766 140135745832768 train.py:69] Starting the experiment.
2022-09-15 11:04:08.145173: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-15 11:04:08.517431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0915 11:04:08.519076 140135745832768 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0915 11:04:08.648869 140135745832768 deeplab.py:57] Synchronized Batchnorm is used.
I0915 11:04:08.649912 140135745832768 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0915 11:04:08.750443 140135745832768 deeplab.py:96] Setting pooling size to (33, 33)
I0915 11:04:08.750556 140135745832768 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 11:04:11.650744 140135745832768 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0915 11:04:11.665199 140135745832768 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0915 11:04:11.676171 140135745832768 controller.py:399] initialized model.
I0915 11:04:12.292161 140135745832768 api.py:447] Eval with scales ListWrapper([1.0])
I0915 11:04:13.156754 140135745832768 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 11:04:13.174859 140135745832768 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0915 11:04:16.066787 140135745832768 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 11:04:16.435033 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-0.
I0915 11:04:16.435627 140135745832768 controller.py:241] train | step:      0 | training until step 4000...
2022-09-15 11:04:35.013098: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0915 11:06:07.521565 140135745832768 controller.py:466] train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00019909976,
     'losses/train_semantic_loss': 1.1599737,
     'losses/train_total_loss': 1.1599737}
I0915 11:07:36.900025 140135745832768 controller.py:466] train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001981991,
     'losses/train_semantic_loss': 1.023988,
     'losses/train_total_loss': 1.023988}
I0915 11:09:07.826045 140135745832768 controller.py:466] train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019729795,
     'losses/train_semantic_loss': 0.97245926,
     'losses/train_total_loss': 0.97245926}
I0915 11:10:39.179771 140135745832768 controller.py:466] train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019639636,
     'losses/train_semantic_loss': 0.92764044,
     'losses/train_total_loss': 0.92764044}
I0915 11:12:10.830175 140135745832768 controller.py:466] train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019549433,
     'losses/train_semantic_loss': 0.9118816,
     'losses/train_total_loss': 0.9118816}
I0915 11:13:43.018934 140135745832768 controller.py:466] train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001945918,
     'losses/train_semantic_loss': 0.8963987,
     'losses/train_total_loss': 0.8963987}
I0915 11:15:15.033133 140135745832768 controller.py:466] train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019368883,
     'losses/train_semantic_loss': 0.8569774,
     'losses/train_total_loss': 0.8569774}
I0915 11:16:46.559139 140135745832768 controller.py:466] train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019278537,
     'losses/train_semantic_loss': 0.83542955,
     'losses/train_total_loss': 0.83542955}
I0915 11:18:17.962313 140135745832768 controller.py:466] train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019188147,
     'losses/train_semantic_loss': 0.81905484,
     'losses/train_total_loss': 0.81905484}
I0915 11:19:49.040303 140135745832768 controller.py:466] train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019097707,
     'losses/train_semantic_loss': 0.8210165,
     'losses/train_total_loss': 0.8210165}
I0915 11:19:49.835521 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-1000.
I0915 11:21:21.370475 140135745832768 controller.py:466] train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001900722,
     'losses/train_semantic_loss': 0.80101854,
     'losses/train_total_loss': 0.80101854}
I0915 11:22:53.160772 140135745832768 controller.py:466] train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018916687,
     'losses/train_semantic_loss': 0.80006266,
     'losses/train_total_loss': 0.80006266}
I0915 11:24:24.120051 140135745832768 controller.py:466] train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018826102,
     'losses/train_semantic_loss': 0.7860569,
     'losses/train_total_loss': 0.7860569}
I0915 11:25:55.771144 140135745832768 controller.py:466] train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018735472,
     'losses/train_semantic_loss': 0.78920656,
     'losses/train_total_loss': 0.78920656}
I0915 11:27:27.205013 140135745832768 controller.py:466] train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018644793,
     'losses/train_semantic_loss': 0.7784339,
     'losses/train_total_loss': 0.7784339}
I0915 11:28:58.806125 140135745832768 controller.py:466] train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018554063,
     'losses/train_semantic_loss': 0.7678462,
     'losses/train_total_loss': 0.7678462}
I0915 11:30:30.632001 140135745832768 controller.py:466] train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018463285,
     'losses/train_semantic_loss': 0.77602434,
     'losses/train_total_loss': 0.77602434}
I0915 11:32:02.398738 140135745832768 controller.py:466] train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018372457,
     'losses/train_semantic_loss': 0.7499517,
     'losses/train_total_loss': 0.7499517}
I0915 11:33:34.168112 140135745832768 controller.py:466] train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018281578,
     'losses/train_semantic_loss': 0.7403393,
     'losses/train_total_loss': 0.7403393}
I0915 11:35:05.824304 140135745832768 controller.py:466] train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018190651,
     'losses/train_semantic_loss': 0.7286661,
     'losses/train_total_loss': 0.7286661}
I0915 11:35:06.562017 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-2000.
I0915 11:36:38.345942 140135745832768 controller.py:466] train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018099672,
     'losses/train_semantic_loss': 0.7521641,
     'losses/train_total_loss': 0.7521641}
I0915 11:38:09.941722 140135745832768 controller.py:466] train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018008643,
     'losses/train_semantic_loss': 0.7514441,
     'losses/train_total_loss': 0.7514441}
I0915 11:39:41.456410 140135745832768 controller.py:466] train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017917564,
     'losses/train_semantic_loss': 0.7471148,
     'losses/train_total_loss': 0.7471148}
I0915 11:41:12.555083 140135745832768 controller.py:466] train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017826431,
     'losses/train_semantic_loss': 0.7443368,
     'losses/train_total_loss': 0.7443368}
I0915 11:42:43.165288 140135745832768 controller.py:466] train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017735246,
     'losses/train_semantic_loss': 0.72307205,
     'losses/train_total_loss': 0.72307205}
I0915 11:44:15.279659 140135745832768 controller.py:466] train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001764401,
     'losses/train_semantic_loss': 0.7417085,
     'losses/train_total_loss': 0.7417085}
I0915 11:45:47.057241 140135745832768 controller.py:466] train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017552721,
     'losses/train_semantic_loss': 0.7345281,
     'losses/train_total_loss': 0.7345281}
I0915 11:47:18.908653 140135745832768 controller.py:466] train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001746138,
     'losses/train_semantic_loss': 0.7277785,
     'losses/train_total_loss': 0.7277785}
I0915 11:48:51.016674 140135745832768 controller.py:466] train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017369987,
     'losses/train_semantic_loss': 0.7220543,
     'losses/train_total_loss': 0.7220543}
I0915 11:50:22.578741 140135745832768 controller.py:466] train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017278538,
     'losses/train_semantic_loss': 0.702388,
     'losses/train_total_loss': 0.702388}
I0915 11:50:23.563463 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-3000.
I0915 11:51:55.437389 140135745832768 controller.py:466] train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017187039,
     'losses/train_semantic_loss': 0.70170695,
     'losses/train_total_loss': 0.70170695}
I0915 11:53:27.498325 140135745832768 controller.py:466] train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017095482,
     'losses/train_semantic_loss': 0.70714736,
     'losses/train_total_loss': 0.70714736}
I0915 11:54:58.789842 140135745832768 controller.py:466] train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017003871,
     'losses/train_semantic_loss': 0.70815885,
     'losses/train_total_loss': 0.70815885}
I0915 11:56:29.689174 140135745832768 controller.py:466] train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016912205,
     'losses/train_semantic_loss': 0.69200516,
     'losses/train_total_loss': 0.69200516}
I0915 11:58:00.804863 140135745832768 controller.py:466] train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016820485,
     'losses/train_semantic_loss': 0.6781361,
     'losses/train_total_loss': 0.6781361}
I0915 11:59:32.424160 140135745832768 controller.py:466] train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001672871,
     'losses/train_semantic_loss': 0.67698133,
     'losses/train_total_loss': 0.67698133}
I0915 12:01:03.745343 140135745832768 controller.py:466] train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016636877,
     'losses/train_semantic_loss': 0.7153247,
     'losses/train_total_loss': 0.7153247}
I0915 12:02:35.106839 140135745832768 controller.py:466] train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001654499,
     'losses/train_semantic_loss': 0.69374,
     'losses/train_total_loss': 0.69374}
I0915 12:04:06.843677 140135745832768 controller.py:466] train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016453046,
     'losses/train_semantic_loss': 0.69918597,
     'losses/train_total_loss': 0.69918597}
I0915 12:05:37.740923 140135745832768 controller.py:466] train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016361041,
     'losses/train_semantic_loss': 0.7119119,
     'losses/train_total_loss': 0.7119119}
I0915 12:05:38.481591 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-4000.
I0915 12:05:38.489976 140135745832768 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0915 12:05:41.434762 140135745832768 api.py:447] Eval with scales ListWrapper([1.0])
I0915 12:05:41.463087 140135745832768 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 12:05:41.487722 140135745832768 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0915 12:05:42.124695 140135745832768 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0915 12:06:17.972829 140135745832768 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 12:06:18.019550 140135745832768 controller.py:295]  eval | step:   4000 | eval time:   39.5 sec | output: 
    {'evaluation/iou/IoU': 0.55728716,
     'losses/eval_semantic_loss': 0.80197793,
     'losses/eval_total_loss': 0.80197793}
I0915 12:06:18.026091 140135745832768 controller.py:241] train | step:   4000 | training until step 8000...
I0915 12:07:49.871695 140135745832768 controller.py:466] train | step:   4100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016268983,
     'losses/train_semantic_loss': 0.68851626,
     'losses/train_total_loss': 0.68851626}
I0915 12:09:21.487579 140135745832768 controller.py:466] train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016176865,
     'losses/train_semantic_loss': 0.6885994,
     'losses/train_total_loss': 0.6885994}
I0915 12:10:52.287388 140135745832768 controller.py:466] train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016084689,
     'losses/train_semantic_loss': 0.69371694,
     'losses/train_total_loss': 0.69371694}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_007/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00019909976,
     'losses/train_semantic_loss': 1.1599737,
     'losses/train_total_loss': 1.1599737}
train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001981991,
     'losses/train_semantic_loss': 1.023988,
     'losses/train_total_loss': 1.023988}
train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019729795,
     'losses/train_semantic_loss': 0.97245926,
     'losses/train_total_loss': 0.97245926}
train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019639636,
     'losses/train_semantic_loss': 0.92764044,
     'losses/train_total_loss': 0.92764044}
train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019549433,
     'losses/train_semantic_loss': 0.9118816,
     'losses/train_total_loss': 0.9118816}
train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001945918,
     'losses/train_semantic_loss': 0.8963987,
     'losses/train_total_loss': 0.8963987}
train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019368883,
     'losses/train_semantic_loss': 0.8569774,
     'losses/train_total_loss': 0.8569774}
train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019278537,
     'losses/train_semantic_loss': 0.83542955,
     'losses/train_total_loss': 0.83542955}
train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019188147,
     'losses/train_semantic_loss': 0.81905484,
     'losses/train_total_loss': 0.81905484}
train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019097707,
     'losses/train_semantic_loss': 0.8210165,
     'losses/train_total_loss': 0.8210165}
saved checkpoint to results/exp_007/ckpt-1000.
train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001900722,
     'losses/train_semantic_loss': 0.80101854,
     'losses/train_total_loss': 0.80101854}
train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018916687,
     'losses/train_semantic_loss': 0.80006266,
     'losses/train_total_loss': 0.80006266}
train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018826102,
     'losses/train_semantic_loss': 0.7860569,
     'losses/train_total_loss': 0.7860569}
train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018735472,
     'losses/train_semantic_loss': 0.78920656,
     'losses/train_total_loss': 0.78920656}
train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018644793,
     'losses/train_semantic_loss': 0.7784339,
     'losses/train_total_loss': 0.7784339}
train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018554063,
     'losses/train_semantic_loss': 0.7678462,
     'losses/train_total_loss': 0.7678462}
train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018463285,
     'losses/train_semantic_loss': 0.77602434,
     'losses/train_total_loss': 0.77602434}
train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018372457,
     'losses/train_semantic_loss': 0.7499517,
     'losses/train_total_loss': 0.7499517}
train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018281578,
     'losses/train_semantic_loss': 0.7403393,
     'losses/train_total_loss': 0.7403393}
train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018190651,
     'losses/train_semantic_loss': 0.7286661,
     'losses/train_total_loss': 0.7286661}
saved checkpoint to results/exp_007/ckpt-2000.
train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018099672,
     'losses/train_semantic_loss': 0.7521641,
     'losses/train_total_loss': 0.7521641}
train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018008643,
     'losses/train_semantic_loss': 0.7514441,
     'losses/train_total_loss': 0.7514441}
train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017917564,
     'losses/train_semantic_loss': 0.7471148,
     'losses/train_total_loss': 0.7471148}
train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017826431,
     'losses/train_semantic_loss': 0.7443368,
     'losses/train_total_loss': 0.7443368}
train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017735246,
     'losses/train_semantic_loss': 0.72307205,
     'losses/train_total_loss': 0.72307205}
train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001764401,
     'losses/train_semantic_loss': 0.7417085,
     'losses/train_total_loss': 0.7417085}
train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017552721,
     'losses/train_semantic_loss': 0.7345281,
     'losses/train_total_loss': 0.7345281}
train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001746138,
     'losses/train_semantic_loss': 0.7277785,
     'losses/train_total_loss': 0.7277785}
train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017369987,
     'losses/train_semantic_loss': 0.7220543,
     'losses/train_total_loss': 0.7220543}
train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017278538,
     'losses/train_semantic_loss': 0.702388,
     'losses/train_total_loss': 0.702388}
saved checkpoint to results/exp_007/ckpt-3000.
train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017187039,
     'losses/train_semantic_loss': 0.70170695,
     'losses/train_total_loss': 0.70170695}
train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017095482,
     'losses/train_semantic_loss': 0.70714736,
     'losses/train_total_loss': 0.70714736}
train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017003871,
     'losses/train_semantic_loss': 0.70815885,
     'losses/train_total_loss': 0.70815885}
train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016912205,
     'losses/train_semantic_loss': 0.69200516,
     'losses/train_total_loss': 0.69200516}
train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016820485,
     'losses/train_semantic_loss': 0.6781361,
     'losses/train_total_loss': 0.6781361}
train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001672871,
     'losses/train_semantic_loss': 0.67698133,
     'losses/train_total_loss': 0.67698133}
train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016636877,
     'losses/train_semantic_loss': 0.7153247,
     'losses/train_total_loss': 0.7153247}
train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001654499,
     'losses/train_semantic_loss': 0.69374,
     'losses/train_total_loss': 0.69374}
train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016453046,
     'losses/train_semantic_loss': 0.69918597,
     'losses/train_total_loss': 0.69918597}
train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016361041,
     'losses/train_semantic_loss': 0.7119119,
     'losses/train_total_loss': 0.7119119}
saved checkpoint to results/exp_007/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   39.5 sec | output: 
    {'evaluation/iou/IoU': 0.55728716,
     'losses/eval_semantic_loss': 0.80197793,
     'losses/eval_total_loss': 0.80197793}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016268983,
     'losses/train_semantic_loss': 0.68851626,
     'losses/train_total_loss': 0.68851626}
train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016176865,
     'losses/train_semantic_loss': 0.6885994,
     'losses/train_total_loss': 0.6885994}
train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016084689,
     'losses/train_semantic_loss': 0.69371694,
     'losses/train_total_loss': 0.69371694}I0915 12:12:23.670516 140135745832768 controller.py:466] train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015992454,
     'losses/train_semantic_loss': 0.6863186,
     'losses/train_total_loss': 0.6863186}
I0915 12:13:55.278378 140135745832768 controller.py:466] train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001590016,
     'losses/train_semantic_loss': 0.6774193,
     'losses/train_total_loss': 0.6774193}
I0915 12:15:26.582591 140135745832768 controller.py:466] train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015807807,
     'losses/train_semantic_loss': 0.6797478,
     'losses/train_total_loss': 0.6797478}
I0915 12:16:57.666059 140135745832768 controller.py:466] train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015715393,
     'losses/train_semantic_loss': 0.6599808,
     'losses/train_total_loss': 0.6599808}
I0915 12:18:29.142106 140135745832768 controller.py:466] train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015622919,
     'losses/train_semantic_loss': 0.66200775,
     'losses/train_total_loss': 0.66200775}
I0915 12:20:00.877753 140135745832768 controller.py:466] train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015530387,
     'losses/train_semantic_loss': 0.66643524,
     'losses/train_total_loss': 0.66643524}
I0915 12:21:32.583123 140135745832768 controller.py:466] train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015437789,
     'losses/train_semantic_loss': 0.66606337,
     'losses/train_total_loss': 0.66606337}
I0915 12:21:33.415114 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-5000.
I0915 12:23:05.031602 140135745832768 controller.py:466] train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015345131,
     'losses/train_semantic_loss': 0.6467726,
     'losses/train_total_loss': 0.6467726}
I0915 12:24:36.821215 140135745832768 controller.py:466] train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015252412,
     'losses/train_semantic_loss': 0.6351966,
     'losses/train_total_loss': 0.6351966}
I0915 12:26:08.740344 140135745832768 controller.py:466] train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001515963,
     'losses/train_semantic_loss': 0.6509663,
     'losses/train_total_loss': 0.6509663}
I0915 12:27:39.608399 140135745832768 controller.py:466] train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015066784,
     'losses/train_semantic_loss': 0.6652427,
     'losses/train_total_loss': 0.6652427}
I0915 12:29:10.245186 140135745832768 controller.py:466] train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014973874,
     'losses/train_semantic_loss': 0.63961595,
     'losses/train_total_loss': 0.63961595}
I0915 12:30:41.693522 140135745832768 controller.py:466] train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000148809,
     'losses/train_semantic_loss': 0.6616649,
     'losses/train_total_loss': 0.6616649}
I0915 12:32:13.551163 140135745832768 controller.py:466] train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014787863,
     'losses/train_semantic_loss': 0.65356016,
     'losses/train_total_loss': 0.65356016}
I0915 12:33:45.117343 140135745832768 controller.py:466] train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014694761,
     'losses/train_semantic_loss': 0.65521985,
     'losses/train_total_loss': 0.65521985}
I0915 12:35:16.304483 140135745832768 controller.py:466] train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014601591,
     'losses/train_semantic_loss': 0.6493767,
     'losses/train_total_loss': 0.6493767}
I0915 12:36:47.717302 140135745832768 controller.py:466] train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014508357,
     'losses/train_semantic_loss': 0.6737933,
     'losses/train_total_loss': 0.6737933}
I0915 12:36:48.644199 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-6000.
I0915 12:38:20.674697 140135745832768 controller.py:466] train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014415054,
     'losses/train_semantic_loss': 0.64279056,
     'losses/train_total_loss': 0.64279056}
I0915 12:39:52.872136 140135745832768 controller.py:466] train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014321688,
     'losses/train_semantic_loss': 0.65174973,
     'losses/train_total_loss': 0.65174973}
I0915 12:41:24.135769 140135745832768 controller.py:466] train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001422825,
     'losses/train_semantic_loss': 0.6177112,
     'losses/train_total_loss': 0.6177112}
I0915 12:42:56.243890 140135745832768 controller.py:466] train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014134747,
     'losses/train_semantic_loss': 0.6429892,
     'losses/train_total_loss': 0.6429892}
I0915 12:44:28.239629 140135745832768 controller.py:466] train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014041172,
     'losses/train_semantic_loss': 0.6259548,
     'losses/train_total_loss': 0.6259548}
I0915 12:46:00.237426 140135745832768 controller.py:466] train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013947528,
     'losses/train_semantic_loss': 0.63593584,
     'losses/train_total_loss': 0.63593584}
I0915 12:47:32.080896 140135745832768 controller.py:466] train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013853816,
     'losses/train_semantic_loss': 0.6232891,
     'losses/train_total_loss': 0.6232891}
I0915 12:49:03.805830 140135745832768 controller.py:466] train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013760033,
     'losses/train_semantic_loss': 0.6504863,
     'losses/train_total_loss': 0.6504863}
I0915 12:50:35.875016 140135745832768 controller.py:466] train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001366618,
     'losses/train_semantic_loss': 0.62997,
     'losses/train_total_loss': 0.62997}
I0915 12:52:07.079110 140135745832768 controller.py:466] train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013572254,
     'losses/train_semantic_loss': 0.63110673,
     'losses/train_total_loss': 0.63110673}
I0915 12:52:07.797474 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-7000.
I0915 12:53:39.424070 140135745832768 controller.py:466] train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013478257,
     'losses/train_semantic_loss': 0.663414,
     'losses/train_total_loss': 0.663414}
I0915 12:55:11.034654 140135745832768 controller.py:466] train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013384185,
     'losses/train_semantic_loss': 0.61357754,
     'losses/train_total_loss': 0.61357754}
I0915 12:56:42.473902 140135745832768 controller.py:466] train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013290042,
     'losses/train_semantic_loss': 0.61498606,
     'losses/train_total_loss': 0.61498606}
I0915 12:58:14.275249 140135745832768 controller.py:466] train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013195824,
     'losses/train_semantic_loss': 0.613628,
     'losses/train_total_loss': 0.613628}
I0915 12:59:46.083045 140135745832768 controller.py:466] train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001310153,
     'losses/train_semantic_loss': 0.61731756,
     'losses/train_total_loss': 0.61731756}
I0915 13:01:17.170578 140135745832768 controller.py:466] train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013007161,
     'losses/train_semantic_loss': 0.6122244,
     'losses/train_total_loss': 0.6122244}
I0915 13:02:48.712149 140135745832768 controller.py:466] train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012912715,
     'losses/train_semantic_loss': 0.6179569,
     'losses/train_total_loss': 0.6179569}
I0915 13:04:20.619237 140135745832768 controller.py:466] train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012818194,
     'losses/train_semantic_loss': 0.6140578,
     'losses/train_total_loss': 0.6140578}
I0915 13:05:51.722029 140135745832768 controller.py:466] train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012723595,
     'losses/train_semantic_loss': 0.6326749,
     'losses/train_total_loss': 0.6326749}
I0915 13:07:23.029548 140135745832768 controller.py:466] train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012628917,
     'losses/train_semantic_loss': 0.62207854,
     'losses/train_total_loss': 0.62207854}
I0915 13:07:23.713913 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-8000.
I0915 13:07:23.714495 140135745832768 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0915 13:07:58.226169 140135745832768 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 13:07:58.231065 140135745832768 controller.py:295]  eval | step:   8000 | eval time:   34.5 sec | output: 
    {'evaluation/iou/IoU': 0.67009574,
     'losses/eval_semantic_loss': 0.65808946,
     'losses/eval_total_loss': 0.65808946}
I0915 13:07:58.237219 140135745832768 controller.py:241] train | step:   8000 | training until step 12000...
I0915 13:09:29.602155 140135745832768 controller.py:466] train | step:   8100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00012534161,
     'losses/train_semantic_loss': 0.5921997,
     'losses/train_total_loss': 0.5921997}
I0915 13:11:01.461085 140135745832768 controller.py:466] train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012439325,
     'losses/train_semantic_loss': 0.6123323,
     'losses/train_total_loss': 0.6123323}
I0915 13:12:32.538033 140135745832768 controller.py:466] train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012344407,
     'losses/train_semantic_loss': 0.6035533,
     'losses/train_total_loss': 0.6035533}
I0915 13:14:03.983206 140135745832768 controller.py:466] train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012249411,
     'losses/train_semantic_loss': 0.60301566,
     'losses/train_total_loss': 0.60301566}
I0915 13:15:35.378439 140135745832768 controller.py:466] train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012154331,
     'losses/train_semantic_loss': 0.59997743,
     'losses/train_total_loss': 0.59997743}
I0915 13:17:06.833801 140135745832768 controller.py:466] train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000120591685,
     'losses/train_semantic_loss': 0.5955988,
     'losses/train_total_loss': 0.5955988}
I0915 13:18:38.234443 140135745832768 controller.py:466] train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000119639226,
     'losses/train_semantic_loss': 0.6252657,
     'losses/train_total_loss': 0.6252657}

train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015992454,
     'losses/train_semantic_loss': 0.6863186,
     'losses/train_total_loss': 0.6863186}
train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001590016,
     'losses/train_semantic_loss': 0.6774193,
     'losses/train_total_loss': 0.6774193}
train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015807807,
     'losses/train_semantic_loss': 0.6797478,
     'losses/train_total_loss': 0.6797478}
train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015715393,
     'losses/train_semantic_loss': 0.6599808,
     'losses/train_total_loss': 0.6599808}
train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015622919,
     'losses/train_semantic_loss': 0.66200775,
     'losses/train_total_loss': 0.66200775}
train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015530387,
     'losses/train_semantic_loss': 0.66643524,
     'losses/train_total_loss': 0.66643524}
train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015437789,
     'losses/train_semantic_loss': 0.66606337,
     'losses/train_total_loss': 0.66606337}
saved checkpoint to results/exp_007/ckpt-5000.
train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015345131,
     'losses/train_semantic_loss': 0.6467726,
     'losses/train_total_loss': 0.6467726}
train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015252412,
     'losses/train_semantic_loss': 0.6351966,
     'losses/train_total_loss': 0.6351966}
train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001515963,
     'losses/train_semantic_loss': 0.6509663,
     'losses/train_total_loss': 0.6509663}
train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015066784,
     'losses/train_semantic_loss': 0.6652427,
     'losses/train_total_loss': 0.6652427}
train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014973874,
     'losses/train_semantic_loss': 0.63961595,
     'losses/train_total_loss': 0.63961595}
train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000148809,
     'losses/train_semantic_loss': 0.6616649,
     'losses/train_total_loss': 0.6616649}
train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014787863,
     'losses/train_semantic_loss': 0.65356016,
     'losses/train_total_loss': 0.65356016}
train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014694761,
     'losses/train_semantic_loss': 0.65521985,
     'losses/train_total_loss': 0.65521985}
train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014601591,
     'losses/train_semantic_loss': 0.6493767,
     'losses/train_total_loss': 0.6493767}
train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014508357,
     'losses/train_semantic_loss': 0.6737933,
     'losses/train_total_loss': 0.6737933}
saved checkpoint to results/exp_007/ckpt-6000.
train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014415054,
     'losses/train_semantic_loss': 0.64279056,
     'losses/train_total_loss': 0.64279056}
train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014321688,
     'losses/train_semantic_loss': 0.65174973,
     'losses/train_total_loss': 0.65174973}
train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001422825,
     'losses/train_semantic_loss': 0.6177112,
     'losses/train_total_loss': 0.6177112}
train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014134747,
     'losses/train_semantic_loss': 0.6429892,
     'losses/train_total_loss': 0.6429892}
train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014041172,
     'losses/train_semantic_loss': 0.6259548,
     'losses/train_total_loss': 0.6259548}
train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013947528,
     'losses/train_semantic_loss': 0.63593584,
     'losses/train_total_loss': 0.63593584}
train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013853816,
     'losses/train_semantic_loss': 0.6232891,
     'losses/train_total_loss': 0.6232891}
train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013760033,
     'losses/train_semantic_loss': 0.6504863,
     'losses/train_total_loss': 0.6504863}
train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001366618,
     'losses/train_semantic_loss': 0.62997,
     'losses/train_total_loss': 0.62997}
train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013572254,
     'losses/train_semantic_loss': 0.63110673,
     'losses/train_total_loss': 0.63110673}
saved checkpoint to results/exp_007/ckpt-7000.
train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013478257,
     'losses/train_semantic_loss': 0.663414,
     'losses/train_total_loss': 0.663414}
train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013384185,
     'losses/train_semantic_loss': 0.61357754,
     'losses/train_total_loss': 0.61357754}
train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013290042,
     'losses/train_semantic_loss': 0.61498606,
     'losses/train_total_loss': 0.61498606}
train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013195824,
     'losses/train_semantic_loss': 0.613628,
     'losses/train_total_loss': 0.613628}
train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001310153,
     'losses/train_semantic_loss': 0.61731756,
     'losses/train_total_loss': 0.61731756}
train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013007161,
     'losses/train_semantic_loss': 0.6122244,
     'losses/train_total_loss': 0.6122244}
train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012912715,
     'losses/train_semantic_loss': 0.6179569,
     'losses/train_total_loss': 0.6179569}
train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012818194,
     'losses/train_semantic_loss': 0.6140578,
     'losses/train_total_loss': 0.6140578}
train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012723595,
     'losses/train_semantic_loss': 0.6326749,
     'losses/train_total_loss': 0.6326749}
train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012628917,
     'losses/train_semantic_loss': 0.62207854,
     'losses/train_total_loss': 0.62207854}
saved checkpoint to results/exp_007/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   34.5 sec | output: 
    {'evaluation/iou/IoU': 0.67009574,
     'losses/eval_semantic_loss': 0.65808946,
     'losses/eval_total_loss': 0.65808946}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00012534161,
     'losses/train_semantic_loss': 0.5921997,
     'losses/train_total_loss': 0.5921997}
train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012439325,
     'losses/train_semantic_loss': 0.6123323,
     'losses/train_total_loss': 0.6123323}
train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012344407,
     'losses/train_semantic_loss': 0.6035533,
     'losses/train_total_loss': 0.6035533}
train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012249411,
     'losses/train_semantic_loss': 0.60301566,
     'losses/train_total_loss': 0.60301566}
train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012154331,
     'losses/train_semantic_loss': 0.59997743,
     'losses/train_total_loss': 0.59997743}
train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000120591685,
     'losses/train_semantic_loss': 0.5955988,
     'losses/train_total_loss': 0.5955988}
train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000119639226,
     'losses/train_semantic_loss': 0.6252657,
     'losses/train_total_loss': 0.6252657}I0915 13:20:09.752358 140135745832768 controller.py:466] train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011868592,
     'losses/train_semantic_loss': 0.5820837,
     'losses/train_total_loss': 0.5820837}
I0915 13:21:41.586326 140135745832768 controller.py:466] train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011773177,
     'losses/train_semantic_loss': 0.59267133,
     'losses/train_total_loss': 0.59267133}
I0915 13:23:13.225075 140135745832768 controller.py:466] train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011677675,
     'losses/train_semantic_loss': 0.61411726,
     'losses/train_total_loss': 0.61411726}
I0915 13:23:13.881601 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-9000.
I0915 13:24:44.884972 140135745832768 controller.py:466] train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011582087,
     'losses/train_semantic_loss': 0.5996678,
     'losses/train_total_loss': 0.5996678}
I0915 13:26:16.823521 140135745832768 controller.py:466] train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011486411,
     'losses/train_semantic_loss': 0.6205385,
     'losses/train_total_loss': 0.6205385}
I0915 13:27:47.766286 140135745832768 controller.py:466] train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011390646,
     'losses/train_semantic_loss': 0.598239,
     'losses/train_total_loss': 0.598239}
I0915 13:29:19.263101 140135745832768 controller.py:466] train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011294793,
     'losses/train_semantic_loss': 0.59321195,
     'losses/train_total_loss': 0.59321195}
I0915 13:30:51.231543 140135745832768 controller.py:466] train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011198847,
     'losses/train_semantic_loss': 0.5873182,
     'losses/train_total_loss': 0.5873182}
I0915 13:32:23.234274 140135745832768 controller.py:466] train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011102812,
     'losses/train_semantic_loss': 0.55193937,
     'losses/train_total_loss': 0.55193937}
I0915 13:33:55.009425 140135745832768 controller.py:466] train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011006683,
     'losses/train_semantic_loss': 0.585047,
     'losses/train_total_loss': 0.585047}
I0915 13:35:26.590404 140135745832768 controller.py:466] train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010910462,
     'losses/train_semantic_loss': 0.6168122,
     'losses/train_total_loss': 0.6168122}
I0915 13:36:58.436768 140135745832768 controller.py:466] train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010814145,
     'losses/train_semantic_loss': 0.59498686,
     'losses/train_total_loss': 0.59498686}
I0915 13:38:30.954686 140135745832768 controller.py:466] train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010717735,
     'losses/train_semantic_loss': 0.57587224,
     'losses/train_total_loss': 0.57587224}
I0915 13:38:31.782443 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-10000.
I0915 13:40:02.886069 140135745832768 controller.py:466] train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010621227,
     'losses/train_semantic_loss': 0.5900979,
     'losses/train_total_loss': 0.5900979}
I0915 13:41:34.600285 140135745832768 controller.py:466] train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010524621,
     'losses/train_semantic_loss': 0.5982217,
     'losses/train_total_loss': 0.5982217}
I0915 13:43:06.612538 140135745832768 controller.py:466] train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010427917,
     'losses/train_semantic_loss': 0.59808266,
     'losses/train_total_loss': 0.59808266}
I0915 13:44:38.161760 140135745832768 controller.py:466] train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010331113,
     'losses/train_semantic_loss': 0.6017285,
     'losses/train_total_loss': 0.6017285}
I0915 13:46:09.912187 140135745832768 controller.py:466] train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010234208,
     'losses/train_semantic_loss': 0.59366244,
     'losses/train_total_loss': 0.59366244}
I0915 13:47:41.823607 140135745832768 controller.py:466] train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010137201,
     'losses/train_semantic_loss': 0.5573052,
     'losses/train_total_loss': 0.5573052}
I0915 13:49:13.881712 140135745832768 controller.py:466] train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010040091,
     'losses/train_semantic_loss': 0.60090244,
     'losses/train_total_loss': 0.60090244}
I0915 13:50:46.100657 140135745832768 controller.py:466] train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.942876e-05,
     'losses/train_semantic_loss': 0.57521176,
     'losses/train_total_loss': 0.57521176}
I0915 13:52:17.683794 140135745832768 controller.py:466] train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.845556e-05,
     'losses/train_semantic_loss': 0.580272,
     'losses/train_total_loss': 0.580272}
I0915 13:53:48.616779 140135745832768 controller.py:466] train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.748128e-05,
     'losses/train_semantic_loss': 0.54571986,
     'losses/train_total_loss': 0.54571986}
I0915 13:53:49.251365 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-11000.
I0915 13:55:21.347108 140135745832768 controller.py:466] train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.650593e-05,
     'losses/train_semantic_loss': 0.56526476,
     'losses/train_total_loss': 0.56526476}
I0915 13:56:53.767524 140135745832768 controller.py:466] train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.5529474e-05,
     'losses/train_semantic_loss': 0.5765691,
     'losses/train_total_loss': 0.5765691}
I0915 13:58:25.926634 140135745832768 controller.py:466] train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.455192e-05,
     'losses/train_semantic_loss': 0.5764597,
     'losses/train_total_loss': 0.5764597}
I0915 13:59:58.082188 140135745832768 controller.py:466] train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.3573224e-05,
     'losses/train_semantic_loss': 0.5621737,
     'losses/train_total_loss': 0.5621737}
I0915 14:01:29.838998 140135745832768 controller.py:466] train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.25934e-05,
     'losses/train_semantic_loss': 0.54963607,
     'losses/train_total_loss': 0.54963607}
I0915 14:03:01.483783 140135745832768 controller.py:466] train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.161242e-05,
     'losses/train_semantic_loss': 0.56620497,
     'losses/train_total_loss': 0.56620497}
I0915 14:04:33.510002 140135745832768 controller.py:466] train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.063028e-05,
     'losses/train_semantic_loss': 0.5640556,
     'losses/train_total_loss': 0.5640556}
I0915 14:06:04.231821 140135745832768 controller.py:466] train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.964694e-05,
     'losses/train_semantic_loss': 0.5681908,
     'losses/train_total_loss': 0.5681908}
I0915 14:07:35.389415 140135745832768 controller.py:466] train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.8662404e-05,
     'losses/train_semantic_loss': 0.5653916,
     'losses/train_total_loss': 0.5653916}
I0915 14:09:07.150152 140135745832768 controller.py:466] train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.767666e-05,
     'losses/train_semantic_loss': 0.56362957,
     'losses/train_total_loss': 0.56362957}
I0915 14:09:08.334381 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-12000.
I0915 14:09:08.335711 140135745832768 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0915 14:09:43.902355 140135745832768 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 14:09:43.906380 140135745832768 controller.py:295]  eval | step:  12000 | eval time:   35.6 sec | output: 
    {'evaluation/iou/IoU': 0.6980063,
     'losses/eval_semantic_loss': 0.4909409,
     'losses/eval_total_loss': 0.4909409}
I0915 14:09:43.911701 140135745832768 controller.py:241] train | step:  12000 | training until step 16000...
I0915 14:11:14.335728 140135745832768 controller.py:466] train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 8.6689666e-05,
     'losses/train_semantic_loss': 0.5644674,
     'losses/train_total_loss': 0.5644674}
I0915 14:12:45.012427 140135745832768 controller.py:466] train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.570144e-05,
     'losses/train_semantic_loss': 0.5667823,
     'losses/train_total_loss': 0.5667823}
I0915 14:14:16.479148 140135745832768 controller.py:466] train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.4711945e-05,
     'losses/train_semantic_loss': 0.5633735,
     'losses/train_total_loss': 0.5633735}
I0915 14:15:47.915440 140135745832768 controller.py:466] train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.3721156e-05,
     'losses/train_semantic_loss': 0.5799515,
     'losses/train_total_loss': 0.5799515}
I0915 14:17:20.172865 140135745832768 controller.py:466] train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.2729064e-05,
     'losses/train_semantic_loss': 0.5542938,
     'losses/train_total_loss': 0.5542938}
I0915 14:18:50.790493 140135745832768 controller.py:466] train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.173565e-05,
     'losses/train_semantic_loss': 0.56562173,
     'losses/train_total_loss': 0.56562173}
I0915 14:20:22.051328 140135745832768 controller.py:466] train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.0740894e-05,
     'losses/train_semantic_loss': 0.551231,
     'losses/train_total_loss': 0.551231}
I0915 14:21:53.461490 140135745832768 controller.py:466] train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.974478e-05,
     'losses/train_semantic_loss': 0.57338566,
     'losses/train_total_loss': 0.57338566}
I0915 14:23:25.474248 140135745832768 controller.py:466] train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.874727e-05,
     'losses/train_semantic_loss': 0.5931735,
     'losses/train_total_loss': 0.5931735}
I0915 14:24:57.512757 140135745832768 controller.py:466] train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.7748366e-05,
     'losses/train_semantic_loss': 0.5409052,
     'losses/train_total_loss': 0.5409052}
I0915 14:24:58.175081 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-13000.
I0915 14:26:29.628982 140135745832768 controller.py:466] train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.674802e-05,
     'losses/train_semantic_loss': 0.55600625,
     'losses/train_total_loss': 0.55600625}

train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011868592,
     'losses/train_semantic_loss': 0.5820837,
     'losses/train_total_loss': 0.5820837}
train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011773177,
     'losses/train_semantic_loss': 0.59267133,
     'losses/train_total_loss': 0.59267133}
train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011677675,
     'losses/train_semantic_loss': 0.61411726,
     'losses/train_total_loss': 0.61411726}
saved checkpoint to results/exp_007/ckpt-9000.
train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011582087,
     'losses/train_semantic_loss': 0.5996678,
     'losses/train_total_loss': 0.5996678}
train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011486411,
     'losses/train_semantic_loss': 0.6205385,
     'losses/train_total_loss': 0.6205385}
train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011390646,
     'losses/train_semantic_loss': 0.598239,
     'losses/train_total_loss': 0.598239}
train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011294793,
     'losses/train_semantic_loss': 0.59321195,
     'losses/train_total_loss': 0.59321195}
train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011198847,
     'losses/train_semantic_loss': 0.5873182,
     'losses/train_total_loss': 0.5873182}
train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011102812,
     'losses/train_semantic_loss': 0.55193937,
     'losses/train_total_loss': 0.55193937}
train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011006683,
     'losses/train_semantic_loss': 0.585047,
     'losses/train_total_loss': 0.585047}
train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010910462,
     'losses/train_semantic_loss': 0.6168122,
     'losses/train_total_loss': 0.6168122}
train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010814145,
     'losses/train_semantic_loss': 0.59498686,
     'losses/train_total_loss': 0.59498686}
train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010717735,
     'losses/train_semantic_loss': 0.57587224,
     'losses/train_total_loss': 0.57587224}
saved checkpoint to results/exp_007/ckpt-10000.
train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010621227,
     'losses/train_semantic_loss': 0.5900979,
     'losses/train_total_loss': 0.5900979}
train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010524621,
     'losses/train_semantic_loss': 0.5982217,
     'losses/train_total_loss': 0.5982217}
train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010427917,
     'losses/train_semantic_loss': 0.59808266,
     'losses/train_total_loss': 0.59808266}
train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010331113,
     'losses/train_semantic_loss': 0.6017285,
     'losses/train_total_loss': 0.6017285}
train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010234208,
     'losses/train_semantic_loss': 0.59366244,
     'losses/train_total_loss': 0.59366244}
train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010137201,
     'losses/train_semantic_loss': 0.5573052,
     'losses/train_total_loss': 0.5573052}
train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010040091,
     'losses/train_semantic_loss': 0.60090244,
     'losses/train_total_loss': 0.60090244}
train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.942876e-05,
     'losses/train_semantic_loss': 0.57521176,
     'losses/train_total_loss': 0.57521176}
train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.845556e-05,
     'losses/train_semantic_loss': 0.580272,
     'losses/train_total_loss': 0.580272}
train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.748128e-05,
     'losses/train_semantic_loss': 0.54571986,
     'losses/train_total_loss': 0.54571986}
saved checkpoint to results/exp_007/ckpt-11000.
train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.650593e-05,
     'losses/train_semantic_loss': 0.56526476,
     'losses/train_total_loss': 0.56526476}
train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.5529474e-05,
     'losses/train_semantic_loss': 0.5765691,
     'losses/train_total_loss': 0.5765691}
train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.455192e-05,
     'losses/train_semantic_loss': 0.5764597,
     'losses/train_total_loss': 0.5764597}
train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.3573224e-05,
     'losses/train_semantic_loss': 0.5621737,
     'losses/train_total_loss': 0.5621737}
train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.25934e-05,
     'losses/train_semantic_loss': 0.54963607,
     'losses/train_total_loss': 0.54963607}
train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.161242e-05,
     'losses/train_semantic_loss': 0.56620497,
     'losses/train_total_loss': 0.56620497}
train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.063028e-05,
     'losses/train_semantic_loss': 0.5640556,
     'losses/train_total_loss': 0.5640556}
train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.964694e-05,
     'losses/train_semantic_loss': 0.5681908,
     'losses/train_total_loss': 0.5681908}
train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.8662404e-05,
     'losses/train_semantic_loss': 0.5653916,
     'losses/train_total_loss': 0.5653916}
train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.767666e-05,
     'losses/train_semantic_loss': 0.56362957,
     'losses/train_total_loss': 0.56362957}
saved checkpoint to results/exp_007/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   35.6 sec | output: 
    {'evaluation/iou/IoU': 0.6980063,
     'losses/eval_semantic_loss': 0.4909409,
     'losses/eval_total_loss': 0.4909409}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 8.6689666e-05,
     'losses/train_semantic_loss': 0.5644674,
     'losses/train_total_loss': 0.5644674}
train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.570144e-05,
     'losses/train_semantic_loss': 0.5667823,
     'losses/train_total_loss': 0.5667823}
train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.4711945e-05,
     'losses/train_semantic_loss': 0.5633735,
     'losses/train_total_loss': 0.5633735}
train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.3721156e-05,
     'losses/train_semantic_loss': 0.5799515,
     'losses/train_total_loss': 0.5799515}
train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.2729064e-05,
     'losses/train_semantic_loss': 0.5542938,
     'losses/train_total_loss': 0.5542938}
train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.173565e-05,
     'losses/train_semantic_loss': 0.56562173,
     'losses/train_total_loss': 0.56562173}
train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.0740894e-05,
     'losses/train_semantic_loss': 0.551231,
     'losses/train_total_loss': 0.551231}
train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.974478e-05,
     'losses/train_semantic_loss': 0.57338566,
     'losses/train_total_loss': 0.57338566}
train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.874727e-05,
     'losses/train_semantic_loss': 0.5931735,
     'losses/train_total_loss': 0.5931735}
train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.7748366e-05,
     'losses/train_semantic_loss': 0.5409052,
     'losses/train_total_loss': 0.5409052}
saved checkpoint to results/exp_007/ckpt-13000.
train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.674802e-05,
     'losses/train_semantic_loss': 0.55600625,
     'losses/train_total_loss': 0.55600625}I0915 14:28:01.363440 140135745832768 controller.py:466] train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.5746226e-05,
     'losses/train_semantic_loss': 0.5549141,
     'losses/train_total_loss': 0.5549141}
I0915 14:29:33.035317 140135745832768 controller.py:466] train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.474296e-05,
     'losses/train_semantic_loss': 0.5470343,
     'losses/train_total_loss': 0.5470343}
I0915 14:31:04.953783 140135745832768 controller.py:466] train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.37382e-05,
     'losses/train_semantic_loss': 0.5611769,
     'losses/train_total_loss': 0.5611769}
I0915 14:32:36.900788 140135745832768 controller.py:466] train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.273191e-05,
     'losses/train_semantic_loss': 0.5642922,
     'losses/train_total_loss': 0.5642922}
I0915 14:34:08.257456 140135745832768 controller.py:466] train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.172408e-05,
     'losses/train_semantic_loss': 0.55181026,
     'losses/train_total_loss': 0.55181026}
I0915 14:35:39.468404 140135745832768 controller.py:466] train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.071466e-05,
     'losses/train_semantic_loss': 0.5486523,
     'losses/train_total_loss': 0.5486523}
I0915 14:37:11.245064 140135745832768 controller.py:466] train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.9703645e-05,
     'losses/train_semantic_loss': 0.54194045,
     'losses/train_total_loss': 0.54194045}
I0915 14:38:42.257496 140135745832768 controller.py:466] train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.8691e-05,
     'losses/train_semantic_loss': 0.5433346,
     'losses/train_total_loss': 0.5433346}
I0915 14:40:14.291801 140135745832768 controller.py:466] train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.7676694e-05,
     'losses/train_semantic_loss': 0.5506973,
     'losses/train_total_loss': 0.5506973}
I0915 14:40:15.093634 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-14000.
I0915 14:41:46.921395 140135745832768 controller.py:466] train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.666069e-05,
     'losses/train_semantic_loss': 0.51926553,
     'losses/train_total_loss': 0.51926553}
I0915 14:43:18.991877 140135745832768 controller.py:466] train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.564298e-05,
     'losses/train_semantic_loss': 0.54429215,
     'losses/train_total_loss': 0.54429215}
I0915 14:44:51.143060 140135745832768 controller.py:466] train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.462349e-05,
     'losses/train_semantic_loss': 0.5241719,
     'losses/train_total_loss': 0.5241719}
I0915 14:46:22.194208 140135745832768 controller.py:466] train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.360221e-05,
     'losses/train_semantic_loss': 0.56026405,
     'losses/train_total_loss': 0.56026405}
I0915 14:47:53.951834 140135745832768 controller.py:466] train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.2579114e-05,
     'losses/train_semantic_loss': 0.535636,
     'losses/train_total_loss': 0.535636}
I0915 14:49:24.482065 140135745832768 controller.py:466] train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.155415e-05,
     'losses/train_semantic_loss': 0.5630701,
     'losses/train_total_loss': 0.5630701}
I0915 14:50:55.519963 140135745832768 controller.py:466] train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.0527287e-05,
     'losses/train_semantic_loss': 0.5252714,
     'losses/train_total_loss': 0.5252714}
I0915 14:52:26.791224 140135745832768 controller.py:466] train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.9498492e-05,
     'losses/train_semantic_loss': 0.54721075,
     'losses/train_total_loss': 0.54721075}
I0915 14:53:58.626245 140135745832768 controller.py:466] train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.8467715e-05,
     'losses/train_semantic_loss': 0.53869706,
     'losses/train_total_loss': 0.53869706}
I0915 14:55:30.561681 140135745832768 controller.py:466] train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.743492e-05,
     'losses/train_semantic_loss': 0.55430144,
     'losses/train_total_loss': 0.55430144}
I0915 14:55:31.753337 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-15000.
I0915 14:57:03.539620 140135745832768 controller.py:466] train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.6400055e-05,
     'losses/train_semantic_loss': 0.5406998,
     'losses/train_total_loss': 0.5406998}
I0915 14:58:34.388234 140135745832768 controller.py:466] train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.536307e-05,
     'losses/train_semantic_loss': 0.5213672,
     'losses/train_total_loss': 0.5213672}
I0915 15:00:05.908643 140135745832768 controller.py:466] train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.4323922e-05,
     'losses/train_semantic_loss': 0.5337222,
     'losses/train_total_loss': 0.5337222}
I0915 15:01:38.214215 140135745832768 controller.py:466] train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.3282558e-05,
     'losses/train_semantic_loss': 0.5303949,
     'losses/train_total_loss': 0.5303949}
I0915 15:03:09.097053 140135745832768 controller.py:466] train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.223894e-05,
     'losses/train_semantic_loss': 0.53197783,
     'losses/train_total_loss': 0.53197783}
I0915 15:04:40.615029 140135745832768 controller.py:466] train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.119298e-05,
     'losses/train_semantic_loss': 0.53143644,
     'losses/train_total_loss': 0.53143644}
I0915 15:06:11.634424 140135745832768 controller.py:466] train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.014465e-05,
     'losses/train_semantic_loss': 0.5323693,
     'losses/train_total_loss': 0.5323693}
I0915 15:07:43.229255 140135745832768 controller.py:466] train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.9093873e-05,
     'losses/train_semantic_loss': 0.51609194,
     'losses/train_total_loss': 0.51609194}
I0915 15:09:15.182042 140135745832768 controller.py:466] train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8040605e-05,
     'losses/train_semantic_loss': 0.5256449,
     'losses/train_total_loss': 0.5256449}
I0915 15:10:46.811310 140135745832768 controller.py:466] train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.698475e-05,
     'losses/train_semantic_loss': 0.5592731,
     'losses/train_total_loss': 0.5592731}
I0915 15:10:47.488993 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-16000.
I0915 15:10:47.489777 140135745832768 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0915 15:11:22.036118 140135745832768 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 15:11:22.054747 140135745832768 controller.py:295]  eval | step:  16000 | eval time:   34.6 sec | output: 
    {'evaluation/iou/IoU': 0.7116722,
     'losses/eval_semantic_loss': 0.4736159,
     'losses/eval_total_loss': 0.4736159}
I0915 15:11:22.060795 140135745832768 controller.py:241] train | step:  16000 | training until step 20000...
I0915 15:12:53.144029 140135745832768 controller.py:466] train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 4.5926263e-05,
     'losses/train_semantic_loss': 0.52226466,
     'losses/train_total_loss': 0.52226466}
I0915 15:14:24.175250 140135745832768 controller.py:466] train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.4865053e-05,
     'losses/train_semantic_loss': 0.5208886,
     'losses/train_total_loss': 0.5208886}
I0915 15:15:55.762351 140135745832768 controller.py:466] train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.380105e-05,
     'losses/train_semantic_loss': 0.5177726,
     'losses/train_total_loss': 0.5177726}
I0915 15:17:27.209423 140135745832768 controller.py:466] train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2734173e-05,
     'losses/train_semantic_loss': 0.4968931,
     'losses/train_total_loss': 0.4968931}
I0915 15:18:58.590382 140135745832768 controller.py:466] train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.1664316e-05,
     'losses/train_semantic_loss': 0.54106677,
     'losses/train_total_loss': 0.54106677}
I0915 15:20:30.149910 140135745832768 controller.py:466] train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.0591407e-05,
     'losses/train_semantic_loss': 0.55712503,
     'losses/train_total_loss': 0.55712503}
I0915 15:22:01.709363 140135745832768 controller.py:466] train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.9515326e-05,
     'losses/train_semantic_loss': 0.50309885,
     'losses/train_total_loss': 0.50309885}
I0915 15:23:32.987298 140135745832768 controller.py:466] train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.843599e-05,
     'losses/train_semantic_loss': 0.5475449,
     'losses/train_total_loss': 0.5475449}
I0915 15:25:04.794735 140135745832768 controller.py:466] train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.7353253e-05,
     'losses/train_semantic_loss': 0.5013796,
     'losses/train_total_loss': 0.5013796}
I0915 15:26:36.210121 140135745832768 controller.py:466] train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6267036e-05,
     'losses/train_semantic_loss': 0.489808,
     'losses/train_total_loss': 0.489808}
I0915 15:26:36.851698 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-17000.
I0915 15:28:07.899667 140135745832768 controller.py:466] train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.5177192e-05,
     'losses/train_semantic_loss': 0.51198417,
     'losses/train_total_loss': 0.51198417}
I0915 15:29:39.193310 140135745832768 controller.py:466] train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.408358e-05,
     'losses/train_semantic_loss': 0.51481754,
     'losses/train_total_loss': 0.51481754}
I0915 15:31:10.748146 140135745832768 controller.py:466] train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.2986052e-05,
     'losses/train_semantic_loss': 0.4777583,
     'losses/train_total_loss': 0.4777583}
I0915 15:32:41.764447 140135745832768 controller.py:466] train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.1884454e-05,
     'losses/train_semantic_loss': 0.5112036,
     'losses/train_total_loss': 0.5112036}
I0915 15:34:13.418539 140135745832768 controller.py:466] train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.0778614e-05,
     'losses/train_semantic_loss': 0.51362866,
     'losses/train_total_loss': 0.51362866}

train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.5746226e-05,
     'losses/train_semantic_loss': 0.5549141,
     'losses/train_total_loss': 0.5549141}
train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.474296e-05,
     'losses/train_semantic_loss': 0.5470343,
     'losses/train_total_loss': 0.5470343}
train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.37382e-05,
     'losses/train_semantic_loss': 0.5611769,
     'losses/train_total_loss': 0.5611769}
train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.273191e-05,
     'losses/train_semantic_loss': 0.5642922,
     'losses/train_total_loss': 0.5642922}
train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.172408e-05,
     'losses/train_semantic_loss': 0.55181026,
     'losses/train_total_loss': 0.55181026}
train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.071466e-05,
     'losses/train_semantic_loss': 0.5486523,
     'losses/train_total_loss': 0.5486523}
train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.9703645e-05,
     'losses/train_semantic_loss': 0.54194045,
     'losses/train_total_loss': 0.54194045}
train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.8691e-05,
     'losses/train_semantic_loss': 0.5433346,
     'losses/train_total_loss': 0.5433346}
train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.7676694e-05,
     'losses/train_semantic_loss': 0.5506973,
     'losses/train_total_loss': 0.5506973}
saved checkpoint to results/exp_007/ckpt-14000.
train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.666069e-05,
     'losses/train_semantic_loss': 0.51926553,
     'losses/train_total_loss': 0.51926553}
train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.564298e-05,
     'losses/train_semantic_loss': 0.54429215,
     'losses/train_total_loss': 0.54429215}
train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.462349e-05,
     'losses/train_semantic_loss': 0.5241719,
     'losses/train_total_loss': 0.5241719}
train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.360221e-05,
     'losses/train_semantic_loss': 0.56026405,
     'losses/train_total_loss': 0.56026405}
train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.2579114e-05,
     'losses/train_semantic_loss': 0.535636,
     'losses/train_total_loss': 0.535636}
train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.155415e-05,
     'losses/train_semantic_loss': 0.5630701,
     'losses/train_total_loss': 0.5630701}
train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.0527287e-05,
     'losses/train_semantic_loss': 0.5252714,
     'losses/train_total_loss': 0.5252714}
train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.9498492e-05,
     'losses/train_semantic_loss': 0.54721075,
     'losses/train_total_loss': 0.54721075}
train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.8467715e-05,
     'losses/train_semantic_loss': 0.53869706,
     'losses/train_total_loss': 0.53869706}
train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.743492e-05,
     'losses/train_semantic_loss': 0.55430144,
     'losses/train_total_loss': 0.55430144}
saved checkpoint to results/exp_007/ckpt-15000.
train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.6400055e-05,
     'losses/train_semantic_loss': 0.5406998,
     'losses/train_total_loss': 0.5406998}
train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.536307e-05,
     'losses/train_semantic_loss': 0.5213672,
     'losses/train_total_loss': 0.5213672}
train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.4323922e-05,
     'losses/train_semantic_loss': 0.5337222,
     'losses/train_total_loss': 0.5337222}
train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.3282558e-05,
     'losses/train_semantic_loss': 0.5303949,
     'losses/train_total_loss': 0.5303949}
train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.223894e-05,
     'losses/train_semantic_loss': 0.53197783,
     'losses/train_total_loss': 0.53197783}
train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.119298e-05,
     'losses/train_semantic_loss': 0.53143644,
     'losses/train_total_loss': 0.53143644}
train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.014465e-05,
     'losses/train_semantic_loss': 0.5323693,
     'losses/train_total_loss': 0.5323693}
train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.9093873e-05,
     'losses/train_semantic_loss': 0.51609194,
     'losses/train_total_loss': 0.51609194}
train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8040605e-05,
     'losses/train_semantic_loss': 0.5256449,
     'losses/train_total_loss': 0.5256449}
train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.698475e-05,
     'losses/train_semantic_loss': 0.5592731,
     'losses/train_total_loss': 0.5592731}
saved checkpoint to results/exp_007/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   34.6 sec | output: 
    {'evaluation/iou/IoU': 0.7116722,
     'losses/eval_semantic_loss': 0.4736159,
     'losses/eval_total_loss': 0.4736159}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 4.5926263e-05,
     'losses/train_semantic_loss': 0.52226466,
     'losses/train_total_loss': 0.52226466}
train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.4865053e-05,
     'losses/train_semantic_loss': 0.5208886,
     'losses/train_total_loss': 0.5208886}
train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.380105e-05,
     'losses/train_semantic_loss': 0.5177726,
     'losses/train_total_loss': 0.5177726}
train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2734173e-05,
     'losses/train_semantic_loss': 0.4968931,
     'losses/train_total_loss': 0.4968931}
train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.1664316e-05,
     'losses/train_semantic_loss': 0.54106677,
     'losses/train_total_loss': 0.54106677}
train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.0591407e-05,
     'losses/train_semantic_loss': 0.55712503,
     'losses/train_total_loss': 0.55712503}
train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.9515326e-05,
     'losses/train_semantic_loss': 0.50309885,
     'losses/train_total_loss': 0.50309885}
train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.843599e-05,
     'losses/train_semantic_loss': 0.5475449,
     'losses/train_total_loss': 0.5475449}
train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.7353253e-05,
     'losses/train_semantic_loss': 0.5013796,
     'losses/train_total_loss': 0.5013796}
train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6267036e-05,
     'losses/train_semantic_loss': 0.489808,
     'losses/train_total_loss': 0.489808}
saved checkpoint to results/exp_007/ckpt-17000.
train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.5177192e-05,
     'losses/train_semantic_loss': 0.51198417,
     'losses/train_total_loss': 0.51198417}
train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.408358e-05,
     'losses/train_semantic_loss': 0.51481754,
     'losses/train_total_loss': 0.51481754}
train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.2986052e-05,
     'losses/train_semantic_loss': 0.4777583,
     'losses/train_total_loss': 0.4777583}
train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.1884454e-05,
     'losses/train_semantic_loss': 0.5112036,
     'losses/train_total_loss': 0.5112036}
train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.0778614e-05,
     'losses/train_semantic_loss': 0.51362866,
     'losses/train_total_loss': 0.51362866}I0915 15:35:45.091645 140135745832768 controller.py:466] train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.9668336e-05,
     'losses/train_semantic_loss': 0.52117926,
     'losses/train_total_loss': 0.52117926}
I0915 15:37:16.362436 140135745832768 controller.py:466] train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.8553417e-05,
     'losses/train_semantic_loss': 0.5372847,
     'losses/train_total_loss': 0.5372847}
I0915 15:38:48.338784 140135745832768 controller.py:466] train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.7433642e-05,
     'losses/train_semantic_loss': 0.5232775,
     'losses/train_total_loss': 0.5232775}
I0915 15:40:19.137328 140135745832768 controller.py:466] train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.6308766e-05,
     'losses/train_semantic_loss': 0.5462688,
     'losses/train_total_loss': 0.5462688}
I0915 15:41:49.986680 140135745832768 controller.py:466] train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.5178519e-05,
     'losses/train_semantic_loss': 0.55163294,
     'losses/train_total_loss': 0.55163294}
I0915 15:41:50.679140 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-18000.
I0915 15:43:22.175048 140135745832768 controller.py:466] train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.4042596e-05,
     'losses/train_semantic_loss': 0.510751,
     'losses/train_total_loss': 0.510751}
I0915 15:44:53.191655 140135745832768 controller.py:466] train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2900667e-05,
     'losses/train_semantic_loss': 0.51645076,
     'losses/train_total_loss': 0.51645076}
I0915 15:46:25.219436 140135745832768 controller.py:466] train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.1752388e-05,
     'losses/train_semantic_loss': 0.52279073,
     'losses/train_total_loss': 0.52279073}
I0915 15:47:56.986109 140135745832768 controller.py:466] train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.0597328e-05,
     'losses/train_semantic_loss': 0.5363134,
     'losses/train_total_loss': 0.5363134}
I0915 15:49:28.411901 140135745832768 controller.py:466] train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.9435025e-05,
     'losses/train_semantic_loss': 0.51258117,
     'losses/train_total_loss': 0.51258117}
I0915 15:50:59.298053 140135745832768 controller.py:466] train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.8264935e-05,
     'losses/train_semantic_loss': 0.4897043,
     'losses/train_total_loss': 0.4897043}
I0915 15:52:30.534235 140135745832768 controller.py:466] train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.7086457e-05,
     'losses/train_semantic_loss': 0.48829433,
     'losses/train_total_loss': 0.48829433}
I0915 15:54:02.583525 140135745832768 controller.py:466] train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5898868e-05,
     'losses/train_semantic_loss': 0.5063317,
     'losses/train_total_loss': 0.5063317}
I0915 15:55:34.266097 140135745832768 controller.py:466] train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.4701326e-05,
     'losses/train_semantic_loss': 0.49583492,
     'losses/train_total_loss': 0.49583492}
I0915 15:57:05.004015 140135745832768 controller.py:466] train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.3492834e-05,
     'losses/train_semantic_loss': 0.51738876,
     'losses/train_total_loss': 0.51738876}
I0915 15:57:05.645264 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-19000.
I0915 15:58:37.120043 140135745832768 controller.py:466] train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.227217e-05,
     'losses/train_semantic_loss': 0.5175252,
     'losses/train_total_loss': 0.5175252}
I0915 16:00:08.458179 140135745832768 controller.py:466] train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.1037842e-05,
     'losses/train_semantic_loss': 0.5140376,
     'losses/train_total_loss': 0.5140376}
I0915 16:01:40.043991 140135745832768 controller.py:466] train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.787945e-06,
     'losses/train_semantic_loss': 0.4903062,
     'losses/train_total_loss': 0.4903062}
I0915 16:03:11.914226 140135745832768 controller.py:466] train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.519983e-06,
     'losses/train_semantic_loss': 0.5004814,
     'losses/train_total_loss': 0.5004814}
I0915 16:04:44.200875 140135745832768 controller.py:466] train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.230622e-06,
     'losses/train_semantic_loss': 0.509101,
     'losses/train_total_loss': 0.509101}
I0915 16:06:16.469821 140135745832768 controller.py:466] train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.9150257e-06,
     'losses/train_semantic_loss': 0.49909937,
     'losses/train_total_loss': 0.49909937}
I0915 16:07:47.995259 140135745832768 controller.py:466] train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.565746e-06,
     'losses/train_semantic_loss': 0.5047913,
     'losses/train_total_loss': 0.5047913}
I0915 16:09:19.520036 140135745832768 controller.py:466] train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.1697834e-06,
     'losses/train_semantic_loss': 0.50441396,
     'losses/train_total_loss': 0.50441396}
I0915 16:10:51.855197 140135745832768 controller.py:466] train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.6986453e-06,
     'losses/train_semantic_loss': 0.49998605,
     'losses/train_total_loss': 0.49998605}
I0915 16:12:23.803327 140135745832768 controller.py:466] train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.49016136,
     'losses/train_total_loss': 0.49016136}
I0915 16:12:24.622336 140135745832768 controller.py:495] saved checkpoint to results/exp_007/ckpt-20000.
I0915 16:12:24.623122 140135745832768 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0915 16:13:00.241028 140135745832768 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 16:13:00.245649 140135745832768 controller.py:295]  eval | step:  20000 | eval time:   35.6 sec | output: 
    {'evaluation/iou/IoU': 0.71992385,
     'losses/eval_semantic_loss': 0.44987923,
     'losses/eval_total_loss': 0.44987923}

train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.9668336e-05,
     'losses/train_semantic_loss': 0.52117926,
     'losses/train_total_loss': 0.52117926}
train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.8553417e-05,
     'losses/train_semantic_loss': 0.5372847,
     'losses/train_total_loss': 0.5372847}
train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.7433642e-05,
     'losses/train_semantic_loss': 0.5232775,
     'losses/train_total_loss': 0.5232775}
train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.6308766e-05,
     'losses/train_semantic_loss': 0.5462688,
     'losses/train_total_loss': 0.5462688}
train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.5178519e-05,
     'losses/train_semantic_loss': 0.55163294,
     'losses/train_total_loss': 0.55163294}
saved checkpoint to results/exp_007/ckpt-18000.
train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.4042596e-05,
     'losses/train_semantic_loss': 0.510751,
     'losses/train_total_loss': 0.510751}
train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2900667e-05,
     'losses/train_semantic_loss': 0.51645076,
     'losses/train_total_loss': 0.51645076}
train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.1752388e-05,
     'losses/train_semantic_loss': 0.52279073,
     'losses/train_total_loss': 0.52279073}
train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.0597328e-05,
     'losses/train_semantic_loss': 0.5363134,
     'losses/train_total_loss': 0.5363134}
train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.9435025e-05,
     'losses/train_semantic_loss': 0.51258117,
     'losses/train_total_loss': 0.51258117}
train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.8264935e-05,
     'losses/train_semantic_loss': 0.4897043,
     'losses/train_total_loss': 0.4897043}
train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.7086457e-05,
     'losses/train_semantic_loss': 0.48829433,
     'losses/train_total_loss': 0.48829433}
train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5898868e-05,
     'losses/train_semantic_loss': 0.5063317,
     'losses/train_total_loss': 0.5063317}
train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.4701326e-05,
     'losses/train_semantic_loss': 0.49583492,
     'losses/train_total_loss': 0.49583492}
train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.3492834e-05,
     'losses/train_semantic_loss': 0.51738876,
     'losses/train_total_loss': 0.51738876}
saved checkpoint to results/exp_007/ckpt-19000.
train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.227217e-05,
     'losses/train_semantic_loss': 0.5175252,
     'losses/train_total_loss': 0.5175252}
train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.1037842e-05,
     'losses/train_semantic_loss': 0.5140376,
     'losses/train_total_loss': 0.5140376}
train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.787945e-06,
     'losses/train_semantic_loss': 0.4903062,
     'losses/train_total_loss': 0.4903062}
train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.519983e-06,
     'losses/train_semantic_loss': 0.5004814,
     'losses/train_total_loss': 0.5004814}
train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.230622e-06,
     'losses/train_semantic_loss': 0.509101,
     'losses/train_total_loss': 0.509101}
train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.9150257e-06,
     'losses/train_semantic_loss': 0.49909937,
     'losses/train_total_loss': 0.49909937}
train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.565746e-06,
     'losses/train_semantic_loss': 0.5047913,
     'losses/train_total_loss': 0.5047913}
train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.1697834e-06,
     'losses/train_semantic_loss': 0.50441396,
     'losses/train_total_loss': 0.50441396}
train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.6986453e-06,
     'losses/train_semantic_loss': 0.49998605,
     'losses/train_total_loss': 0.49998605}
train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.49016136,
     'losses/train_total_loss': 0.49016136}
saved checkpoint to results/exp_007/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   35.6 sec | output: 
    {'evaluation/iou/IoU': 0.71992385,
     'losses/eval_semantic_loss': 0.44987923,
     'losses/eval_total_loss': 0.44987923}
