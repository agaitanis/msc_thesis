I0916 12:04:13.129224 139993253058368 train.py:65] Reading the config file.
I0916 12:04:13.136356 139993253058368 train.py:69] Starting the experiment.
2022-09-16 12:04:13.137228: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-16 12:04:14.417147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0916 12:04:14.423459 139993253058368 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0916 12:04:14.573048 139993253058368 deeplab.py:57] Synchronized Batchnorm is used.
I0916 12:04:14.574064 139993253058368 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 8, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0916 12:04:14.674171 139993253058368 deeplab.py:96] Setting pooling size to (65, 65)
I0916 12:04:14.674294 139993253058368 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 12:04:17.616488 139993253058368 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0916 12:04:17.631975 139993253058368 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0916 12:04:17.642905 139993253058368 controller.py:399] initialized model.
I0916 12:04:18.348671 139993253058368 api.py:447] Eval with scales ListWrapper([1.0])
I0916 12:04:19.125705 139993253058368 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 12:04:19.143592 139993253058368 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0916 12:04:22.127172 139993253058368 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 12:04:22.498483 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-0.
I0916 12:04:22.499030 139993253058368 controller.py:241] train | step:      0 | training until step 4000...
2022-09-16 12:04:48.068720: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 989 of 1000
2022-09-16 12:04:48.239672: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.
2022-09-16 12:04:52.093461: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0916 12:06:36.765370 139993253058368 controller.py:466] train | step:    100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.1220887,
     'losses/train_total_loss': 1.1220887}
I0916 12:08:15.689146 139993253058368 controller.py:466] train | step:    200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 1.0188794,
     'losses/train_total_loss': 1.0188794}
I0916 12:09:54.244881 139993253058368 controller.py:466] train | step:    300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.9999777,
     'losses/train_total_loss': 0.9999777}
I0916 12:11:32.764409 139993253058368 controller.py:466] train | step:    400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.97141594,
     'losses/train_total_loss': 0.97141594}
I0916 12:13:11.212290 139993253058368 controller.py:466] train | step:    500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.8960273,
     'losses/train_total_loss': 0.8960273}
I0916 12:14:49.791336 139993253058368 controller.py:466] train | step:    600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8900793,
     'losses/train_total_loss': 0.8900793}
I0916 12:16:28.552404 139993253058368 controller.py:466] train | step:    700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.8560777,
     'losses/train_total_loss': 0.8560777}
I0916 12:18:07.193358 139993253058368 controller.py:466] train | step:    800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.85167485,
     'losses/train_total_loss': 0.85167485}
I0916 12:19:45.987517 139993253058368 controller.py:466] train | step:    900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.8139685,
     'losses/train_total_loss': 0.8139685}
I0916 12:21:24.767900 139993253058368 controller.py:466] train | step:   1000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.82132226,
     'losses/train_total_loss': 0.82132226}
I0916 12:21:25.597687 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-1000.
I0916 12:23:04.194831 139993253058368 controller.py:466] train | step:   1100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.8331343,
     'losses/train_total_loss': 0.8331343}
I0916 12:24:43.205998 139993253058368 controller.py:466] train | step:   1200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7931819,
     'losses/train_total_loss': 0.7931819}
I0916 12:26:21.974618 139993253058368 controller.py:466] train | step:   1300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.8184278,
     'losses/train_total_loss': 0.8184278}
I0916 12:28:00.594008 139993253058368 controller.py:466] train | step:   1400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.82492524,
     'losses/train_total_loss': 0.82492524}
I0916 12:29:39.261751 139993253058368 controller.py:466] train | step:   1500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7942262,
     'losses/train_total_loss': 0.7942262}
I0916 12:31:18.024404 139993253058368 controller.py:466] train | step:   1600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.7823597,
     'losses/train_total_loss': 0.7823597}
I0916 12:32:57.015130 139993253058368 controller.py:466] train | step:   1700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.78316617,
     'losses/train_total_loss': 0.78316617}
I0916 12:34:35.671408 139993253058368 controller.py:466] train | step:   1800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.7985505,
     'losses/train_total_loss': 0.7985505}
I0916 12:36:14.750244 139993253058368 controller.py:466] train | step:   1900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.77241206,
     'losses/train_total_loss': 0.77241206}
I0916 12:37:53.528635 139993253058368 controller.py:466] train | step:   2000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.7607969,
     'losses/train_total_loss': 0.7607969}
I0916 12:37:54.377308 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-2000.
I0916 12:39:33.154314 139993253058368 controller.py:466] train | step:   2100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.76571906,
     'losses/train_total_loss': 0.76571906}
I0916 12:41:11.921109 139993253058368 controller.py:466] train | step:   2200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.8038904,
     'losses/train_total_loss': 0.8038904}
I0916 12:42:50.801809 139993253058368 controller.py:466] train | step:   2300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.759625,
     'losses/train_total_loss': 0.759625}
I0916 12:44:29.571482 139993253058368 controller.py:466] train | step:   2400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.76071656,
     'losses/train_total_loss': 0.76071656}
I0916 12:46:08.283648 139993253058368 controller.py:466] train | step:   2500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.72210574,
     'losses/train_total_loss': 0.72210574}
I0916 12:47:47.263048 139993253058368 controller.py:466] train | step:   2600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.73150134,
     'losses/train_total_loss': 0.73150134}
I0916 12:49:26.415751 139993253058368 controller.py:466] train | step:   2700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.74275255,
     'losses/train_total_loss': 0.74275255}
I0916 12:51:05.586597 139993253058368 controller.py:466] train | step:   2800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.7591833,
     'losses/train_total_loss': 0.7591833}
I0916 12:52:44.410436 139993253058368 controller.py:466] train | step:   2900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.73173386,
     'losses/train_total_loss': 0.73173386}
I0916 12:54:23.287360 139993253058368 controller.py:466] train | step:   3000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.72822917,
     'losses/train_total_loss': 0.72822917}
I0916 12:54:24.062070 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-3000.
I0916 12:56:03.078669 139993253058368 controller.py:466] train | step:   3100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.73840296,
     'losses/train_total_loss': 0.73840296}
I0916 12:57:41.944392 139993253058368 controller.py:466] train | step:   3200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.7601262,
     'losses/train_total_loss': 0.7601262}
I0916 12:59:20.877292 139993253058368 controller.py:466] train | step:   3300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.7205429,
     'losses/train_total_loss': 0.7205429}
I0916 13:00:59.705759 139993253058368 controller.py:466] train | step:   3400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.74429893,
     'losses/train_total_loss': 0.74429893}
I0916 13:02:38.610213 139993253058368 controller.py:466] train | step:   3500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.71519643,
     'losses/train_total_loss': 0.71519643}
I0916 13:04:17.468480 139993253058368 controller.py:466] train | step:   3600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.7436121,
     'losses/train_total_loss': 0.7436121}
I0916 13:05:56.183258 139993253058368 controller.py:466] train | step:   3700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.72639745,
     'losses/train_total_loss': 0.72639745}
I0916 13:07:35.339883 139993253058368 controller.py:466] train | step:   3800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.7018751,
     'losses/train_total_loss': 0.7018751}
I0916 13:09:13.864542 139993253058368 controller.py:466] train | step:   3900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.73172486,
     'losses/train_total_loss': 0.73172486}
I0916 13:10:52.197787 139993253058368 controller.py:466] train | step:   4000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.7679842,
     'losses/train_total_loss': 0.7679842}
I0916 13:10:53.041380 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-4000.
I0916 13:10:53.042227 139993253058368 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0916 13:10:55.802568 139993253058368 api.py:447] Eval with scales ListWrapper([1.0])
I0916 13:10:55.831728 139993253058368 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 13:10:55.856846 139993253058368 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0916 13:10:56.553566 139993253058368 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 13:11:45.775896 139993253058368 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 13:11:45.806752 139993253058368 controller.py:295]  eval | step:   4000 | eval time:   52.8 sec | output: 
    {'evaluation/iou/IoU': 0.5374397,
     'losses/eval_semantic_loss': 0.8391339,
     'losses/eval_total_loss': 0.8391339}
I0916 13:11:45.812650 139993253058368 controller.py:241] train | step:   4000 | training until step 8000...
I0916 13:13:24.562168 139993253058368 controller.py:466] train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.7278936,
     'losses/train_total_loss': 0.7278936}
I0916 13:15:03.346252 139993253058368 controller.py:466] train | step:   4200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.71156126,
     'losses/train_total_loss': 0.71156126}
I0916 13:16:42.027845 139993253058368 controller.py:466] train | step:   4300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6992694,
     'losses/train_total_loss': 0.6992694}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_009/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.1220887,
     'losses/train_total_loss': 1.1220887}
train | step:    200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 1.0188794,
     'losses/train_total_loss': 1.0188794}
train | step:    300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.9999777,
     'losses/train_total_loss': 0.9999777}
train | step:    400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.97141594,
     'losses/train_total_loss': 0.97141594}
train | step:    500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.8960273,
     'losses/train_total_loss': 0.8960273}
train | step:    600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8900793,
     'losses/train_total_loss': 0.8900793}
train | step:    700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.8560777,
     'losses/train_total_loss': 0.8560777}
train | step:    800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.85167485,
     'losses/train_total_loss': 0.85167485}
train | step:    900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.8139685,
     'losses/train_total_loss': 0.8139685}
train | step:   1000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.82132226,
     'losses/train_total_loss': 0.82132226}
saved checkpoint to results/exp_009/ckpt-1000.
train | step:   1100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.8331343,
     'losses/train_total_loss': 0.8331343}
train | step:   1200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7931819,
     'losses/train_total_loss': 0.7931819}
train | step:   1300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.8184278,
     'losses/train_total_loss': 0.8184278}
train | step:   1400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.82492524,
     'losses/train_total_loss': 0.82492524}
train | step:   1500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7942262,
     'losses/train_total_loss': 0.7942262}
train | step:   1600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.7823597,
     'losses/train_total_loss': 0.7823597}
train | step:   1700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.78316617,
     'losses/train_total_loss': 0.78316617}
train | step:   1800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.7985505,
     'losses/train_total_loss': 0.7985505}
train | step:   1900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.77241206,
     'losses/train_total_loss': 0.77241206}
train | step:   2000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.7607969,
     'losses/train_total_loss': 0.7607969}
saved checkpoint to results/exp_009/ckpt-2000.
train | step:   2100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.76571906,
     'losses/train_total_loss': 0.76571906}
train | step:   2200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.8038904,
     'losses/train_total_loss': 0.8038904}
train | step:   2300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.759625,
     'losses/train_total_loss': 0.759625}
train | step:   2400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.76071656,
     'losses/train_total_loss': 0.76071656}
train | step:   2500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.72210574,
     'losses/train_total_loss': 0.72210574}
train | step:   2600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.73150134,
     'losses/train_total_loss': 0.73150134}
train | step:   2700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.74275255,
     'losses/train_total_loss': 0.74275255}
train | step:   2800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.7591833,
     'losses/train_total_loss': 0.7591833}
train | step:   2900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.73173386,
     'losses/train_total_loss': 0.73173386}
train | step:   3000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.72822917,
     'losses/train_total_loss': 0.72822917}
saved checkpoint to results/exp_009/ckpt-3000.
train | step:   3100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.73840296,
     'losses/train_total_loss': 0.73840296}
train | step:   3200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.7601262,
     'losses/train_total_loss': 0.7601262}
train | step:   3300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.7205429,
     'losses/train_total_loss': 0.7205429}
train | step:   3400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.74429893,
     'losses/train_total_loss': 0.74429893}
train | step:   3500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.71519643,
     'losses/train_total_loss': 0.71519643}
train | step:   3600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.7436121,
     'losses/train_total_loss': 0.7436121}
train | step:   3700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.72639745,
     'losses/train_total_loss': 0.72639745}
train | step:   3800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.7018751,
     'losses/train_total_loss': 0.7018751}
train | step:   3900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.73172486,
     'losses/train_total_loss': 0.73172486}
train | step:   4000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.7679842,
     'losses/train_total_loss': 0.7679842}
saved checkpoint to results/exp_009/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   52.8 sec | output: 
    {'evaluation/iou/IoU': 0.5374397,
     'losses/eval_semantic_loss': 0.8391339,
     'losses/eval_total_loss': 0.8391339}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.7278936,
     'losses/train_total_loss': 0.7278936}
train | step:   4200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.71156126,
     'losses/train_total_loss': 0.71156126}
train | step:   4300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6992694,
     'losses/train_total_loss': 0.6992694}I0916 13:18:20.633363 139993253058368 controller.py:466] train | step:   4400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.6804695,
     'losses/train_total_loss': 0.6804695}
I0916 13:19:59.201319 139993253058368 controller.py:466] train | step:   4500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.71222776,
     'losses/train_total_loss': 0.71222776}
I0916 13:21:38.297472 139993253058368 controller.py:466] train | step:   4600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.6954644,
     'losses/train_total_loss': 0.6954644}
I0916 13:23:17.975705 139993253058368 controller.py:466] train | step:   4700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.7482969,
     'losses/train_total_loss': 0.7482969}
I0916 13:24:57.936616 139993253058368 controller.py:466] train | step:   4800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.7250744,
     'losses/train_total_loss': 0.7250744}
I0916 13:26:37.604411 139993253058368 controller.py:466] train | step:   4900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.66679496,
     'losses/train_total_loss': 0.66679496}
I0916 13:28:17.401415 139993253058368 controller.py:466] train | step:   5000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6928232,
     'losses/train_total_loss': 0.6928232}
I0916 13:28:18.150970 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-5000.
I0916 13:29:57.603017 139993253058368 controller.py:466] train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.71586454,
     'losses/train_total_loss': 0.71586454}
I0916 13:31:37.088063 139993253058368 controller.py:466] train | step:   5200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.67910606,
     'losses/train_total_loss': 0.67910606}
I0916 13:33:16.442127 139993253058368 controller.py:466] train | step:   5300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.70871073,
     'losses/train_total_loss': 0.70871073}
I0916 13:34:56.106029 139993253058368 controller.py:466] train | step:   5400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.6694663,
     'losses/train_total_loss': 0.6694663}
I0916 13:36:35.715889 139993253058368 controller.py:466] train | step:   5500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.65103835,
     'losses/train_total_loss': 0.65103835}
I0916 13:38:15.171352 139993253058368 controller.py:466] train | step:   5600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6657715,
     'losses/train_total_loss': 0.6657715}
I0916 13:39:54.651338 139993253058368 controller.py:466] train | step:   5700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.68976426,
     'losses/train_total_loss': 0.68976426}
I0916 13:41:34.281502 139993253058368 controller.py:466] train | step:   5800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.68859553,
     'losses/train_total_loss': 0.68859553}
I0916 13:43:13.702657 139993253058368 controller.py:466] train | step:   5900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.6568817,
     'losses/train_total_loss': 0.6568817}
I0916 13:44:53.378940 139993253058368 controller.py:466] train | step:   6000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6663061,
     'losses/train_total_loss': 0.6663061}
I0916 13:44:54.043666 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-6000.
I0916 13:46:33.785991 139993253058368 controller.py:466] train | step:   6100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.66796076,
     'losses/train_total_loss': 0.66796076}
I0916 13:48:13.275423 139993253058368 controller.py:466] train | step:   6200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6519934,
     'losses/train_total_loss': 0.6519934}
I0916 13:49:52.874737 139993253058368 controller.py:466] train | step:   6300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.65596604,
     'losses/train_total_loss': 0.65596604}
I0916 13:51:32.538888 139993253058368 controller.py:466] train | step:   6400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6752388,
     'losses/train_total_loss': 0.6752388}
I0916 13:53:12.073103 139993253058368 controller.py:466] train | step:   6500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.63820285,
     'losses/train_total_loss': 0.63820285}
I0916 13:54:51.533863 139993253058368 controller.py:466] train | step:   6600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6891597,
     'losses/train_total_loss': 0.6891597}
I0916 13:56:31.061948 139993253058368 controller.py:466] train | step:   6700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6617435,
     'losses/train_total_loss': 0.6617435}
I0916 13:58:10.580738 139993253058368 controller.py:466] train | step:   6800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.6749887,
     'losses/train_total_loss': 0.6749887}
I0916 13:59:50.262005 139993253058368 controller.py:466] train | step:   6900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.67266136,
     'losses/train_total_loss': 0.67266136}
I0916 14:01:29.774877 139993253058368 controller.py:466] train | step:   7000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6451367,
     'losses/train_total_loss': 0.6451367}
I0916 14:01:30.455336 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-7000.
I0916 14:03:10.072664 139993253058368 controller.py:466] train | step:   7100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.68406165,
     'losses/train_total_loss': 0.68406165}
I0916 14:04:49.580520 139993253058368 controller.py:466] train | step:   7200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6614593,
     'losses/train_total_loss': 0.6614593}
I0916 14:06:29.017369 139993253058368 controller.py:466] train | step:   7300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.64972353,
     'losses/train_total_loss': 0.64972353}
I0916 14:08:08.615864 139993253058368 controller.py:466] train | step:   7400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.6317564,
     'losses/train_total_loss': 0.6317564}
I0916 14:09:48.125680 139993253058368 controller.py:466] train | step:   7500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.65646863,
     'losses/train_total_loss': 0.65646863}
I0916 14:11:27.550922 139993253058368 controller.py:466] train | step:   7600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.67063814,
     'losses/train_total_loss': 0.67063814}
I0916 14:13:06.855562 139993253058368 controller.py:466] train | step:   7700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.6322774,
     'losses/train_total_loss': 0.6322774}
I0916 14:14:46.374597 139993253058368 controller.py:466] train | step:   7800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.68063897,
     'losses/train_total_loss': 0.68063897}
I0916 14:16:26.232303 139993253058368 controller.py:466] train | step:   7900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.6388226,
     'losses/train_total_loss': 0.6388226}
I0916 14:18:05.530001 139993253058368 controller.py:466] train | step:   8000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.7032506,
     'losses/train_total_loss': 0.7032506}
I0916 14:18:06.232846 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-8000.
I0916 14:18:06.233364 139993253058368 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0916 14:18:54.162623 139993253058368 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 14:18:54.167325 139993253058368 controller.py:295]  eval | step:   8000 | eval time:   47.9 sec | output: 
    {'evaluation/iou/IoU': 0.64905834,
     'losses/eval_semantic_loss': 0.68807775,
     'losses/eval_total_loss': 0.68807775}
I0916 14:18:54.173563 139993253058368 controller.py:241] train | step:   8000 | training until step 12000...
2022-09-16 14:18:54.477806: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:18:55.676053: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:18:56.857524: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:18:58.110074: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:18:59.301965: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:19:00.492203: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:19:01.682608: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:19:02.877122: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:19:04.059855: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 14:19:05.244585: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
I0916 14:20:54.250313 139993253058368 controller.py:466] train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.66062474,
     'losses/train_total_loss': 0.66062474}
I0916 14:22:54.798509 139993253058368 controller.py:466] train | step:   8200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.6500272,
     'losses/train_total_loss': 0.6500272}
I0916 14:24:54.939393 139993253058368 controller.py:466] train | step:   8300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.64530534,
     'losses/train_total_loss': 0.64530534}
I0916 14:26:54.895972 139993253058368 controller.py:466] train | step:   8400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.62202,
     'losses/train_total_loss': 0.62202}
I0916 14:28:54.639750 139993253058368 controller.py:466] train | step:   8500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.6184991,
     'losses/train_total_loss': 0.6184991}
I0916 14:30:54.400836 139993253058368 controller.py:466] train | step:   8600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.6667514,
     'losses/train_total_loss': 0.6667514}
I0916 14:32:54.288504 139993253058368 controller.py:466] train | step:   8700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.62253386,
     'losses/train_total_loss': 0.62253386}

train | step:   4400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.6804695,
     'losses/train_total_loss': 0.6804695}
train | step:   4500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.71222776,
     'losses/train_total_loss': 0.71222776}
train | step:   4600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.6954644,
     'losses/train_total_loss': 0.6954644}
train | step:   4700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.7482969,
     'losses/train_total_loss': 0.7482969}
train | step:   4800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.7250744,
     'losses/train_total_loss': 0.7250744}
train | step:   4900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.66679496,
     'losses/train_total_loss': 0.66679496}
train | step:   5000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6928232,
     'losses/train_total_loss': 0.6928232}
saved checkpoint to results/exp_009/ckpt-5000.
train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.71586454,
     'losses/train_total_loss': 0.71586454}
train | step:   5200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.67910606,
     'losses/train_total_loss': 0.67910606}
train | step:   5300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.70871073,
     'losses/train_total_loss': 0.70871073}
train | step:   5400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.6694663,
     'losses/train_total_loss': 0.6694663}
train | step:   5500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.65103835,
     'losses/train_total_loss': 0.65103835}
train | step:   5600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6657715,
     'losses/train_total_loss': 0.6657715}
train | step:   5700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.68976426,
     'losses/train_total_loss': 0.68976426}
train | step:   5800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.68859553,
     'losses/train_total_loss': 0.68859553}
train | step:   5900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.6568817,
     'losses/train_total_loss': 0.6568817}
train | step:   6000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6663061,
     'losses/train_total_loss': 0.6663061}
saved checkpoint to results/exp_009/ckpt-6000.
train | step:   6100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.66796076,
     'losses/train_total_loss': 0.66796076}
train | step:   6200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6519934,
     'losses/train_total_loss': 0.6519934}
train | step:   6300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.65596604,
     'losses/train_total_loss': 0.65596604}
train | step:   6400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6752388,
     'losses/train_total_loss': 0.6752388}
train | step:   6500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.63820285,
     'losses/train_total_loss': 0.63820285}
train | step:   6600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6891597,
     'losses/train_total_loss': 0.6891597}
train | step:   6700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6617435,
     'losses/train_total_loss': 0.6617435}
train | step:   6800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.6749887,
     'losses/train_total_loss': 0.6749887}
train | step:   6900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.67266136,
     'losses/train_total_loss': 0.67266136}
train | step:   7000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6451367,
     'losses/train_total_loss': 0.6451367}
saved checkpoint to results/exp_009/ckpt-7000.
train | step:   7100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.68406165,
     'losses/train_total_loss': 0.68406165}
train | step:   7200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6614593,
     'losses/train_total_loss': 0.6614593}
train | step:   7300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.64972353,
     'losses/train_total_loss': 0.64972353}
train | step:   7400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.6317564,
     'losses/train_total_loss': 0.6317564}
train | step:   7500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.65646863,
     'losses/train_total_loss': 0.65646863}
train | step:   7600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.67063814,
     'losses/train_total_loss': 0.67063814}
train | step:   7700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.6322774,
     'losses/train_total_loss': 0.6322774}
train | step:   7800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.68063897,
     'losses/train_total_loss': 0.68063897}
train | step:   7900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.6388226,
     'losses/train_total_loss': 0.6388226}
train | step:   8000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.7032506,
     'losses/train_total_loss': 0.7032506}
saved checkpoint to results/exp_009/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   47.9 sec | output: 
    {'evaluation/iou/IoU': 0.64905834,
     'losses/eval_semantic_loss': 0.68807775,
     'losses/eval_total_loss': 0.68807775}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.66062474,
     'losses/train_total_loss': 0.66062474}
train | step:   8200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.6500272,
     'losses/train_total_loss': 0.6500272}
train | step:   8300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.64530534,
     'losses/train_total_loss': 0.64530534}
train | step:   8400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.62202,
     'losses/train_total_loss': 0.62202}
train | step:   8500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.6184991,
     'losses/train_total_loss': 0.6184991}
train | step:   8600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.6667514,
     'losses/train_total_loss': 0.6667514}
train | step:   8700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.62253386,
     'losses/train_total_loss': 0.62253386}I0916 14:34:54.540198 139993253058368 controller.py:466] train | step:   8800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.66648364,
     'losses/train_total_loss': 0.66648364}
I0916 14:36:54.556761 139993253058368 controller.py:466] train | step:   8900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.661905,
     'losses/train_total_loss': 0.661905}
I0916 14:38:54.737043 139993253058368 controller.py:466] train | step:   9000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.6421656,
     'losses/train_total_loss': 0.6421656}
I0916 14:38:55.325606 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-9000.
I0916 14:40:34.488026 139993253058368 controller.py:466] train | step:   9100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.64943403,
     'losses/train_total_loss': 0.64943403}
I0916 14:42:13.847427 139993253058368 controller.py:466] train | step:   9200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.64422613,
     'losses/train_total_loss': 0.64422613}
I0916 14:43:53.162840 139993253058368 controller.py:466] train | step:   9300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.6005712,
     'losses/train_total_loss': 0.6005712}
I0916 14:45:32.677613 139993253058368 controller.py:466] train | step:   9400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.6279144,
     'losses/train_total_loss': 0.6279144}
I0916 14:47:12.103110 139993253058368 controller.py:466] train | step:   9500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.61496854,
     'losses/train_total_loss': 0.61496854}
I0916 14:48:51.374471 139993253058368 controller.py:466] train | step:   9600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.64096284,
     'losses/train_total_loss': 0.64096284}
I0916 14:50:30.844359 139993253058368 controller.py:466] train | step:   9700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.6261613,
     'losses/train_total_loss': 0.6261613}
I0916 14:52:10.260043 139993253058368 controller.py:466] train | step:   9800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.6496198,
     'losses/train_total_loss': 0.6496198}
I0916 14:53:49.812385 139993253058368 controller.py:466] train | step:   9900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.61424714,
     'losses/train_total_loss': 0.61424714}
I0916 14:55:29.326463 139993253058368 controller.py:466] train | step:  10000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.60293853,
     'losses/train_total_loss': 0.60293853}
I0916 14:55:29.934512 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-10000.
I0916 14:57:09.562116 139993253058368 controller.py:466] train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.6437751,
     'losses/train_total_loss': 0.6437751}
I0916 14:58:49.006048 139993253058368 controller.py:466] train | step:  10200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.6244176,
     'losses/train_total_loss': 0.6244176}
I0916 15:00:28.575949 139993253058368 controller.py:466] train | step:  10300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.59885526,
     'losses/train_total_loss': 0.59885526}
I0916 15:02:08.265259 139993253058368 controller.py:466] train | step:  10400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.62945455,
     'losses/train_total_loss': 0.62945455}
I0916 15:03:48.019364 139993253058368 controller.py:466] train | step:  10500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.6047382,
     'losses/train_total_loss': 0.6047382}
I0916 15:05:27.770068 139993253058368 controller.py:466] train | step:  10600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.6173184,
     'losses/train_total_loss': 0.6173184}
I0916 15:07:07.291231 139993253058368 controller.py:466] train | step:  10700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.58933574,
     'losses/train_total_loss': 0.58933574}
I0916 15:08:46.945545 139993253058368 controller.py:466] train | step:  10800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.5857981,
     'losses/train_total_loss': 0.5857981}
I0916 15:10:26.268208 139993253058368 controller.py:466] train | step:  10900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5830109,
     'losses/train_total_loss': 0.5830109}
I0916 15:12:05.898123 139993253058368 controller.py:466] train | step:  11000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.6346272,
     'losses/train_total_loss': 0.6346272}
I0916 15:12:06.597693 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-11000.
I0916 15:13:46.464021 139993253058368 controller.py:466] train | step:  11100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.57754403,
     'losses/train_total_loss': 0.57754403}
I0916 15:15:25.985682 139993253058368 controller.py:466] train | step:  11200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.6202685,
     'losses/train_total_loss': 0.6202685}
I0916 15:17:05.469007 139993253058368 controller.py:466] train | step:  11300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.588974,
     'losses/train_total_loss': 0.588974}
I0916 15:18:44.858797 139993253058368 controller.py:466] train | step:  11400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.61624956,
     'losses/train_total_loss': 0.61624956}
I0916 15:20:24.088134 139993253058368 controller.py:466] train | step:  11500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5924092,
     'losses/train_total_loss': 0.5924092}
I0916 15:22:03.231197 139993253058368 controller.py:466] train | step:  11600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.57400477,
     'losses/train_total_loss': 0.57400477}
I0916 15:23:42.833820 139993253058368 controller.py:466] train | step:  11700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.6021154,
     'losses/train_total_loss': 0.6021154}
I0916 15:25:22.188200 139993253058368 controller.py:466] train | step:  11800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.6045361,
     'losses/train_total_loss': 0.6045361}
I0916 15:27:01.705486 139993253058368 controller.py:466] train | step:  11900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.60324013,
     'losses/train_total_loss': 0.60324013}
I0916 15:28:41.702217 139993253058368 controller.py:466] train | step:  12000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.6026741,
     'losses/train_total_loss': 0.6026741}
I0916 15:28:42.370512 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-12000.
I0916 15:28:42.371108 139993253058368 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0916 15:29:29.616920 139993253058368 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 15:29:29.621690 139993253058368 controller.py:295]  eval | step:  12000 | eval time:   47.2 sec | output: 
    {'evaluation/iou/IoU': 0.7094866,
     'losses/eval_semantic_loss': 0.51768214,
     'losses/eval_total_loss': 0.51768214}
I0916 15:29:29.627876 139993253058368 controller.py:241] train | step:  12000 | training until step 16000...
I0916 15:31:28.486041 139993253058368 controller.py:466] train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.58097005,
     'losses/train_total_loss': 0.58097005}
I0916 15:33:28.754423 139993253058368 controller.py:466] train | step:  12200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.61427385,
     'losses/train_total_loss': 0.61427385}
I0916 15:35:27.817153 139993253058368 controller.py:466] train | step:  12300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.6135773,
     'losses/train_total_loss': 0.6135773}
I0916 15:37:26.845843 139993253058368 controller.py:466] train | step:  12400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.59166235,
     'losses/train_total_loss': 0.59166235}
I0916 15:39:27.456103 139993253058368 controller.py:466] train | step:  12500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.60765654,
     'losses/train_total_loss': 0.60765654}
I0916 15:41:25.662660 139993253058368 controller.py:466] train | step:  12600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.59619,
     'losses/train_total_loss': 0.59619}
I0916 15:43:24.662446 139993253058368 controller.py:466] train | step:  12700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.6449124,
     'losses/train_total_loss': 0.6449124}
I0916 15:45:23.562244 139993253058368 controller.py:466] train | step:  12800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.57798636,
     'losses/train_total_loss': 0.57798636}
I0916 15:47:22.056514 139993253058368 controller.py:466] train | step:  12900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5765721,
     'losses/train_total_loss': 0.5765721}
I0916 15:49:20.528662 139993253058368 controller.py:466] train | step:  13000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.5751414,
     'losses/train_total_loss': 0.5751414}
I0916 15:49:21.257784 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-13000.

train | step:   8800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.66648364,
     'losses/train_total_loss': 0.66648364}
train | step:   8900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.661905,
     'losses/train_total_loss': 0.661905}
train | step:   9000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.6421656,
     'losses/train_total_loss': 0.6421656}
saved checkpoint to results/exp_009/ckpt-9000.
train | step:   9100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.64943403,
     'losses/train_total_loss': 0.64943403}
train | step:   9200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.64422613,
     'losses/train_total_loss': 0.64422613}
train | step:   9300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.6005712,
     'losses/train_total_loss': 0.6005712}
train | step:   9400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.6279144,
     'losses/train_total_loss': 0.6279144}
train | step:   9500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.61496854,
     'losses/train_total_loss': 0.61496854}
train | step:   9600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.64096284,
     'losses/train_total_loss': 0.64096284}
train | step:   9700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.6261613,
     'losses/train_total_loss': 0.6261613}
train | step:   9800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.6496198,
     'losses/train_total_loss': 0.6496198}
train | step:   9900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.61424714,
     'losses/train_total_loss': 0.61424714}
train | step:  10000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.60293853,
     'losses/train_total_loss': 0.60293853}
saved checkpoint to results/exp_009/ckpt-10000.
train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.6437751,
     'losses/train_total_loss': 0.6437751}
train | step:  10200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.6244176,
     'losses/train_total_loss': 0.6244176}
train | step:  10300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.59885526,
     'losses/train_total_loss': 0.59885526}
train | step:  10400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.62945455,
     'losses/train_total_loss': 0.62945455}
train | step:  10500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.6047382,
     'losses/train_total_loss': 0.6047382}
train | step:  10600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.6173184,
     'losses/train_total_loss': 0.6173184}
train | step:  10700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.58933574,
     'losses/train_total_loss': 0.58933574}
train | step:  10800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.5857981,
     'losses/train_total_loss': 0.5857981}
train | step:  10900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5830109,
     'losses/train_total_loss': 0.5830109}
train | step:  11000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.6346272,
     'losses/train_total_loss': 0.6346272}
saved checkpoint to results/exp_009/ckpt-11000.
train | step:  11100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.57754403,
     'losses/train_total_loss': 0.57754403}
train | step:  11200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.6202685,
     'losses/train_total_loss': 0.6202685}
train | step:  11300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.588974,
     'losses/train_total_loss': 0.588974}
train | step:  11400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.61624956,
     'losses/train_total_loss': 0.61624956}
train | step:  11500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5924092,
     'losses/train_total_loss': 0.5924092}
train | step:  11600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.57400477,
     'losses/train_total_loss': 0.57400477}
train | step:  11700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.6021154,
     'losses/train_total_loss': 0.6021154}
train | step:  11800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.6045361,
     'losses/train_total_loss': 0.6045361}
train | step:  11900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.60324013,
     'losses/train_total_loss': 0.60324013}
train | step:  12000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.6026741,
     'losses/train_total_loss': 0.6026741}
saved checkpoint to results/exp_009/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   47.2 sec | output: 
    {'evaluation/iou/IoU': 0.7094866,
     'losses/eval_semantic_loss': 0.51768214,
     'losses/eval_total_loss': 0.51768214}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.58097005,
     'losses/train_total_loss': 0.58097005}
train | step:  12200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.61427385,
     'losses/train_total_loss': 0.61427385}
train | step:  12300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.6135773,
     'losses/train_total_loss': 0.6135773}
train | step:  12400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.59166235,
     'losses/train_total_loss': 0.59166235}
train | step:  12500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.60765654,
     'losses/train_total_loss': 0.60765654}
train | step:  12600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.59619,
     'losses/train_total_loss': 0.59619}
train | step:  12700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.6449124,
     'losses/train_total_loss': 0.6449124}
train | step:  12800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.57798636,
     'losses/train_total_loss': 0.57798636}
train | step:  12900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5765721,
     'losses/train_total_loss': 0.5765721}
train | step:  13000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.5751414,
     'losses/train_total_loss': 0.5751414}
saved checkpoint to results/exp_009/ckpt-13000.I0916 15:51:00.317822 139993253058368 controller.py:466] train | step:  13100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.56480306,
     'losses/train_total_loss': 0.56480306}
I0916 15:52:39.569823 139993253058368 controller.py:466] train | step:  13200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.61339736,
     'losses/train_total_loss': 0.61339736}
I0916 15:54:18.884956 139993253058368 controller.py:466] train | step:  13300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.57462466,
     'losses/train_total_loss': 0.57462466}
I0916 15:55:58.263924 139993253058368 controller.py:466] train | step:  13400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.58930403,
     'losses/train_total_loss': 0.58930403}
I0916 15:57:37.373521 139993253058368 controller.py:466] train | step:  13500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.6033851,
     'losses/train_total_loss': 0.6033851}
I0916 15:59:16.534745 139993253058368 controller.py:466] train | step:  13600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.6010087,
     'losses/train_total_loss': 0.6010087}
I0916 16:00:55.698807 139993253058368 controller.py:466] train | step:  13700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.565874,
     'losses/train_total_loss': 0.565874}
I0916 16:02:34.862255 139993253058368 controller.py:466] train | step:  13800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.5806792,
     'losses/train_total_loss': 0.5806792}
I0916 16:04:13.973078 139993253058368 controller.py:466] train | step:  13900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.6155327,
     'losses/train_total_loss': 0.6155327}
I0916 16:05:52.902733 139993253058368 controller.py:466] train | step:  14000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.57636404,
     'losses/train_total_loss': 0.57636404}
I0916 16:05:53.517680 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-14000.
I0916 16:07:32.595336 139993253058368 controller.py:466] train | step:  14100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.6011487,
     'losses/train_total_loss': 0.6011487}
I0916 16:09:11.922886 139993253058368 controller.py:466] train | step:  14200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.5840258,
     'losses/train_total_loss': 0.5840258}
I0916 16:10:51.102066 139993253058368 controller.py:466] train | step:  14300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.55177546,
     'losses/train_total_loss': 0.55177546}
I0916 16:12:30.231501 139993253058368 controller.py:466] train | step:  14400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.61096513,
     'losses/train_total_loss': 0.61096513}
I0916 16:14:09.623514 139993253058368 controller.py:466] train | step:  14500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5979324,
     'losses/train_total_loss': 0.5979324}
I0916 16:15:48.786030 139993253058368 controller.py:466] train | step:  14600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.57826376,
     'losses/train_total_loss': 0.57826376}
I0916 16:17:28.116200 139993253058368 controller.py:466] train | step:  14700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.59529257,
     'losses/train_total_loss': 0.59529257}
I0916 16:19:07.281318 139993253058368 controller.py:466] train | step:  14800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.5264065,
     'losses/train_total_loss': 0.5264065}
I0916 16:20:46.504916 139993253058368 controller.py:466] train | step:  14900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.56977504,
     'losses/train_total_loss': 0.56977504}
I0916 16:22:25.563378 139993253058368 controller.py:466] train | step:  15000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.58183306,
     'losses/train_total_loss': 0.58183306}
I0916 16:22:26.603633 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-15000.
I0916 16:24:05.450794 139993253058368 controller.py:466] train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.5673795,
     'losses/train_total_loss': 0.5673795}
I0916 16:25:44.402522 139993253058368 controller.py:466] train | step:  15200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.540894,
     'losses/train_total_loss': 0.540894}
I0916 16:27:23.327497 139993253058368 controller.py:466] train | step:  15300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.55292845,
     'losses/train_total_loss': 0.55292845}
I0916 16:29:02.099082 139993253058368 controller.py:466] train | step:  15400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.5721811,
     'losses/train_total_loss': 0.5721811}
I0916 16:30:40.856525 139993253058368 controller.py:466] train | step:  15500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.5852647,
     'losses/train_total_loss': 0.5852647}
I0916 16:32:19.737583 139993253058368 controller.py:466] train | step:  15600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.53655696,
     'losses/train_total_loss': 0.53655696}
I0916 16:33:58.570742 139993253058368 controller.py:466] train | step:  15700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.54421526,
     'losses/train_total_loss': 0.54421526}
I0916 16:35:37.349975 139993253058368 controller.py:466] train | step:  15800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.58945876,
     'losses/train_total_loss': 0.58945876}
I0916 16:37:15.879054 139993253058368 controller.py:466] train | step:  15900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.5517118,
     'losses/train_total_loss': 0.5517118}
I0916 16:38:54.589022 139993253058368 controller.py:466] train | step:  16000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.5583928,
     'losses/train_total_loss': 0.5583928}
I0916 16:38:55.484941 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-16000.
I0916 16:38:55.485728 139993253058368 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0916 16:39:44.114888 139993253058368 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 16:39:44.129180 139993253058368 controller.py:295]  eval | step:  16000 | eval time:   48.6 sec | output: 
    {'evaluation/iou/IoU': 0.71834457,
     'losses/eval_semantic_loss': 0.48963726,
     'losses/eval_total_loss': 0.48963726}
I0916 16:39:44.134465 139993253058368 controller.py:241] train | step:  16000 | training until step 20000...
I0916 16:41:23.101279 139993253058368 controller.py:466] train | step:  16100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.58474344,
     'losses/train_total_loss': 0.58474344}
I0916 16:43:02.248820 139993253058368 controller.py:466] train | step:  16200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.56595826,
     'losses/train_total_loss': 0.56595826}
I0916 16:44:41.128147 139993253058368 controller.py:466] train | step:  16300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.5576348,
     'losses/train_total_loss': 0.5576348}
I0916 16:46:20.197688 139993253058368 controller.py:466] train | step:  16400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.5437533,
     'losses/train_total_loss': 0.5437533}
I0916 16:47:59.007263 139993253058368 controller.py:466] train | step:  16500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5628407,
     'losses/train_total_loss': 0.5628407}
I0916 16:49:38.164901 139993253058368 controller.py:466] train | step:  16600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.56475973,
     'losses/train_total_loss': 0.56475973}
I0916 16:51:17.074163 139993253058368 controller.py:466] train | step:  16700 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.5501368,
     'losses/train_total_loss': 0.5501368}
I0916 16:52:55.943084 139993253058368 controller.py:466] train | step:  16800 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.52655303,
     'losses/train_total_loss': 0.52655303}
I0916 16:54:34.888253 139993253058368 controller.py:466] train | step:  16900 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.58109456,
     'losses/train_total_loss': 0.58109456}
I0916 16:56:14.116662 139993253058368 controller.py:466] train | step:  17000 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.55471253,
     'losses/train_total_loss': 0.55471253}
I0916 16:56:14.834533 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-17000.
I0916 16:57:53.988779 139993253058368 controller.py:466] train | step:  17100 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.5436243,
     'losses/train_total_loss': 0.5436243}
I0916 16:59:33.059428 139993253058368 controller.py:466] train | step:  17200 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.5495485,
     'losses/train_total_loss': 0.5495485}
I0916 17:01:12.165275 139993253058368 controller.py:466] train | step:  17300 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.53849316,
     'losses/train_total_loss': 0.53849316}
I0916 17:02:51.240182 139993253058368 controller.py:466] train | step:  17400 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.546367,
     'losses/train_total_loss': 0.546367}

train | step:  13100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.56480306,
     'losses/train_total_loss': 0.56480306}
train | step:  13200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.61339736,
     'losses/train_total_loss': 0.61339736}
train | step:  13300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.57462466,
     'losses/train_total_loss': 0.57462466}
train | step:  13400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.58930403,
     'losses/train_total_loss': 0.58930403}
train | step:  13500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.6033851,
     'losses/train_total_loss': 0.6033851}
train | step:  13600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.6010087,
     'losses/train_total_loss': 0.6010087}
train | step:  13700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.565874,
     'losses/train_total_loss': 0.565874}
train | step:  13800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.5806792,
     'losses/train_total_loss': 0.5806792}
train | step:  13900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.6155327,
     'losses/train_total_loss': 0.6155327}
train | step:  14000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.57636404,
     'losses/train_total_loss': 0.57636404}
saved checkpoint to results/exp_009/ckpt-14000.
train | step:  14100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.6011487,
     'losses/train_total_loss': 0.6011487}
train | step:  14200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.5840258,
     'losses/train_total_loss': 0.5840258}
train | step:  14300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.55177546,
     'losses/train_total_loss': 0.55177546}
train | step:  14400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.61096513,
     'losses/train_total_loss': 0.61096513}
train | step:  14500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5979324,
     'losses/train_total_loss': 0.5979324}
train | step:  14600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.57826376,
     'losses/train_total_loss': 0.57826376}
train | step:  14700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.59529257,
     'losses/train_total_loss': 0.59529257}
train | step:  14800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.5264065,
     'losses/train_total_loss': 0.5264065}
train | step:  14900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.56977504,
     'losses/train_total_loss': 0.56977504}
train | step:  15000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.58183306,
     'losses/train_total_loss': 0.58183306}
saved checkpoint to results/exp_009/ckpt-15000.
train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.5673795,
     'losses/train_total_loss': 0.5673795}
train | step:  15200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.540894,
     'losses/train_total_loss': 0.540894}
train | step:  15300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.55292845,
     'losses/train_total_loss': 0.55292845}
train | step:  15400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.5721811,
     'losses/train_total_loss': 0.5721811}
train | step:  15500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.5852647,
     'losses/train_total_loss': 0.5852647}
train | step:  15600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.53655696,
     'losses/train_total_loss': 0.53655696}
train | step:  15700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.54421526,
     'losses/train_total_loss': 0.54421526}
train | step:  15800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.58945876,
     'losses/train_total_loss': 0.58945876}
train | step:  15900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.5517118,
     'losses/train_total_loss': 0.5517118}
train | step:  16000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.5583928,
     'losses/train_total_loss': 0.5583928}
saved checkpoint to results/exp_009/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   48.6 sec | output: 
    {'evaluation/iou/IoU': 0.71834457,
     'losses/eval_semantic_loss': 0.48963726,
     'losses/eval_total_loss': 0.48963726}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.58474344,
     'losses/train_total_loss': 0.58474344}
train | step:  16200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.56595826,
     'losses/train_total_loss': 0.56595826}
train | step:  16300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.5576348,
     'losses/train_total_loss': 0.5576348}
train | step:  16400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.5437533,
     'losses/train_total_loss': 0.5437533}
train | step:  16500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5628407,
     'losses/train_total_loss': 0.5628407}
train | step:  16600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.56475973,
     'losses/train_total_loss': 0.56475973}
train | step:  16700 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.5501368,
     'losses/train_total_loss': 0.5501368}
train | step:  16800 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.52655303,
     'losses/train_total_loss': 0.52655303}
train | step:  16900 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.58109456,
     'losses/train_total_loss': 0.58109456}
train | step:  17000 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.55471253,
     'losses/train_total_loss': 0.55471253}
saved checkpoint to results/exp_009/ckpt-17000.
train | step:  17100 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.5436243,
     'losses/train_total_loss': 0.5436243}
train | step:  17200 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.5495485,
     'losses/train_total_loss': 0.5495485}
train | step:  17300 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.53849316,
     'losses/train_total_loss': 0.53849316}
train | step:  17400 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.546367,
     'losses/train_total_loss': 0.546367}I0916 17:04:30.228876 139993253058368 controller.py:466] train | step:  17500 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.59281695,
     'losses/train_total_loss': 0.59281695}
I0916 17:06:09.258921 139993253058368 controller.py:466] train | step:  17600 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.5340574,
     'losses/train_total_loss': 0.5340574}
I0916 17:07:48.315619 139993253058368 controller.py:466] train | step:  17700 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.528236,
     'losses/train_total_loss': 0.528236}
I0916 17:09:27.700083 139993253058368 controller.py:466] train | step:  17800 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.53968,
     'losses/train_total_loss': 0.53968}
I0916 17:11:06.849264 139993253058368 controller.py:466] train | step:  17900 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.59584546,
     'losses/train_total_loss': 0.59584546}
I0916 17:12:46.255469 139993253058368 controller.py:466] train | step:  18000 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.5543453,
     'losses/train_total_loss': 0.5543453}
I0916 17:12:46.959523 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-18000.
I0916 17:14:25.671059 139993253058368 controller.py:466] train | step:  18100 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.54964566,
     'losses/train_total_loss': 0.54964566}
I0916 17:16:04.375655 139993253058368 controller.py:466] train | step:  18200 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.55990106,
     'losses/train_total_loss': 0.55990106}
I0916 17:17:42.838378 139993253058368 controller.py:466] train | step:  18300 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.5251314,
     'losses/train_total_loss': 0.5251314}
I0916 17:19:21.604518 139993253058368 controller.py:466] train | step:  18400 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.5383281,
     'losses/train_total_loss': 0.5383281}
I0916 17:21:00.287234 139993253058368 controller.py:466] train | step:  18500 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.53540653,
     'losses/train_total_loss': 0.53540653}
I0916 17:22:39.172487 139993253058368 controller.py:466] train | step:  18600 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.51369554,
     'losses/train_total_loss': 0.51369554}
I0916 17:24:18.112235 139993253058368 controller.py:466] train | step:  18700 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.5593563,
     'losses/train_total_loss': 0.5593563}
I0916 17:25:56.881536 139993253058368 controller.py:466] train | step:  18800 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.5408882,
     'losses/train_total_loss': 0.5408882}
I0916 17:27:35.780164 139993253058368 controller.py:466] train | step:  18900 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.5219931,
     'losses/train_total_loss': 0.5219931}
I0916 17:29:14.584206 139993253058368 controller.py:466] train | step:  19000 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.5307549,
     'losses/train_total_loss': 0.5307549}
I0916 17:29:15.249710 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-19000.
I0916 17:30:53.931853 139993253058368 controller.py:466] train | step:  19100 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.5047991,
     'losses/train_total_loss': 0.5047991}
I0916 17:32:32.705790 139993253058368 controller.py:466] train | step:  19200 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.5737455,
     'losses/train_total_loss': 0.5737455}
I0916 17:34:11.463684 139993253058368 controller.py:466] train | step:  19300 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.5247908,
     'losses/train_total_loss': 0.5247908}
I0916 17:35:50.010617 139993253058368 controller.py:466] train | step:  19400 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.5504202,
     'losses/train_total_loss': 0.5504202}
I0916 17:37:28.878317 139993253058368 controller.py:466] train | step:  19500 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.51040465,
     'losses/train_total_loss': 0.51040465}
I0916 17:39:07.741587 139993253058368 controller.py:466] train | step:  19600 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.53924894,
     'losses/train_total_loss': 0.53924894}
I0916 17:40:46.542213 139993253058368 controller.py:466] train | step:  19700 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.5436947,
     'losses/train_total_loss': 0.5436947}
I0916 17:42:25.421073 139993253058368 controller.py:466] train | step:  19800 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.5403972,
     'losses/train_total_loss': 0.5403972}
I0916 17:44:04.060896 139993253058368 controller.py:466] train | step:  19900 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.55065215,
     'losses/train_total_loss': 0.55065215}
I0916 17:45:42.898239 139993253058368 controller.py:466] train | step:  20000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.522259,
     'losses/train_total_loss': 0.522259}
I0916 17:45:43.618530 139993253058368 controller.py:495] saved checkpoint to results/exp_009/ckpt-20000.
I0916 17:45:43.619393 139993253058368 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0916 17:46:31.346608 139993253058368 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 17:46:31.351613 139993253058368 controller.py:295]  eval | step:  20000 | eval time:   47.7 sec | output: 
    {'evaluation/iou/IoU': 0.73152995,
     'losses/eval_semantic_loss': 0.44888827,
     'losses/eval_total_loss': 0.44888827}

train | step:  17500 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.59281695,
     'losses/train_total_loss': 0.59281695}
train | step:  17600 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.5340574,
     'losses/train_total_loss': 0.5340574}
train | step:  17700 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.528236,
     'losses/train_total_loss': 0.528236}
train | step:  17800 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.53968,
     'losses/train_total_loss': 0.53968}
train | step:  17900 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.59584546,
     'losses/train_total_loss': 0.59584546}
train | step:  18000 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.5543453,
     'losses/train_total_loss': 0.5543453}
saved checkpoint to results/exp_009/ckpt-18000.
train | step:  18100 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.54964566,
     'losses/train_total_loss': 0.54964566}
train | step:  18200 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.55990106,
     'losses/train_total_loss': 0.55990106}
train | step:  18300 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.5251314,
     'losses/train_total_loss': 0.5251314}
train | step:  18400 | steps/sec:    1.0 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.5383281,
     'losses/train_total_loss': 0.5383281}
train | step:  18500 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.53540653,
     'losses/train_total_loss': 0.53540653}
train | step:  18600 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.51369554,
     'losses/train_total_loss': 0.51369554}
train | step:  18700 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.5593563,
     'losses/train_total_loss': 0.5593563}
train | step:  18800 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.5408882,
     'losses/train_total_loss': 0.5408882}
train | step:  18900 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.5219931,
     'losses/train_total_loss': 0.5219931}
train | step:  19000 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.5307549,
     'losses/train_total_loss': 0.5307549}
saved checkpoint to results/exp_009/ckpt-19000.
train | step:  19100 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.5047991,
     'losses/train_total_loss': 0.5047991}
train | step:  19200 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.5737455,
     'losses/train_total_loss': 0.5737455}
train | step:  19300 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.5247908,
     'losses/train_total_loss': 0.5247908}
train | step:  19400 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.5504202,
     'losses/train_total_loss': 0.5504202}
train | step:  19500 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.51040465,
     'losses/train_total_loss': 0.51040465}
train | step:  19600 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.53924894,
     'losses/train_total_loss': 0.53924894}
train | step:  19700 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.5436947,
     'losses/train_total_loss': 0.5436947}
train | step:  19800 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.5403972,
     'losses/train_total_loss': 0.5403972}
train | step:  19900 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.55065215,
     'losses/train_total_loss': 0.55065215}
train | step:  20000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.522259,
     'losses/train_total_loss': 0.522259}
saved checkpoint to results/exp_009/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   47.7 sec | output: 
    {'evaluation/iou/IoU': 0.73152995,
     'losses/eval_semantic_loss': 0.44888827,
     'losses/eval_total_loss': 0.44888827}
