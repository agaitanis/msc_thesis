I0916 20:48:56.460585 139757943469888 train.py:65] Reading the config file.
I0916 20:48:56.462271 139757943469888 train.py:69] Starting the experiment.
2022-09-16 20:48:56.462680: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-16 20:48:56.871216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0916 20:48:56.873373 139757943469888 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0916 20:48:57.003999 139757943469888 deeplab.py:57] Synchronized Batchnorm is used.
I0916 20:48:57.005033 139757943469888 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0916 20:48:57.104575 139757943469888 deeplab.py:96] Setting pooling size to (46, 46)
I0916 20:48:57.104690 139757943469888 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 20:48:59.996151 139757943469888 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0916 20:49:00.010476 139757943469888 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0916 20:49:00.021396 139757943469888 controller.py:399] initialized model.
I0916 20:49:00.727333 139757943469888 api.py:447] Eval with scales ListWrapper([1.0])
I0916 20:49:01.535334 139757943469888 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 20:49:01.553654 139757943469888 api.py:447] Eval scale 1.0; setting pooling size to [46, 46]
I0916 20:49:04.481238 139757943469888 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 20:49:04.849219 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-0.
I0916 20:49:04.849849 139757943469888 controller.py:241] train | step:      0 | training until step 4000...
2022-09-16 20:49:23.506691: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0916 20:50:54.378838 139757943469888 controller.py:466] train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.0916668,
     'losses/train_total_loss': 1.0916668}
I0916 20:52:24.226493 139757943469888 controller.py:466] train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 0.9824058,
     'losses/train_total_loss': 0.9824058}
I0916 20:53:54.377469 139757943469888 controller.py:466] train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.9575645,
     'losses/train_total_loss': 0.9575645}
I0916 20:55:24.754614 139757943469888 controller.py:466] train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.9060878,
     'losses/train_total_loss': 0.9060878}
I0916 20:56:55.393220 139757943469888 controller.py:466] train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.8980378,
     'losses/train_total_loss': 0.8980378}
I0916 20:58:27.096208 139757943469888 controller.py:466] train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.9011615,
     'losses/train_total_loss': 0.9011615}
I0916 20:59:57.671709 139757943469888 controller.py:466] train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.88770986,
     'losses/train_total_loss': 0.88770986}
I0916 21:01:28.717472 139757943469888 controller.py:466] train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.87642074,
     'losses/train_total_loss': 0.87642074}
I0916 21:03:00.019304 139757943469888 controller.py:466] train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.85262865,
     'losses/train_total_loss': 0.85262865}
I0916 21:04:30.866150 139757943469888 controller.py:466] train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.8562338,
     'losses/train_total_loss': 0.8562338}
I0916 21:04:31.713044 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-1000.
I0916 21:06:02.560258 139757943469888 controller.py:466] train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.86192864,
     'losses/train_total_loss': 0.86192864}
I0916 21:07:31.908255 139757943469888 controller.py:466] train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.79908013,
     'losses/train_total_loss': 0.79908013}
I0916 21:09:02.639832 139757943469888 controller.py:466] train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.84612894,
     'losses/train_total_loss': 0.84612894}
I0916 21:10:33.599066 139757943469888 controller.py:466] train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.78961754,
     'losses/train_total_loss': 0.78961754}
I0916 21:12:04.219559 139757943469888 controller.py:466] train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.7707459,
     'losses/train_total_loss': 0.7707459}
I0916 21:13:35.475851 139757943469888 controller.py:466] train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.77112967,
     'losses/train_total_loss': 0.77112967}
I0916 21:15:06.355863 139757943469888 controller.py:466] train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.79755056,
     'losses/train_total_loss': 0.79755056}
I0916 21:16:36.939242 139757943469888 controller.py:466] train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.8043662,
     'losses/train_total_loss': 0.8043662}
I0916 21:18:07.294757 139757943469888 controller.py:466] train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.7523141,
     'losses/train_total_loss': 0.7523141}
I0916 21:19:38.570749 139757943469888 controller.py:466] train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.7820573,
     'losses/train_total_loss': 0.7820573}
I0916 21:19:39.445832 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-2000.
I0916 21:21:09.507043 139757943469888 controller.py:466] train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.7717712,
     'losses/train_total_loss': 0.7717712}
I0916 21:22:41.058371 139757943469888 controller.py:466] train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.7558302,
     'losses/train_total_loss': 0.7558302}
I0916 21:24:12.154914 139757943469888 controller.py:466] train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.7637944,
     'losses/train_total_loss': 0.7637944}
I0916 21:25:42.947230 139757943469888 controller.py:466] train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.7689016,
     'losses/train_total_loss': 0.7689016}
I0916 21:27:13.113844 139757943469888 controller.py:466] train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7531095,
     'losses/train_total_loss': 0.7531095}
I0916 21:28:44.185220 139757943469888 controller.py:466] train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.7479362,
     'losses/train_total_loss': 0.7479362}
I0916 21:30:14.867867 139757943469888 controller.py:466] train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.74856997,
     'losses/train_total_loss': 0.74856997}
I0916 21:31:45.243274 139757943469888 controller.py:466] train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.72551227,
     'losses/train_total_loss': 0.72551227}
I0916 21:33:15.921622 139757943469888 controller.py:466] train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.74451447,
     'losses/train_total_loss': 0.74451447}
I0916 21:34:46.909623 139757943469888 controller.py:466] train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7321786,
     'losses/train_total_loss': 0.7321786}
I0916 21:34:47.966009 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-3000.
I0916 21:36:18.533155 139757943469888 controller.py:466] train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.7017654,
     'losses/train_total_loss': 0.7017654}
I0916 21:37:49.368256 139757943469888 controller.py:466] train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.73937297,
     'losses/train_total_loss': 0.73937297}
I0916 21:39:19.933630 139757943469888 controller.py:466] train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.6982613,
     'losses/train_total_loss': 0.6982613}
I0916 21:40:50.759483 139757943469888 controller.py:466] train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.7106451,
     'losses/train_total_loss': 0.7106451}
I0916 21:42:20.733448 139757943469888 controller.py:466] train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.7096394,
     'losses/train_total_loss': 0.7096394}
I0916 21:43:51.139306 139757943469888 controller.py:466] train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.7028316,
     'losses/train_total_loss': 0.7028316}
I0916 21:45:21.798353 139757943469888 controller.py:466] train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.7054084,
     'losses/train_total_loss': 0.7054084}
I0916 21:46:52.182948 139757943469888 controller.py:466] train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.7123918,
     'losses/train_total_loss': 0.7123918}
I0916 21:48:22.902339 139757943469888 controller.py:466] train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.68211645,
     'losses/train_total_loss': 0.68211645}
I0916 21:49:53.807250 139757943469888 controller.py:466] train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.7085467,
     'losses/train_total_loss': 0.7085467}
I0916 21:49:54.563085 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-4000.
I0916 21:49:54.563657 139757943469888 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0916 21:49:55.192895 139757943469888 api.py:447] Eval with scales ListWrapper([1.0])
I0916 21:49:55.221410 139757943469888 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 21:49:55.246178 139757943469888 api.py:447] Eval scale 1.0; setting pooling size to [46, 46]
I0916 21:49:55.880759 139757943469888 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 21:50:40.111103 139757943469888 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 21:50:40.139672 139757943469888 controller.py:295]  eval | step:   4000 | eval time:   45.6 sec | output: 
    {'evaluation/iou/IoU': 0.60622215,
     'losses/eval_semantic_loss': 0.7872851,
     'losses/eval_total_loss': 0.7872851}
I0916 21:50:40.146501 139757943469888 controller.py:241] train | step:   4000 | training until step 8000...
I0916 21:52:10.695821 139757943469888 controller.py:466] train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.72453797,
     'losses/train_total_loss': 0.72453797}
I0916 21:53:41.187985 139757943469888 controller.py:466] train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.7233828,
     'losses/train_total_loss': 0.7233828}
I0916 21:55:11.682098 139757943469888 controller.py:466] train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.68548894,
     'losses/train_total_loss': 0.68548894}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_010/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.0916668,
     'losses/train_total_loss': 1.0916668}
train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 0.9824058,
     'losses/train_total_loss': 0.9824058}
train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.9575645,
     'losses/train_total_loss': 0.9575645}
train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.9060878,
     'losses/train_total_loss': 0.9060878}
train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.8980378,
     'losses/train_total_loss': 0.8980378}
train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.9011615,
     'losses/train_total_loss': 0.9011615}
train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.88770986,
     'losses/train_total_loss': 0.88770986}
train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.87642074,
     'losses/train_total_loss': 0.87642074}
train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.85262865,
     'losses/train_total_loss': 0.85262865}
train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.8562338,
     'losses/train_total_loss': 0.8562338}
saved checkpoint to results/exp_010/ckpt-1000.
train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.86192864,
     'losses/train_total_loss': 0.86192864}
train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.79908013,
     'losses/train_total_loss': 0.79908013}
train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.84612894,
     'losses/train_total_loss': 0.84612894}
train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.78961754,
     'losses/train_total_loss': 0.78961754}
train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.7707459,
     'losses/train_total_loss': 0.7707459}
train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.77112967,
     'losses/train_total_loss': 0.77112967}
train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.79755056,
     'losses/train_total_loss': 0.79755056}
train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.8043662,
     'losses/train_total_loss': 0.8043662}
train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.7523141,
     'losses/train_total_loss': 0.7523141}
train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.7820573,
     'losses/train_total_loss': 0.7820573}
saved checkpoint to results/exp_010/ckpt-2000.
train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.7717712,
     'losses/train_total_loss': 0.7717712}
train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.7558302,
     'losses/train_total_loss': 0.7558302}
train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.7637944,
     'losses/train_total_loss': 0.7637944}
train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.7689016,
     'losses/train_total_loss': 0.7689016}
train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7531095,
     'losses/train_total_loss': 0.7531095}
train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.7479362,
     'losses/train_total_loss': 0.7479362}
train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.74856997,
     'losses/train_total_loss': 0.74856997}
train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.72551227,
     'losses/train_total_loss': 0.72551227}
train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.74451447,
     'losses/train_total_loss': 0.74451447}
train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7321786,
     'losses/train_total_loss': 0.7321786}
saved checkpoint to results/exp_010/ckpt-3000.
train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.7017654,
     'losses/train_total_loss': 0.7017654}
train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.73937297,
     'losses/train_total_loss': 0.73937297}
train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.6982613,
     'losses/train_total_loss': 0.6982613}
train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.7106451,
     'losses/train_total_loss': 0.7106451}
train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.7096394,
     'losses/train_total_loss': 0.7096394}
train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.7028316,
     'losses/train_total_loss': 0.7028316}
train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.7054084,
     'losses/train_total_loss': 0.7054084}
train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.7123918,
     'losses/train_total_loss': 0.7123918}
train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.68211645,
     'losses/train_total_loss': 0.68211645}
train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.7085467,
     'losses/train_total_loss': 0.7085467}
saved checkpoint to results/exp_010/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   45.6 sec | output: 
    {'evaluation/iou/IoU': 0.60622215,
     'losses/eval_semantic_loss': 0.7872851,
     'losses/eval_total_loss': 0.7872851}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.72453797,
     'losses/train_total_loss': 0.72453797}
train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.7233828,
     'losses/train_total_loss': 0.7233828}
train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.68548894,
     'losses/train_total_loss': 0.68548894}I0916 21:56:42.478463 139757943469888 controller.py:466] train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.7222208,
     'losses/train_total_loss': 0.7222208}
I0916 21:58:12.272376 139757943469888 controller.py:466] train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.6853987,
     'losses/train_total_loss': 0.6853987}
I0916 21:59:42.656723 139757943469888 controller.py:466] train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.6977665,
     'losses/train_total_loss': 0.6977665}
I0916 22:01:12.610003 139757943469888 controller.py:466] train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.7202022,
     'losses/train_total_loss': 0.7202022}
I0916 22:02:42.888709 139757943469888 controller.py:466] train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.69165874,
     'losses/train_total_loss': 0.69165874}
I0916 22:04:13.273573 139757943469888 controller.py:466] train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.69872946,
     'losses/train_total_loss': 0.69872946}
I0916 22:05:44.422371 139757943469888 controller.py:466] train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.7107173,
     'losses/train_total_loss': 0.7107173}
I0916 22:05:45.227595 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-5000.
I0916 22:07:15.219942 139757943469888 controller.py:466] train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.6787493,
     'losses/train_total_loss': 0.6787493}
I0916 22:08:45.751433 139757943469888 controller.py:466] train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.69993055,
     'losses/train_total_loss': 0.69993055}
I0916 22:10:15.931220 139757943469888 controller.py:466] train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.6623188,
     'losses/train_total_loss': 0.6623188}
I0916 22:11:46.872077 139757943469888 controller.py:466] train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.6737831,
     'losses/train_total_loss': 0.6737831}
I0916 22:13:17.685472 139757943469888 controller.py:466] train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.6754053,
     'losses/train_total_loss': 0.6754053}
I0916 22:14:48.675364 139757943469888 controller.py:466] train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.6838347,
     'losses/train_total_loss': 0.6838347}
I0916 22:16:19.292145 139757943469888 controller.py:466] train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.66070265,
     'losses/train_total_loss': 0.66070265}
I0916 22:17:49.824142 139757943469888 controller.py:466] train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.6699725,
     'losses/train_total_loss': 0.6699725}
I0916 22:19:20.045025 139757943469888 controller.py:466] train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.6887653,
     'losses/train_total_loss': 0.6887653}
I0916 22:20:50.370229 139757943469888 controller.py:466] train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.6587007,
     'losses/train_total_loss': 0.6587007}
I0916 22:20:51.182788 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-6000.
I0916 22:22:21.407398 139757943469888 controller.py:466] train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.6639841,
     'losses/train_total_loss': 0.6639841}
I0916 22:23:52.481842 139757943469888 controller.py:466] train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.6759281,
     'losses/train_total_loss': 0.6759281}
I0916 22:25:23.083550 139757943469888 controller.py:466] train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.66174406,
     'losses/train_total_loss': 0.66174406}
I0916 22:26:53.568133 139757943469888 controller.py:466] train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.6657919,
     'losses/train_total_loss': 0.6657919}
I0916 22:28:23.820961 139757943469888 controller.py:466] train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.62824845,
     'losses/train_total_loss': 0.62824845}
I0916 22:29:54.044402 139757943469888 controller.py:466] train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.699794,
     'losses/train_total_loss': 0.699794}
I0916 22:31:24.453861 139757943469888 controller.py:466] train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6833061,
     'losses/train_total_loss': 0.6833061}
I0916 22:32:54.899268 139757943469888 controller.py:466] train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.64203143,
     'losses/train_total_loss': 0.64203143}
I0916 22:34:25.161131 139757943469888 controller.py:466] train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.7092813,
     'losses/train_total_loss': 0.7092813}
I0916 22:35:55.096959 139757943469888 controller.py:466] train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.6599836,
     'losses/train_total_loss': 0.6599836}
I0916 22:35:55.887353 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-7000.
I0916 22:37:26.448496 139757943469888 controller.py:466] train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.6380195,
     'losses/train_total_loss': 0.6380195}
I0916 22:38:57.432308 139757943469888 controller.py:466] train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.655441,
     'losses/train_total_loss': 0.655441}
I0916 22:40:28.180248 139757943469888 controller.py:466] train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.6625799,
     'losses/train_total_loss': 0.6625799}
I0916 22:41:59.085181 139757943469888 controller.py:466] train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.6924725,
     'losses/train_total_loss': 0.6924725}
I0916 22:43:29.764811 139757943469888 controller.py:466] train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.66752434,
     'losses/train_total_loss': 0.66752434}
I0916 22:45:00.680145 139757943469888 controller.py:466] train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.6125608,
     'losses/train_total_loss': 0.6125608}
I0916 22:46:31.063414 139757943469888 controller.py:466] train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.6357351,
     'losses/train_total_loss': 0.6357351}
I0916 22:48:01.552659 139757943469888 controller.py:466] train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.68215996,
     'losses/train_total_loss': 0.68215996}
I0916 22:49:32.636005 139757943469888 controller.py:466] train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.63393974,
     'losses/train_total_loss': 0.63393974}
I0916 22:51:02.926742 139757943469888 controller.py:466] train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.6014099,
     'losses/train_total_loss': 0.6014099}
I0916 22:51:03.871528 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-8000.
I0916 22:51:03.872419 139757943469888 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0916 22:51:44.780690 139757943469888 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 22:51:44.786037 139757943469888 controller.py:295]  eval | step:   8000 | eval time:   40.9 sec | output: 
    {'evaluation/iou/IoU': 0.690823,
     'losses/eval_semantic_loss': 0.5929465,
     'losses/eval_total_loss': 0.5929465}
I0916 22:51:44.791659 139757943469888 controller.py:241] train | step:   8000 | training until step 12000...
I0916 22:53:16.442423 139757943469888 controller.py:466] train | step:   8100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.67050385,
     'losses/train_total_loss': 0.67050385}
I0916 22:54:48.143684 139757943469888 controller.py:466] train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.6739372,
     'losses/train_total_loss': 0.6739372}
I0916 22:56:19.859764 139757943469888 controller.py:466] train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.67807466,
     'losses/train_total_loss': 0.67807466}
I0916 22:57:51.017414 139757943469888 controller.py:466] train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.5852926,
     'losses/train_total_loss': 0.5852926}
I0916 22:59:22.695283 139757943469888 controller.py:466] train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.6047256,
     'losses/train_total_loss': 0.6047256}
I0916 23:00:53.994195 139757943469888 controller.py:466] train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.64568305,
     'losses/train_total_loss': 0.64568305}
I0916 23:02:24.800499 139757943469888 controller.py:466] train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.6234908,
     'losses/train_total_loss': 0.6234908}

train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.7222208,
     'losses/train_total_loss': 0.7222208}
train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.6853987,
     'losses/train_total_loss': 0.6853987}
train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.6977665,
     'losses/train_total_loss': 0.6977665}
train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.7202022,
     'losses/train_total_loss': 0.7202022}
train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.69165874,
     'losses/train_total_loss': 0.69165874}
train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.69872946,
     'losses/train_total_loss': 0.69872946}
train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.7107173,
     'losses/train_total_loss': 0.7107173}
saved checkpoint to results/exp_010/ckpt-5000.
train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.6787493,
     'losses/train_total_loss': 0.6787493}
train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.69993055,
     'losses/train_total_loss': 0.69993055}
train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.6623188,
     'losses/train_total_loss': 0.6623188}
train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.6737831,
     'losses/train_total_loss': 0.6737831}
train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.6754053,
     'losses/train_total_loss': 0.6754053}
train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.6838347,
     'losses/train_total_loss': 0.6838347}
train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.66070265,
     'losses/train_total_loss': 0.66070265}
train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.6699725,
     'losses/train_total_loss': 0.6699725}
train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.6887653,
     'losses/train_total_loss': 0.6887653}
train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.6587007,
     'losses/train_total_loss': 0.6587007}
saved checkpoint to results/exp_010/ckpt-6000.
train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.6639841,
     'losses/train_total_loss': 0.6639841}
train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.6759281,
     'losses/train_total_loss': 0.6759281}
train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.66174406,
     'losses/train_total_loss': 0.66174406}
train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.6657919,
     'losses/train_total_loss': 0.6657919}
train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.62824845,
     'losses/train_total_loss': 0.62824845}
train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.699794,
     'losses/train_total_loss': 0.699794}
train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6833061,
     'losses/train_total_loss': 0.6833061}
train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.64203143,
     'losses/train_total_loss': 0.64203143}
train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.7092813,
     'losses/train_total_loss': 0.7092813}
train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.6599836,
     'losses/train_total_loss': 0.6599836}
saved checkpoint to results/exp_010/ckpt-7000.
train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.6380195,
     'losses/train_total_loss': 0.6380195}
train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.655441,
     'losses/train_total_loss': 0.655441}
train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.6625799,
     'losses/train_total_loss': 0.6625799}
train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.6924725,
     'losses/train_total_loss': 0.6924725}
train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.66752434,
     'losses/train_total_loss': 0.66752434}
train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.6125608,
     'losses/train_total_loss': 0.6125608}
train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.6357351,
     'losses/train_total_loss': 0.6357351}
train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.68215996,
     'losses/train_total_loss': 0.68215996}
train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.63393974,
     'losses/train_total_loss': 0.63393974}
train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.6014099,
     'losses/train_total_loss': 0.6014099}
saved checkpoint to results/exp_010/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   40.9 sec | output: 
    {'evaluation/iou/IoU': 0.690823,
     'losses/eval_semantic_loss': 0.5929465,
     'losses/eval_total_loss': 0.5929465}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.67050385,
     'losses/train_total_loss': 0.67050385}
train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.6739372,
     'losses/train_total_loss': 0.6739372}
train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.67807466,
     'losses/train_total_loss': 0.67807466}
train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.5852926,
     'losses/train_total_loss': 0.5852926}
train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.6047256,
     'losses/train_total_loss': 0.6047256}
train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.64568305,
     'losses/train_total_loss': 0.64568305}
train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.6234908,
     'losses/train_total_loss': 0.6234908}I0916 23:03:55.708170 139757943469888 controller.py:466] train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.647217,
     'losses/train_total_loss': 0.647217}
I0916 23:05:26.892714 139757943469888 controller.py:466] train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.6545045,
     'losses/train_total_loss': 0.6545045}
I0916 23:06:58.156861 139757943469888 controller.py:466] train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.6508015,
     'losses/train_total_loss': 0.6508015}
I0916 23:06:58.839664 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-9000.
I0916 23:08:29.018458 139757943469888 controller.py:466] train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.6340045,
     'losses/train_total_loss': 0.6340045}
I0916 23:09:59.662861 139757943469888 controller.py:466] train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.6347369,
     'losses/train_total_loss': 0.6347369}
I0916 23:11:29.107333 139757943469888 controller.py:466] train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.66145194,
     'losses/train_total_loss': 0.66145194}
I0916 23:12:58.941901 139757943469888 controller.py:466] train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.621978,
     'losses/train_total_loss': 0.621978}
I0916 23:14:28.650696 139757943469888 controller.py:466] train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.6017643,
     'losses/train_total_loss': 0.6017643}
I0916 23:15:58.573569 139757943469888 controller.py:466] train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.61340964,
     'losses/train_total_loss': 0.61340964}
I0916 23:17:28.366358 139757943469888 controller.py:466] train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.6139519,
     'losses/train_total_loss': 0.6139519}
I0916 23:18:58.269564 139757943469888 controller.py:466] train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.59161407,
     'losses/train_total_loss': 0.59161407}
I0916 23:20:28.651368 139757943469888 controller.py:466] train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.6492772,
     'losses/train_total_loss': 0.6492772}
I0916 23:21:59.253234 139757943469888 controller.py:466] train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.6369322,
     'losses/train_total_loss': 0.6369322}
I0916 23:21:59.913065 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-10000.
I0916 23:23:30.055090 139757943469888 controller.py:466] train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.6139964,
     'losses/train_total_loss': 0.6139964}
I0916 23:24:59.505975 139757943469888 controller.py:466] train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.57957083,
     'losses/train_total_loss': 0.57957083}
I0916 23:26:29.898236 139757943469888 controller.py:466] train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.5835268,
     'losses/train_total_loss': 0.5835268}
I0916 23:27:59.848959 139757943469888 controller.py:466] train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.6116417,
     'losses/train_total_loss': 0.6116417}
I0916 23:29:29.710740 139757943469888 controller.py:466] train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.6000762,
     'losses/train_total_loss': 0.6000762}
I0916 23:30:59.225028 139757943469888 controller.py:466] train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.5736363,
     'losses/train_total_loss': 0.5736363}
I0916 23:32:29.310013 139757943469888 controller.py:466] train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.6156626,
     'losses/train_total_loss': 0.6156626}
I0916 23:33:59.758862 139757943469888 controller.py:466] train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.5800448,
     'losses/train_total_loss': 0.5800448}
I0916 23:35:29.795200 139757943469888 controller.py:466] train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.59544814,
     'losses/train_total_loss': 0.59544814}
I0916 23:36:59.273473 139757943469888 controller.py:466] train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.57092124,
     'losses/train_total_loss': 0.57092124}
I0916 23:36:59.934697 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-11000.
I0916 23:38:29.540074 139757943469888 controller.py:466] train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.60641265,
     'losses/train_total_loss': 0.60641265}
I0916 23:39:59.143878 139757943469888 controller.py:466] train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.6119834,
     'losses/train_total_loss': 0.6119834}
I0916 23:41:28.962662 139757943469888 controller.py:466] train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.59255064,
     'losses/train_total_loss': 0.59255064}
I0916 23:42:58.233544 139757943469888 controller.py:466] train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.59038216,
     'losses/train_total_loss': 0.59038216}
I0916 23:44:28.573524 139757943469888 controller.py:466] train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.5921273,
     'losses/train_total_loss': 0.5921273}
I0916 23:45:58.509235 139757943469888 controller.py:466] train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.56455344,
     'losses/train_total_loss': 0.56455344}
I0916 23:47:28.414480 139757943469888 controller.py:466] train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.58841425,
     'losses/train_total_loss': 0.58841425}
I0916 23:48:58.175179 139757943469888 controller.py:466] train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.6332592,
     'losses/train_total_loss': 0.6332592}
I0916 23:50:28.395499 139757943469888 controller.py:466] train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.6174306,
     'losses/train_total_loss': 0.6174306}
I0916 23:51:57.962794 139757943469888 controller.py:466] train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.61855596,
     'losses/train_total_loss': 0.61855596}
I0916 23:51:58.940904 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-12000.
I0916 23:51:58.941732 139757943469888 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0916 23:52:39.339473 139757943469888 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 23:52:39.359323 139757943469888 controller.py:295]  eval | step:  12000 | eval time:   40.4 sec | output: 
    {'evaluation/iou/IoU': 0.72334325,
     'losses/eval_semantic_loss': 0.53697866,
     'losses/eval_total_loss': 0.53697866}
I0916 23:52:39.365192 139757943469888 controller.py:241] train | step:  12000 | training until step 16000...
I0916 23:54:09.362189 139757943469888 controller.py:466] train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.62133986,
     'losses/train_total_loss': 0.62133986}
I0916 23:55:39.347788 139757943469888 controller.py:466] train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.56963694,
     'losses/train_total_loss': 0.56963694}
I0916 23:57:08.971753 139757943469888 controller.py:466] train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.55183816,
     'losses/train_total_loss': 0.55183816}
I0916 23:58:38.535506 139757943469888 controller.py:466] train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.58443785,
     'losses/train_total_loss': 0.58443785}
I0917 00:00:08.885046 139757943469888 controller.py:466] train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.5543773,
     'losses/train_total_loss': 0.5543773}
I0917 00:01:38.679989 139757943469888 controller.py:466] train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.59881806,
     'losses/train_total_loss': 0.59881806}
I0917 00:03:08.705740 139757943469888 controller.py:466] train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.5896344,
     'losses/train_total_loss': 0.5896344}
I0917 00:04:38.570885 139757943469888 controller.py:466] train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.5777849,
     'losses/train_total_loss': 0.5777849}
I0917 00:06:08.948270 139757943469888 controller.py:466] train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.57177037,
     'losses/train_total_loss': 0.57177037}
I0917 00:07:38.935171 139757943469888 controller.py:466] train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5715004,
     'losses/train_total_loss': 0.5715004}
I0917 00:07:39.589530 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-13000.

train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.647217,
     'losses/train_total_loss': 0.647217}
train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.6545045,
     'losses/train_total_loss': 0.6545045}
train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.6508015,
     'losses/train_total_loss': 0.6508015}
saved checkpoint to results/exp_010/ckpt-9000.
train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.6340045,
     'losses/train_total_loss': 0.6340045}
train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.6347369,
     'losses/train_total_loss': 0.6347369}
train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.66145194,
     'losses/train_total_loss': 0.66145194}
train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.621978,
     'losses/train_total_loss': 0.621978}
train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.6017643,
     'losses/train_total_loss': 0.6017643}
train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.61340964,
     'losses/train_total_loss': 0.61340964}
train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.6139519,
     'losses/train_total_loss': 0.6139519}
train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.59161407,
     'losses/train_total_loss': 0.59161407}
train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.6492772,
     'losses/train_total_loss': 0.6492772}
train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.6369322,
     'losses/train_total_loss': 0.6369322}
saved checkpoint to results/exp_010/ckpt-10000.
train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.6139964,
     'losses/train_total_loss': 0.6139964}
train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.57957083,
     'losses/train_total_loss': 0.57957083}
train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.5835268,
     'losses/train_total_loss': 0.5835268}
train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.6116417,
     'losses/train_total_loss': 0.6116417}
train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.6000762,
     'losses/train_total_loss': 0.6000762}
train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.5736363,
     'losses/train_total_loss': 0.5736363}
train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.6156626,
     'losses/train_total_loss': 0.6156626}
train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.5800448,
     'losses/train_total_loss': 0.5800448}
train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.59544814,
     'losses/train_total_loss': 0.59544814}
train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.57092124,
     'losses/train_total_loss': 0.57092124}
saved checkpoint to results/exp_010/ckpt-11000.
train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.60641265,
     'losses/train_total_loss': 0.60641265}
train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.6119834,
     'losses/train_total_loss': 0.6119834}
train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.59255064,
     'losses/train_total_loss': 0.59255064}
train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.59038216,
     'losses/train_total_loss': 0.59038216}
train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.5921273,
     'losses/train_total_loss': 0.5921273}
train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.56455344,
     'losses/train_total_loss': 0.56455344}
train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.58841425,
     'losses/train_total_loss': 0.58841425}
train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.6332592,
     'losses/train_total_loss': 0.6332592}
train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.6174306,
     'losses/train_total_loss': 0.6174306}
train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.61855596,
     'losses/train_total_loss': 0.61855596}
saved checkpoint to results/exp_010/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   40.4 sec | output: 
    {'evaluation/iou/IoU': 0.72334325,
     'losses/eval_semantic_loss': 0.53697866,
     'losses/eval_total_loss': 0.53697866}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.62133986,
     'losses/train_total_loss': 0.62133986}
train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.56963694,
     'losses/train_total_loss': 0.56963694}
train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.55183816,
     'losses/train_total_loss': 0.55183816}
train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.58443785,
     'losses/train_total_loss': 0.58443785}
train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.5543773,
     'losses/train_total_loss': 0.5543773}
train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.59881806,
     'losses/train_total_loss': 0.59881806}
train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.5896344,
     'losses/train_total_loss': 0.5896344}
train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.5777849,
     'losses/train_total_loss': 0.5777849}
train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.57177037,
     'losses/train_total_loss': 0.57177037}
train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5715004,
     'losses/train_total_loss': 0.5715004}
saved checkpoint to results/exp_010/ckpt-13000.I0917 00:09:09.547108 139757943469888 controller.py:466] train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.5773724,
     'losses/train_total_loss': 0.5773724}
I0917 00:10:38.775387 139757943469888 controller.py:466] train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.55599505,
     'losses/train_total_loss': 0.55599505}
I0917 00:12:08.302471 139757943469888 controller.py:466] train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.56990343,
     'losses/train_total_loss': 0.56990343}
I0917 00:13:38.354812 139757943469888 controller.py:466] train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.5762269,
     'losses/train_total_loss': 0.5762269}
I0917 00:15:07.768449 139757943469888 controller.py:466] train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.5577712,
     'losses/train_total_loss': 0.5577712}
I0917 00:16:38.216499 139757943469888 controller.py:466] train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.54824483,
     'losses/train_total_loss': 0.54824483}
I0917 00:18:07.698488 139757943469888 controller.py:466] train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.57970595,
     'losses/train_total_loss': 0.57970595}
I0917 00:19:37.497639 139757943469888 controller.py:466] train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.5704472,
     'losses/train_total_loss': 0.5704472}
I0917 00:21:07.633590 139757943469888 controller.py:466] train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.6039728,
     'losses/train_total_loss': 0.6039728}
I0917 00:22:37.561155 139757943469888 controller.py:466] train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.5865183,
     'losses/train_total_loss': 0.5865183}
I0917 00:22:38.192906 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-14000.
I0917 00:24:07.671294 139757943469888 controller.py:466] train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.5410898,
     'losses/train_total_loss': 0.5410898}
I0917 00:25:37.554911 139757943469888 controller.py:466] train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.5844313,
     'losses/train_total_loss': 0.5844313}
I0917 00:27:07.375774 139757943469888 controller.py:466] train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.5495643,
     'losses/train_total_loss': 0.5495643}
I0917 00:28:37.270250 139757943469888 controller.py:466] train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.58006215,
     'losses/train_total_loss': 0.58006215}
I0917 00:30:06.481228 139757943469888 controller.py:466] train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.5767229,
     'losses/train_total_loss': 0.5767229}
I0917 00:31:35.494257 139757943469888 controller.py:466] train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.57714874,
     'losses/train_total_loss': 0.57714874}
I0917 00:33:04.643329 139757943469888 controller.py:466] train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.58154756,
     'losses/train_total_loss': 0.58154756}
I0917 00:34:34.394303 139757943469888 controller.py:466] train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.52267015,
     'losses/train_total_loss': 0.52267015}
I0917 00:36:05.161159 139757943469888 controller.py:466] train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.566098,
     'losses/train_total_loss': 0.566098}
I0917 00:37:34.434769 139757943469888 controller.py:466] train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.5735411,
     'losses/train_total_loss': 0.5735411}
I0917 00:37:35.098379 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-15000.
I0917 00:39:05.220121 139757943469888 controller.py:466] train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.5346639,
     'losses/train_total_loss': 0.5346639}
I0917 00:40:35.143670 139757943469888 controller.py:466] train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.5821799,
     'losses/train_total_loss': 0.5821799}
I0917 00:42:04.568512 139757943469888 controller.py:466] train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.52887434,
     'losses/train_total_loss': 0.52887434}
I0917 00:43:34.509859 139757943469888 controller.py:466] train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.51607084,
     'losses/train_total_loss': 0.51607084}
I0917 00:45:04.076237 139757943469888 controller.py:466] train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.5779957,
     'losses/train_total_loss': 0.5779957}
I0917 00:46:34.015091 139757943469888 controller.py:466] train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.5704044,
     'losses/train_total_loss': 0.5704044}
I0917 00:48:04.096504 139757943469888 controller.py:466] train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.5401383,
     'losses/train_total_loss': 0.5401383}
I0917 00:49:33.884009 139757943469888 controller.py:466] train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.5502601,
     'losses/train_total_loss': 0.5502601}
I0917 00:51:03.262075 139757943469888 controller.py:466] train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.55326253,
     'losses/train_total_loss': 0.55326253}
I0917 00:52:33.247967 139757943469888 controller.py:466] train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.54186857,
     'losses/train_total_loss': 0.54186857}
I0917 00:52:33.925087 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-16000.
I0917 00:52:33.925665 139757943469888 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0917 00:53:14.762620 139757943469888 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 00:53:14.771272 139757943469888 controller.py:295]  eval | step:  16000 | eval time:   40.8 sec | output: 
    {'evaluation/iou/IoU': 0.7392903,
     'losses/eval_semantic_loss': 0.48746195,
     'losses/eval_total_loss': 0.48746195}
I0917 00:53:14.778509 139757943469888 controller.py:241] train | step:  16000 | training until step 20000...
I0917 00:54:45.396104 139757943469888 controller.py:466] train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.52964157,
     'losses/train_total_loss': 0.52964157}
I0917 00:56:16.747636 139757943469888 controller.py:466] train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.56839436,
     'losses/train_total_loss': 0.56839436}
I0917 00:57:48.573694 139757943469888 controller.py:466] train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.5375122,
     'losses/train_total_loss': 0.5375122}
I0917 00:59:20.339327 139757943469888 controller.py:466] train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.5316847,
     'losses/train_total_loss': 0.5316847}
I0917 01:00:52.304680 139757943469888 controller.py:466] train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.529202,
     'losses/train_total_loss': 0.529202}
I0917 01:02:24.220170 139757943469888 controller.py:466] train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.54140145,
     'losses/train_total_loss': 0.54140145}
I0917 01:03:56.654758 139757943469888 controller.py:466] train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.54604787,
     'losses/train_total_loss': 0.54604787}
I0917 01:05:28.927210 139757943469888 controller.py:466] train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.5514455,
     'losses/train_total_loss': 0.5514455}
I0917 01:07:00.866315 139757943469888 controller.py:466] train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.52505857,
     'losses/train_total_loss': 0.52505857}
I0917 01:08:33.246862 139757943469888 controller.py:466] train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.538625,
     'losses/train_total_loss': 0.538625}
I0917 01:08:33.994061 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-17000.
I0917 01:10:04.577023 139757943469888 controller.py:466] train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.57691073,
     'losses/train_total_loss': 0.57691073}
I0917 01:11:34.994216 139757943469888 controller.py:466] train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.5407552,
     'losses/train_total_loss': 0.5407552}
I0917 01:13:06.205685 139757943469888 controller.py:466] train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.5302108,
     'losses/train_total_loss': 0.5302108}
I0917 01:14:36.827182 139757943469888 controller.py:466] train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.5574548,
     'losses/train_total_loss': 0.5574548}

train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.5773724,
     'losses/train_total_loss': 0.5773724}
train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.55599505,
     'losses/train_total_loss': 0.55599505}
train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.56990343,
     'losses/train_total_loss': 0.56990343}
train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.5762269,
     'losses/train_total_loss': 0.5762269}
train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.5577712,
     'losses/train_total_loss': 0.5577712}
train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.54824483,
     'losses/train_total_loss': 0.54824483}
train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.57970595,
     'losses/train_total_loss': 0.57970595}
train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.5704472,
     'losses/train_total_loss': 0.5704472}
train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.6039728,
     'losses/train_total_loss': 0.6039728}
train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.5865183,
     'losses/train_total_loss': 0.5865183}
saved checkpoint to results/exp_010/ckpt-14000.
train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.5410898,
     'losses/train_total_loss': 0.5410898}
train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.5844313,
     'losses/train_total_loss': 0.5844313}
train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.5495643,
     'losses/train_total_loss': 0.5495643}
train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.58006215,
     'losses/train_total_loss': 0.58006215}
train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.5767229,
     'losses/train_total_loss': 0.5767229}
train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.57714874,
     'losses/train_total_loss': 0.57714874}
train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.58154756,
     'losses/train_total_loss': 0.58154756}
train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.52267015,
     'losses/train_total_loss': 0.52267015}
train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.566098,
     'losses/train_total_loss': 0.566098}
train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.5735411,
     'losses/train_total_loss': 0.5735411}
saved checkpoint to results/exp_010/ckpt-15000.
train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.5346639,
     'losses/train_total_loss': 0.5346639}
train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.5821799,
     'losses/train_total_loss': 0.5821799}
train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.52887434,
     'losses/train_total_loss': 0.52887434}
train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.51607084,
     'losses/train_total_loss': 0.51607084}
train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.5779957,
     'losses/train_total_loss': 0.5779957}
train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.5704044,
     'losses/train_total_loss': 0.5704044}
train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.5401383,
     'losses/train_total_loss': 0.5401383}
train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.5502601,
     'losses/train_total_loss': 0.5502601}
train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.55326253,
     'losses/train_total_loss': 0.55326253}
train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.54186857,
     'losses/train_total_loss': 0.54186857}
saved checkpoint to results/exp_010/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   40.8 sec | output: 
    {'evaluation/iou/IoU': 0.7392903,
     'losses/eval_semantic_loss': 0.48746195,
     'losses/eval_total_loss': 0.48746195}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.52964157,
     'losses/train_total_loss': 0.52964157}
train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.56839436,
     'losses/train_total_loss': 0.56839436}
train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.5375122,
     'losses/train_total_loss': 0.5375122}
train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.5316847,
     'losses/train_total_loss': 0.5316847}
train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.529202,
     'losses/train_total_loss': 0.529202}
train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.54140145,
     'losses/train_total_loss': 0.54140145}
train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.54604787,
     'losses/train_total_loss': 0.54604787}
train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.5514455,
     'losses/train_total_loss': 0.5514455}
train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.52505857,
     'losses/train_total_loss': 0.52505857}
train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.538625,
     'losses/train_total_loss': 0.538625}
saved checkpoint to results/exp_010/ckpt-17000.
train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.57691073,
     'losses/train_total_loss': 0.57691073}
train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.5407552,
     'losses/train_total_loss': 0.5407552}
train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.5302108,
     'losses/train_total_loss': 0.5302108}
train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.5574548,
     'losses/train_total_loss': 0.5574548}I0917 01:16:07.975010 139757943469888 controller.py:466] train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.5565223,
     'losses/train_total_loss': 0.5565223}
I0917 01:17:39.005838 139757943469888 controller.py:466] train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.5486844,
     'losses/train_total_loss': 0.5486844}
I0917 01:19:10.231284 139757943469888 controller.py:466] train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.5139026,
     'losses/train_total_loss': 0.5139026}
I0917 01:20:41.433387 139757943469888 controller.py:466] train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.5017126,
     'losses/train_total_loss': 0.5017126}
I0917 01:22:12.269211 139757943469888 controller.py:466] train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.53340983,
     'losses/train_total_loss': 0.53340983}
I0917 01:23:42.940547 139757943469888 controller.py:466] train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.4807573,
     'losses/train_total_loss': 0.4807573}
I0917 01:23:43.612819 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-18000.
I0917 01:25:15.591739 139757943469888 controller.py:466] train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.53425074,
     'losses/train_total_loss': 0.53425074}
I0917 01:26:46.022501 139757943469888 controller.py:466] train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.48898005,
     'losses/train_total_loss': 0.48898005}
I0917 01:28:18.453574 139757943469888 controller.py:466] train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.5246637,
     'losses/train_total_loss': 0.5246637}
I0917 01:29:49.475314 139757943469888 controller.py:466] train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.5165413,
     'losses/train_total_loss': 0.5165413}
I0917 01:31:20.116887 139757943469888 controller.py:466] train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.54244936,
     'losses/train_total_loss': 0.54244936}
I0917 01:32:50.954562 139757943469888 controller.py:466] train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.5278392,
     'losses/train_total_loss': 0.5278392}
I0917 01:34:22.123497 139757943469888 controller.py:466] train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.51915365,
     'losses/train_total_loss': 0.51915365}
I0917 01:35:54.578578 139757943469888 controller.py:466] train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.5009283,
     'losses/train_total_loss': 0.5009283}
I0917 01:37:25.282660 139757943469888 controller.py:466] train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.5235817,
     'losses/train_total_loss': 0.5235817}
I0917 01:38:56.644154 139757943469888 controller.py:466] train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.49653977,
     'losses/train_total_loss': 0.49653977}
I0917 01:38:57.298122 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-19000.
I0917 01:40:29.643438 139757943469888 controller.py:466] train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.5227489,
     'losses/train_total_loss': 0.5227489}
I0917 01:42:00.833409 139757943469888 controller.py:466] train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.52133614,
     'losses/train_total_loss': 0.52133614}
I0917 01:43:31.444902 139757943469888 controller.py:466] train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.56696784,
     'losses/train_total_loss': 0.56696784}
I0917 01:45:03.580896 139757943469888 controller.py:466] train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.51018333,
     'losses/train_total_loss': 0.51018333}
I0917 01:46:34.454853 139757943469888 controller.py:466] train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.5196166,
     'losses/train_total_loss': 0.5196166}
I0917 01:48:07.197534 139757943469888 controller.py:466] train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.5006781,
     'losses/train_total_loss': 0.5006781}
I0917 01:49:38.605828 139757943469888 controller.py:466] train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.5101121,
     'losses/train_total_loss': 0.5101121}
I0917 01:51:10.005766 139757943469888 controller.py:466] train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.5389772,
     'losses/train_total_loss': 0.5389772}
I0917 01:52:43.244059 139757943469888 controller.py:466] train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.5211243,
     'losses/train_total_loss': 0.5211243}
I0917 01:54:14.377965 139757943469888 controller.py:466] train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5033697,
     'losses/train_total_loss': 0.5033697}
I0917 01:54:15.057279 139757943469888 controller.py:495] saved checkpoint to results/exp_010/ckpt-20000.
I0917 01:54:15.058083 139757943469888 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0917 01:54:54.983595 139757943469888 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 01:54:54.988216 139757943469888 controller.py:295]  eval | step:  20000 | eval time:   39.9 sec | output: 
    {'evaluation/iou/IoU': 0.75862074,
     'losses/eval_semantic_loss': 0.4300232,
     'losses/eval_total_loss': 0.4300232}

train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.5565223,
     'losses/train_total_loss': 0.5565223}
train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.5486844,
     'losses/train_total_loss': 0.5486844}
train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.5139026,
     'losses/train_total_loss': 0.5139026}
train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.5017126,
     'losses/train_total_loss': 0.5017126}
train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.53340983,
     'losses/train_total_loss': 0.53340983}
train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.4807573,
     'losses/train_total_loss': 0.4807573}
saved checkpoint to results/exp_010/ckpt-18000.
train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.53425074,
     'losses/train_total_loss': 0.53425074}
train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.48898005,
     'losses/train_total_loss': 0.48898005}
train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.5246637,
     'losses/train_total_loss': 0.5246637}
train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.5165413,
     'losses/train_total_loss': 0.5165413}
train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.54244936,
     'losses/train_total_loss': 0.54244936}
train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.5278392,
     'losses/train_total_loss': 0.5278392}
train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.51915365,
     'losses/train_total_loss': 0.51915365}
train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.5009283,
     'losses/train_total_loss': 0.5009283}
train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.5235817,
     'losses/train_total_loss': 0.5235817}
train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.49653977,
     'losses/train_total_loss': 0.49653977}
saved checkpoint to results/exp_010/ckpt-19000.
train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.5227489,
     'losses/train_total_loss': 0.5227489}
train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.52133614,
     'losses/train_total_loss': 0.52133614}
train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.56696784,
     'losses/train_total_loss': 0.56696784}
train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.51018333,
     'losses/train_total_loss': 0.51018333}
train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.5196166,
     'losses/train_total_loss': 0.5196166}
train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.5006781,
     'losses/train_total_loss': 0.5006781}
train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.5101121,
     'losses/train_total_loss': 0.5101121}
train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.5389772,
     'losses/train_total_loss': 0.5389772}
train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.5211243,
     'losses/train_total_loss': 0.5211243}
train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5033697,
     'losses/train_total_loss': 0.5033697}
saved checkpoint to results/exp_010/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   39.9 sec | output: 
    {'evaluation/iou/IoU': 0.75862074,
     'losses/eval_semantic_loss': 0.4300232,
     'losses/eval_total_loss': 0.4300232}
