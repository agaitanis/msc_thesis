I0916 00:38:30.188491 139836075194176 train.py:65] Reading the config file.
I0916 00:38:30.190154 139836075194176 train.py:69] Starting the experiment.
2022-09-16 00:38:30.191175: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-16 00:38:30.589105: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0916 00:38:30.590607 139836075194176 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0916 00:38:30.711196 139836075194176 deeplab.py:57] Synchronized Batchnorm is used.
I0916 00:38:30.712225 139836075194176 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 8, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0916 00:38:30.811897 139836075194176 deeplab.py:96] Setting pooling size to (65, 65)
I0916 00:38:30.812017 139836075194176 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 00:38:33.712699 139836075194176 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0916 00:38:33.727526 139836075194176 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0916 00:38:33.738389 139836075194176 controller.py:399] initialized model.
I0916 00:38:34.445395 139836075194176 api.py:447] Eval with scales ListWrapper([1.0])
I0916 00:38:35.234289 139836075194176 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 00:38:35.252434 139836075194176 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0916 00:38:38.426714 139836075194176 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 00:38:38.806019 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-0.
I0916 00:38:38.806655 139836075194176 controller.py:241] train | step:      0 | training until step 4000...
2022-09-16 00:38:57.293328: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 64346544 exceeds 10% of free system memory.
2022-09-16 00:38:57.295070: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 64346544 exceeds 10% of free system memory.
2022-09-16 00:38:57.348271: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 123002304 exceeds 10% of free system memory.
2022-09-16 00:38:57.350498: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 57829632 exceeds 10% of free system memory.
2022-09-16 00:38:57.350641: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 73517568 exceeds 10% of free system memory.
2022-09-16 00:38:59.498859: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0916 00:40:42.678847 139836075194176 controller.py:466] train | step:    100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00049887487,
     'losses/train_semantic_loss': 1.0937542,
     'losses/train_total_loss': 1.0937542}
I0916 00:42:21.184130 139836075194176 controller.py:466] train | step:    200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.0053933,
     'losses/train_total_loss': 1.0053933}
I0916 00:44:00.251070 139836075194176 controller.py:466] train | step:    300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049662375,
     'losses/train_semantic_loss': 0.95397455,
     'losses/train_total_loss': 0.95397455}
I0916 00:45:39.291577 139836075194176 controller.py:466] train | step:    400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 0.91882324,
     'losses/train_total_loss': 0.91882324}
I0916 00:47:18.004262 139836075194176 controller.py:466] train | step:    500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004943715,
     'losses/train_semantic_loss': 0.9089366,
     'losses/train_total_loss': 0.9089366}
I0916 00:48:56.838729 139836075194176 controller.py:466] train | step:    600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.88615906,
     'losses/train_total_loss': 0.88615906}
I0916 00:50:35.628128 139836075194176 controller.py:466] train | step:    700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049211807,
     'losses/train_semantic_loss': 0.88625276,
     'losses/train_total_loss': 0.88625276}
I0916 00:52:14.118261 139836075194176 controller.py:466] train | step:    800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.84988564,
     'losses/train_total_loss': 0.84988564}
I0916 00:53:52.797434 139836075194176 controller.py:466] train | step:    900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048986357,
     'losses/train_semantic_loss': 0.86267805,
     'losses/train_total_loss': 0.86267805}
I0916 00:55:31.477531 139836075194176 controller.py:466] train | step:   1000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.84894997,
     'losses/train_total_loss': 0.84894997}
I0916 00:55:32.322577 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-1000.
I0916 00:57:10.636265 139836075194176 controller.py:466] train | step:   1100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048760785,
     'losses/train_semantic_loss': 0.8111065,
     'losses/train_total_loss': 0.8111065}
I0916 00:58:49.008261 139836075194176 controller.py:466] train | step:   1200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8332198,
     'losses/train_total_loss': 0.8332198}
I0916 01:00:27.309168 139836075194176 controller.py:466] train | step:   1300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048535096,
     'losses/train_semantic_loss': 0.81069463,
     'losses/train_total_loss': 0.81069463}
I0916 01:02:05.968737 139836075194176 controller.py:466] train | step:   1400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.79086614,
     'losses/train_total_loss': 0.79086614}
I0916 01:03:44.219068 139836075194176 controller.py:466] train | step:   1500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004830929,
     'losses/train_semantic_loss': 0.8082046,
     'losses/train_total_loss': 0.8082046}
I0916 01:05:22.755230 139836075194176 controller.py:466] train | step:   1600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.78218544,
     'losses/train_total_loss': 0.78218544}
I0916 01:07:01.190176 139836075194176 controller.py:466] train | step:   1700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004808337,
     'losses/train_semantic_loss': 0.79031026,
     'losses/train_total_loss': 0.79031026}
I0916 01:08:39.766894 139836075194176 controller.py:466] train | step:   1800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.7727261,
     'losses/train_total_loss': 0.7727261}
I0916 01:10:18.260321 139836075194176 controller.py:466] train | step:   1900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047857335,
     'losses/train_semantic_loss': 0.78027636,
     'losses/train_total_loss': 0.78027636}
I0916 01:11:56.586989 139836075194176 controller.py:466] train | step:   2000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.76408905,
     'losses/train_total_loss': 0.76408905}
I0916 01:11:57.420165 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-2000.
I0916 01:13:35.686103 139836075194176 controller.py:466] train | step:   2100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047631178,
     'losses/train_semantic_loss': 0.7975064,
     'losses/train_total_loss': 0.7975064}
I0916 01:15:13.880301 139836075194176 controller.py:466] train | step:   2200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7705666,
     'losses/train_total_loss': 0.7705666}
I0916 01:16:52.092016 139836075194176 controller.py:466] train | step:   2300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047404898,
     'losses/train_semantic_loss': 0.76409477,
     'losses/train_total_loss': 0.76409477}
I0916 01:18:30.426392 139836075194176 controller.py:466] train | step:   2400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7674434,
     'losses/train_total_loss': 0.7674434}
I0916 01:20:08.644349 139836075194176 controller.py:466] train | step:   2500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047178505,
     'losses/train_semantic_loss': 0.7522553,
     'losses/train_total_loss': 0.7522553}
I0916 01:21:46.802032 139836075194176 controller.py:466] train | step:   2600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.75983167,
     'losses/train_total_loss': 0.75983167}
I0916 01:23:24.980382 139836075194176 controller.py:466] train | step:   2700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046951987,
     'losses/train_semantic_loss': 0.6963385,
     'losses/train_total_loss': 0.6963385}
I0916 01:25:03.115455 139836075194176 controller.py:466] train | step:   2800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7490058,
     'losses/train_total_loss': 0.7490058}
I0916 01:26:41.479277 139836075194176 controller.py:466] train | step:   2900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004672535,
     'losses/train_semantic_loss': 0.7204476,
     'losses/train_total_loss': 0.7204476}
I0916 01:28:19.908843 139836075194176 controller.py:466] train | step:   3000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.72599137,
     'losses/train_total_loss': 0.72599137}
I0916 01:28:20.722602 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-3000.
I0916 01:29:59.066642 139836075194176 controller.py:466] train | step:   3100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046498587,
     'losses/train_semantic_loss': 0.77524644,
     'losses/train_total_loss': 0.77524644}
I0916 01:31:37.478760 139836075194176 controller.py:466] train | step:   3200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.73503053,
     'losses/train_total_loss': 0.73503053}
I0916 01:33:15.982151 139836075194176 controller.py:466] train | step:   3300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046271706,
     'losses/train_semantic_loss': 0.7111784,
     'losses/train_total_loss': 0.7111784}
I0916 01:34:54.374157 139836075194176 controller.py:466] train | step:   3400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.75181276,
     'losses/train_total_loss': 0.75181276}
I0916 01:36:32.598093 139836075194176 controller.py:466] train | step:   3500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000460447,
     'losses/train_semantic_loss': 0.7534144,
     'losses/train_total_loss': 0.7534144}
I0916 01:38:10.736481 139836075194176 controller.py:466] train | step:   3600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.7386714,
     'losses/train_total_loss': 0.7386714}
I0916 01:39:48.960251 139836075194176 controller.py:466] train | step:   3700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004581756,
     'losses/train_semantic_loss': 0.70275056,
     'losses/train_total_loss': 0.70275056}
I0916 01:41:27.120061 139836075194176 controller.py:466] train | step:   3800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.70205855,
     'losses/train_total_loss': 0.70205855}
I0916 01:43:05.221733 139836075194176 controller.py:466] train | step:   3900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004559031,
     'losses/train_semantic_loss': 0.75238764,
     'losses/train_total_loss': 0.75238764}
I0916 01:44:43.371749 139836075194176 controller.py:466] train | step:   4000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.6825605,
     'losses/train_total_loss': 0.6825605}
I0916 01:44:44.210161 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-4000.
I0916 01:44:44.211065 139836075194176 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0916 01:44:45.748078 139836075194176 api.py:447] Eval with scales ListWrapper([1.0])
I0916 01:44:45.777148 139836075194176 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 01:44:45.802349 139836075194176 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0916 01:44:46.474506 139836075194176 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0916 01:45:35.645879 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 01:45:35.667479 139836075194176 controller.py:295]  eval | step:   4000 | eval time:   51.5 sec | output: 
    {'evaluation/iou/IoU': 0.4446795,
     'losses/eval_semantic_loss': 1.0172391,
     'losses/eval_total_loss': 1.0172391}
I0916 01:45:35.673177 139836075194176 controller.py:241] train | step:   4000 | training until step 8000...
I0916 01:47:14.512275 139836075194176 controller.py:466] train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00045362924,
     'losses/train_semantic_loss': 0.72470754,
     'losses/train_total_loss': 0.72470754}
I0916 01:48:53.378646 139836075194176 controller.py:466] train | step:   4200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.66738135,
     'losses/train_total_loss': 0.66738135}
I0916 01:50:32.004472 139836075194176 controller.py:466] train | step:   4300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045135414,
     'losses/train_semantic_loss': 0.67911357,
     'losses/train_total_loss': 0.67911357}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_006/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00049887487,
     'losses/train_semantic_loss': 1.0937542,
     'losses/train_total_loss': 1.0937542}
train | step:    200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.0053933,
     'losses/train_total_loss': 1.0053933}
train | step:    300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049662375,
     'losses/train_semantic_loss': 0.95397455,
     'losses/train_total_loss': 0.95397455}
train | step:    400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 0.91882324,
     'losses/train_total_loss': 0.91882324}
train | step:    500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004943715,
     'losses/train_semantic_loss': 0.9089366,
     'losses/train_total_loss': 0.9089366}
train | step:    600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.88615906,
     'losses/train_total_loss': 0.88615906}
train | step:    700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049211807,
     'losses/train_semantic_loss': 0.88625276,
     'losses/train_total_loss': 0.88625276}
train | step:    800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.84988564,
     'losses/train_total_loss': 0.84988564}
train | step:    900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048986357,
     'losses/train_semantic_loss': 0.86267805,
     'losses/train_total_loss': 0.86267805}
train | step:   1000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.84894997,
     'losses/train_total_loss': 0.84894997}
saved checkpoint to results/exp_006/ckpt-1000.
train | step:   1100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048760785,
     'losses/train_semantic_loss': 0.8111065,
     'losses/train_total_loss': 0.8111065}
train | step:   1200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8332198,
     'losses/train_total_loss': 0.8332198}
train | step:   1300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048535096,
     'losses/train_semantic_loss': 0.81069463,
     'losses/train_total_loss': 0.81069463}
train | step:   1400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.79086614,
     'losses/train_total_loss': 0.79086614}
train | step:   1500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004830929,
     'losses/train_semantic_loss': 0.8082046,
     'losses/train_total_loss': 0.8082046}
train | step:   1600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.78218544,
     'losses/train_total_loss': 0.78218544}
train | step:   1700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004808337,
     'losses/train_semantic_loss': 0.79031026,
     'losses/train_total_loss': 0.79031026}
train | step:   1800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.7727261,
     'losses/train_total_loss': 0.7727261}
train | step:   1900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047857335,
     'losses/train_semantic_loss': 0.78027636,
     'losses/train_total_loss': 0.78027636}
train | step:   2000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.76408905,
     'losses/train_total_loss': 0.76408905}
saved checkpoint to results/exp_006/ckpt-2000.
train | step:   2100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047631178,
     'losses/train_semantic_loss': 0.7975064,
     'losses/train_total_loss': 0.7975064}
train | step:   2200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7705666,
     'losses/train_total_loss': 0.7705666}
train | step:   2300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047404898,
     'losses/train_semantic_loss': 0.76409477,
     'losses/train_total_loss': 0.76409477}
train | step:   2400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7674434,
     'losses/train_total_loss': 0.7674434}
train | step:   2500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00047178505,
     'losses/train_semantic_loss': 0.7522553,
     'losses/train_total_loss': 0.7522553}
train | step:   2600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.75983167,
     'losses/train_total_loss': 0.75983167}
train | step:   2700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046951987,
     'losses/train_semantic_loss': 0.6963385,
     'losses/train_total_loss': 0.6963385}
train | step:   2800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7490058,
     'losses/train_total_loss': 0.7490058}
train | step:   2900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004672535,
     'losses/train_semantic_loss': 0.7204476,
     'losses/train_total_loss': 0.7204476}
train | step:   3000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.72599137,
     'losses/train_total_loss': 0.72599137}
saved checkpoint to results/exp_006/ckpt-3000.
train | step:   3100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046498587,
     'losses/train_semantic_loss': 0.77524644,
     'losses/train_total_loss': 0.77524644}
train | step:   3200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.73503053,
     'losses/train_total_loss': 0.73503053}
train | step:   3300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046271706,
     'losses/train_semantic_loss': 0.7111784,
     'losses/train_total_loss': 0.7111784}
train | step:   3400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.75181276,
     'losses/train_total_loss': 0.75181276}
train | step:   3500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000460447,
     'losses/train_semantic_loss': 0.7534144,
     'losses/train_total_loss': 0.7534144}
train | step:   3600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.7386714,
     'losses/train_total_loss': 0.7386714}
train | step:   3700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004581756,
     'losses/train_semantic_loss': 0.70275056,
     'losses/train_total_loss': 0.70275056}
train | step:   3800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.70205855,
     'losses/train_total_loss': 0.70205855}
train | step:   3900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004559031,
     'losses/train_semantic_loss': 0.75238764,
     'losses/train_total_loss': 0.75238764}
train | step:   4000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.6825605,
     'losses/train_total_loss': 0.6825605}
saved checkpoint to results/exp_006/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   51.5 sec | output: 
    {'evaluation/iou/IoU': 0.4446795,
     'losses/eval_semantic_loss': 1.0172391,
     'losses/eval_total_loss': 1.0172391}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00045362924,
     'losses/train_semantic_loss': 0.72470754,
     'losses/train_total_loss': 0.72470754}
train | step:   4200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.66738135,
     'losses/train_total_loss': 0.66738135}
train | step:   4300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045135414,
     'losses/train_semantic_loss': 0.67911357,
     'losses/train_total_loss': 0.67911357}I0916 01:52:10.842610 139836075194176 controller.py:466] train | step:   4400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.7122356,
     'losses/train_total_loss': 0.7122356}
I0916 01:53:49.798593 139836075194176 controller.py:466] train | step:   4500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044907775,
     'losses/train_semantic_loss': 0.71854246,
     'losses/train_total_loss': 0.71854246}
I0916 01:55:29.030506 139836075194176 controller.py:466] train | step:   4600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.682479,
     'losses/train_total_loss': 0.682479}
I0916 01:57:08.273926 139836075194176 controller.py:466] train | step:   4700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004468001,
     'losses/train_semantic_loss': 0.7077541,
     'losses/train_total_loss': 0.7077541}
I0916 01:58:47.563596 139836075194176 controller.py:466] train | step:   4800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.7237467,
     'losses/train_total_loss': 0.7237467}
I0916 02:00:26.839024 139836075194176 controller.py:466] train | step:   4900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044452114,
     'losses/train_semantic_loss': 0.72863626,
     'losses/train_total_loss': 0.72863626}
I0916 02:02:06.034208 139836075194176 controller.py:466] train | step:   5000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.72221404,
     'losses/train_total_loss': 0.72221404}
I0916 02:02:06.853847 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-5000.
I0916 02:03:46.213395 139836075194176 controller.py:466] train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044224088,
     'losses/train_semantic_loss': 0.6641662,
     'losses/train_total_loss': 0.6641662}
I0916 02:05:25.598945 139836075194176 controller.py:466] train | step:   5200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.71812457,
     'losses/train_total_loss': 0.71812457}
I0916 02:07:04.819156 139836075194176 controller.py:466] train | step:   5300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043995937,
     'losses/train_semantic_loss': 0.70946586,
     'losses/train_total_loss': 0.70946586}
I0916 02:08:44.170896 139836075194176 controller.py:466] train | step:   5400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.70974326,
     'losses/train_total_loss': 0.70974326}
I0916 02:10:23.703262 139836075194176 controller.py:466] train | step:   5500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043767647,
     'losses/train_semantic_loss': 0.6851516,
     'losses/train_total_loss': 0.6851516}
I0916 02:12:02.982583 139836075194176 controller.py:466] train | step:   5600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.7145862,
     'losses/train_total_loss': 0.7145862}
I0916 02:13:42.395870 139836075194176 controller.py:466] train | step:   5700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004353923,
     'losses/train_semantic_loss': 0.7282475,
     'losses/train_total_loss': 0.7282475}
I0916 02:15:21.819586 139836075194176 controller.py:466] train | step:   5800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.65956634,
     'losses/train_total_loss': 0.65956634}
I0916 02:17:00.923629 139836075194176 controller.py:466] train | step:   5900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004331068,
     'losses/train_semantic_loss': 0.6742167,
     'losses/train_total_loss': 0.6742167}
I0916 02:18:40.129555 139836075194176 controller.py:466] train | step:   6000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.6784428,
     'losses/train_total_loss': 0.6784428}
I0916 02:18:40.884780 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-6000.
I0916 02:20:20.339427 139836075194176 controller.py:466] train | step:   6100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004308199,
     'losses/train_semantic_loss': 0.6649568,
     'losses/train_total_loss': 0.6649568}
I0916 02:21:59.881071 139836075194176 controller.py:466] train | step:   6200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.68437785,
     'losses/train_total_loss': 0.68437785}
I0916 02:23:39.497841 139836075194176 controller.py:466] train | step:   6300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042853167,
     'losses/train_semantic_loss': 0.7146622,
     'losses/train_total_loss': 0.7146622}
I0916 02:25:19.085480 139836075194176 controller.py:466] train | step:   6400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.634443,
     'losses/train_total_loss': 0.634443}
I0916 02:26:58.675918 139836075194176 controller.py:466] train | step:   6500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042624207,
     'losses/train_semantic_loss': 0.6464425,
     'losses/train_total_loss': 0.6464425}
I0916 02:28:38.361368 139836075194176 controller.py:466] train | step:   6600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.69081706,
     'losses/train_total_loss': 0.69081706}
I0916 02:30:17.674833 139836075194176 controller.py:466] train | step:   6700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042395113,
     'losses/train_semantic_loss': 0.69816965,
     'losses/train_total_loss': 0.69816965}
I0916 02:31:57.309927 139836075194176 controller.py:466] train | step:   6800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.66971886,
     'losses/train_total_loss': 0.66971886}
I0916 02:33:36.728554 139836075194176 controller.py:466] train | step:   6900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042165883,
     'losses/train_semantic_loss': 0.6758831,
     'losses/train_total_loss': 0.6758831}
I0916 02:35:16.181886 139836075194176 controller.py:466] train | step:   7000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.631404,
     'losses/train_total_loss': 0.631404}
I0916 02:35:16.862179 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-7000.
I0916 02:36:56.188582 139836075194176 controller.py:466] train | step:   7100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041936515,
     'losses/train_semantic_loss': 0.6300293,
     'losses/train_total_loss': 0.6300293}
I0916 02:38:35.808425 139836075194176 controller.py:466] train | step:   7200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6579257,
     'losses/train_total_loss': 0.6579257}
I0916 02:40:15.119268 139836075194176 controller.py:466] train | step:   7300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041707006,
     'losses/train_semantic_loss': 0.6810634,
     'losses/train_total_loss': 0.6810634}
I0916 02:41:54.602083 139836075194176 controller.py:466] train | step:   7400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6957275,
     'losses/train_total_loss': 0.6957275}
I0916 02:43:33.859680 139836075194176 controller.py:466] train | step:   7500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041477353,
     'losses/train_semantic_loss': 0.67855746,
     'losses/train_total_loss': 0.67855746}
I0916 02:45:13.293488 139836075194176 controller.py:466] train | step:   7600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.658917,
     'losses/train_total_loss': 0.658917}
I0916 02:46:52.688237 139836075194176 controller.py:466] train | step:   7700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004124756,
     'losses/train_semantic_loss': 0.65374327,
     'losses/train_total_loss': 0.65374327}
I0916 02:48:32.073801 139836075194176 controller.py:466] train | step:   7800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.6396068,
     'losses/train_total_loss': 0.6396068}
I0916 02:50:11.485944 139836075194176 controller.py:466] train | step:   7900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004101763,
     'losses/train_semantic_loss': 0.65255636,
     'losses/train_total_loss': 0.65255636}
I0916 02:51:50.937010 139836075194176 controller.py:466] train | step:   8000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.66017014,
     'losses/train_total_loss': 0.66017014}
I0916 02:51:51.706201 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-8000.
I0916 02:51:51.707257 139836075194176 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0916 02:52:39.694879 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 02:52:39.699992 139836075194176 controller.py:295]  eval | step:   8000 | eval time:   48.0 sec | output: 
    {'evaluation/iou/IoU': 0.665185,
     'losses/eval_semantic_loss': 0.65895385,
     'losses/eval_total_loss': 0.65895385}
I0916 02:52:39.706281 139836075194176 controller.py:241] train | step:   8000 | training until step 12000...
2022-09-16 02:52:40.004901: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:41.184208: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:45.463387: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:46.654995: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:47.844111: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:49.030553: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:50.216128: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:51.403417: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:52.588823: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2022-09-16 02:52:53.776865: W tensorflow/core/common_runtime/bfc_allocator.cc:275] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.67GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
I0916 02:54:32.595595 139836075194176 controller.py:466] train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0004078755,
     'losses/train_semantic_loss': 0.6768935,
     'losses/train_total_loss': 0.6768935}
I0916 02:56:25.373423 139836075194176 controller.py:466] train | step:   8200 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6732455,
     'losses/train_total_loss': 0.6732455}
I0916 02:58:18.493942 139836075194176 controller.py:466] train | step:   8300 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040557332,
     'losses/train_semantic_loss': 0.6820871,
     'losses/train_total_loss': 0.6820871}
I0916 03:00:10.692492 139836075194176 controller.py:466] train | step:   8400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.61011434,
     'losses/train_total_loss': 0.61011434}
I0916 03:02:04.563189 139836075194176 controller.py:466] train | step:   8500 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040326963,
     'losses/train_semantic_loss': 0.62784564,
     'losses/train_total_loss': 0.62784564}
I0916 03:03:58.640903 139836075194176 controller.py:466] train | step:   8600 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6657564,
     'losses/train_total_loss': 0.6657564}
I0916 03:05:50.832835 139836075194176 controller.py:466] train | step:   8700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040096452,
     'losses/train_semantic_loss': 0.6509866,
     'losses/train_total_loss': 0.6509866}

train | step:   4400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.7122356,
     'losses/train_total_loss': 0.7122356}
train | step:   4500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044907775,
     'losses/train_semantic_loss': 0.71854246,
     'losses/train_total_loss': 0.71854246}
train | step:   4600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.682479,
     'losses/train_total_loss': 0.682479}
train | step:   4700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004468001,
     'losses/train_semantic_loss': 0.7077541,
     'losses/train_total_loss': 0.7077541}
train | step:   4800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.7237467,
     'losses/train_total_loss': 0.7237467}
train | step:   4900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044452114,
     'losses/train_semantic_loss': 0.72863626,
     'losses/train_total_loss': 0.72863626}
train | step:   5000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.72221404,
     'losses/train_total_loss': 0.72221404}
saved checkpoint to results/exp_006/ckpt-5000.
train | step:   5100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044224088,
     'losses/train_semantic_loss': 0.6641662,
     'losses/train_total_loss': 0.6641662}
train | step:   5200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.71812457,
     'losses/train_total_loss': 0.71812457}
train | step:   5300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043995937,
     'losses/train_semantic_loss': 0.70946586,
     'losses/train_total_loss': 0.70946586}
train | step:   5400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.70974326,
     'losses/train_total_loss': 0.70974326}
train | step:   5500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043767647,
     'losses/train_semantic_loss': 0.6851516,
     'losses/train_total_loss': 0.6851516}
train | step:   5600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.7145862,
     'losses/train_total_loss': 0.7145862}
train | step:   5700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004353923,
     'losses/train_semantic_loss': 0.7282475,
     'losses/train_total_loss': 0.7282475}
train | step:   5800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.65956634,
     'losses/train_total_loss': 0.65956634}
train | step:   5900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004331068,
     'losses/train_semantic_loss': 0.6742167,
     'losses/train_total_loss': 0.6742167}
train | step:   6000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.6784428,
     'losses/train_total_loss': 0.6784428}
saved checkpoint to results/exp_006/ckpt-6000.
train | step:   6100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004308199,
     'losses/train_semantic_loss': 0.6649568,
     'losses/train_total_loss': 0.6649568}
train | step:   6200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.68437785,
     'losses/train_total_loss': 0.68437785}
train | step:   6300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042853167,
     'losses/train_semantic_loss': 0.7146622,
     'losses/train_total_loss': 0.7146622}
train | step:   6400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.634443,
     'losses/train_total_loss': 0.634443}
train | step:   6500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042624207,
     'losses/train_semantic_loss': 0.6464425,
     'losses/train_total_loss': 0.6464425}
train | step:   6600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.69081706,
     'losses/train_total_loss': 0.69081706}
train | step:   6700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042395113,
     'losses/train_semantic_loss': 0.69816965,
     'losses/train_total_loss': 0.69816965}
train | step:   6800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.66971886,
     'losses/train_total_loss': 0.66971886}
train | step:   6900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042165883,
     'losses/train_semantic_loss': 0.6758831,
     'losses/train_total_loss': 0.6758831}
train | step:   7000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.631404,
     'losses/train_total_loss': 0.631404}
saved checkpoint to results/exp_006/ckpt-7000.
train | step:   7100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041936515,
     'losses/train_semantic_loss': 0.6300293,
     'losses/train_total_loss': 0.6300293}
train | step:   7200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6579257,
     'losses/train_total_loss': 0.6579257}
train | step:   7300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041707006,
     'losses/train_semantic_loss': 0.6810634,
     'losses/train_total_loss': 0.6810634}
train | step:   7400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6957275,
     'losses/train_total_loss': 0.6957275}
train | step:   7500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041477353,
     'losses/train_semantic_loss': 0.67855746,
     'losses/train_total_loss': 0.67855746}
train | step:   7600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.658917,
     'losses/train_total_loss': 0.658917}
train | step:   7700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004124756,
     'losses/train_semantic_loss': 0.65374327,
     'losses/train_total_loss': 0.65374327}
train | step:   7800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.6396068,
     'losses/train_total_loss': 0.6396068}
train | step:   7900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0004101763,
     'losses/train_semantic_loss': 0.65255636,
     'losses/train_total_loss': 0.65255636}
train | step:   8000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.66017014,
     'losses/train_total_loss': 0.66017014}
saved checkpoint to results/exp_006/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   48.0 sec | output: 
    {'evaluation/iou/IoU': 0.665185,
     'losses/eval_semantic_loss': 0.65895385,
     'losses/eval_total_loss': 0.65895385}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0004078755,
     'losses/train_semantic_loss': 0.6768935,
     'losses/train_total_loss': 0.6768935}
train | step:   8200 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6732455,
     'losses/train_total_loss': 0.6732455}
train | step:   8300 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040557332,
     'losses/train_semantic_loss': 0.6820871,
     'losses/train_total_loss': 0.6820871}
train | step:   8400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.61011434,
     'losses/train_total_loss': 0.61011434}
train | step:   8500 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040326963,
     'losses/train_semantic_loss': 0.62784564,
     'losses/train_total_loss': 0.62784564}
train | step:   8600 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.6657564,
     'losses/train_total_loss': 0.6657564}
train | step:   8700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00040096452,
     'losses/train_semantic_loss': 0.6509866,
     'losses/train_total_loss': 0.6509866}I0916 03:07:43.528429 139836075194176 controller.py:466] train | step:   8800 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.63332486,
     'losses/train_total_loss': 0.63332486}
I0916 03:09:36.156569 139836075194176 controller.py:466] train | step:   8900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039865792,
     'losses/train_semantic_loss': 0.7207636,
     'losses/train_total_loss': 0.7207636}
I0916 03:11:31.514543 139836075194176 controller.py:466] train | step:   9000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.66146606,
     'losses/train_total_loss': 0.66146606}
I0916 03:11:32.153364 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-9000.
I0916 03:13:11.307126 139836075194176 controller.py:466] train | step:   9100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039634982,
     'losses/train_semantic_loss': 0.615579,
     'losses/train_total_loss': 0.615579}
I0916 03:14:50.728577 139836075194176 controller.py:466] train | step:   9200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.6422487,
     'losses/train_total_loss': 0.6422487}
I0916 03:16:30.299771 139836075194176 controller.py:466] train | step:   9300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039404025,
     'losses/train_semantic_loss': 0.62597746,
     'losses/train_total_loss': 0.62597746}
I0916 03:18:09.905169 139836075194176 controller.py:466] train | step:   9400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.63286346,
     'losses/train_total_loss': 0.63286346}
I0916 03:19:49.299139 139836075194176 controller.py:466] train | step:   9500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039172915,
     'losses/train_semantic_loss': 0.696667,
     'losses/train_total_loss': 0.696667}
I0916 03:21:28.715776 139836075194176 controller.py:466] train | step:   9600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6127601,
     'losses/train_total_loss': 0.6127601}
I0916 03:23:07.952333 139836075194176 controller.py:466] train | step:   9700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038941653,
     'losses/train_semantic_loss': 0.65358406,
     'losses/train_total_loss': 0.65358406}
I0916 03:24:47.303541 139836075194176 controller.py:466] train | step:   9800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.62306106,
     'losses/train_total_loss': 0.62306106}
I0916 03:26:26.408340 139836075194176 controller.py:466] train | step:   9900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003871024,
     'losses/train_semantic_loss': 0.6361522,
     'losses/train_total_loss': 0.6361522}
I0916 03:28:05.741722 139836075194176 controller.py:466] train | step:  10000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6301787,
     'losses/train_total_loss': 0.6301787}
I0916 03:28:06.333654 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-10000.
I0916 03:29:45.527415 139836075194176 controller.py:466] train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038478675,
     'losses/train_semantic_loss': 0.5990384,
     'losses/train_total_loss': 0.5990384}
I0916 03:31:24.835949 139836075194176 controller.py:466] train | step:  10200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.6043525,
     'losses/train_total_loss': 0.6043525}
I0916 03:33:04.187905 139836075194176 controller.py:466] train | step:  10300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038246953,
     'losses/train_semantic_loss': 0.62271696,
     'losses/train_total_loss': 0.62271696}
I0916 03:34:43.453660 139836075194176 controller.py:466] train | step:  10400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.61494464,
     'losses/train_total_loss': 0.61494464}
I0916 03:36:22.954147 139836075194176 controller.py:466] train | step:  10500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038015074,
     'losses/train_semantic_loss': 0.6219727,
     'losses/train_total_loss': 0.6219727}
I0916 03:38:02.203804 139836075194176 controller.py:466] train | step:  10600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.6267355,
     'losses/train_total_loss': 0.6267355}
I0916 03:39:41.692098 139836075194176 controller.py:466] train | step:  10700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037783038,
     'losses/train_semantic_loss': 0.61929727,
     'losses/train_total_loss': 0.61929727}
I0916 03:41:21.232142 139836075194176 controller.py:466] train | step:  10800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.5843945,
     'losses/train_total_loss': 0.5843945}
I0916 03:43:00.367321 139836075194176 controller.py:466] train | step:  10900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037550845,
     'losses/train_semantic_loss': 0.5947119,
     'losses/train_total_loss': 0.5947119}
I0916 03:44:39.729258 139836075194176 controller.py:466] train | step:  11000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6332436,
     'losses/train_total_loss': 0.6332436}
I0916 03:44:40.349949 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-11000.
I0916 03:46:20.097762 139836075194176 controller.py:466] train | step:  11100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037318494,
     'losses/train_semantic_loss': 0.66551733,
     'losses/train_total_loss': 0.66551733}
I0916 03:47:59.517603 139836075194176 controller.py:466] train | step:  11200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.66082084,
     'losses/train_total_loss': 0.66082084}
I0916 03:49:38.856949 139836075194176 controller.py:466] train | step:  11300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037085975,
     'losses/train_semantic_loss': 0.6382304,
     'losses/train_total_loss': 0.6382304}
I0916 03:51:17.939542 139836075194176 controller.py:466] train | step:  11400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.5946931,
     'losses/train_total_loss': 0.5946931}
I0916 03:52:57.237058 139836075194176 controller.py:466] train | step:  11500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036853302,
     'losses/train_semantic_loss': 0.61271507,
     'losses/train_total_loss': 0.61271507}
I0916 03:54:36.677866 139836075194176 controller.py:466] train | step:  11600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.5962216,
     'losses/train_total_loss': 0.5962216}
I0916 03:56:15.696516 139836075194176 controller.py:466] train | step:  11700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003662046,
     'losses/train_semantic_loss': 0.64425606,
     'losses/train_total_loss': 0.64425606}
I0916 03:57:55.094432 139836075194176 controller.py:466] train | step:  11800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.5912177,
     'losses/train_total_loss': 0.5912177}
I0916 03:59:34.772729 139836075194176 controller.py:466] train | step:  11900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003638746,
     'losses/train_semantic_loss': 0.56994885,
     'losses/train_total_loss': 0.56994885}
I0916 04:01:14.507879 139836075194176 controller.py:466] train | step:  12000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6273336,
     'losses/train_total_loss': 0.6273336}
I0916 04:01:15.118272 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-12000.
I0916 04:01:15.118874 139836075194176 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0916 04:02:03.113239 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 04:02:03.118066 139836075194176 controller.py:295]  eval | step:  12000 | eval time:   48.0 sec | output: 
    {'evaluation/iou/IoU': 0.6853378,
     'losses/eval_semantic_loss': 0.6339172,
     'losses/eval_total_loss': 0.6339172}
I0916 04:02:03.124060 139836075194176 controller.py:241] train | step:  12000 | training until step 16000...
I0916 04:03:54.800140 139836075194176 controller.py:466] train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0003615429,
     'losses/train_semantic_loss': 0.6061995,
     'losses/train_total_loss': 0.6061995}
I0916 04:05:49.499488 139836075194176 controller.py:466] train | step:  12200 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.6160749,
     'losses/train_total_loss': 0.6160749}
I0916 04:07:42.568680 139836075194176 controller.py:466] train | step:  12300 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035920952,
     'losses/train_semantic_loss': 0.6466839,
     'losses/train_total_loss': 0.6466839}
I0916 04:09:37.134449 139836075194176 controller.py:466] train | step:  12400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.56352425,
     'losses/train_total_loss': 0.56352425}
I0916 04:11:28.551576 139836075194176 controller.py:466] train | step:  12500 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035687446,
     'losses/train_semantic_loss': 0.5971707,
     'losses/train_total_loss': 0.5971707}
I0916 04:13:21.125371 139836075194176 controller.py:466] train | step:  12600 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.5754049,
     'losses/train_total_loss': 0.5754049}
I0916 04:15:15.775958 139836075194176 controller.py:466] train | step:  12700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035453768,
     'losses/train_semantic_loss': 0.58408755,
     'losses/train_total_loss': 0.58408755}
I0916 04:17:08.334321 139836075194176 controller.py:466] train | step:  12800 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6049662,
     'losses/train_total_loss': 0.6049662}
I0916 04:19:01.785525 139836075194176 controller.py:466] train | step:  12900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035219922,
     'losses/train_semantic_loss': 0.57311445,
     'losses/train_total_loss': 0.57311445}
I0916 04:20:54.753062 139836075194176 controller.py:466] train | step:  13000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.5884819,
     'losses/train_total_loss': 0.5884819}
I0916 04:20:55.372163 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-13000.

train | step:   8800 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.63332486,
     'losses/train_total_loss': 0.63332486}
train | step:   8900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039865792,
     'losses/train_semantic_loss': 0.7207636,
     'losses/train_total_loss': 0.7207636}
train | step:   9000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.66146606,
     'losses/train_total_loss': 0.66146606}
saved checkpoint to results/exp_006/ckpt-9000.
train | step:   9100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039634982,
     'losses/train_semantic_loss': 0.615579,
     'losses/train_total_loss': 0.615579}
train | step:   9200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.6422487,
     'losses/train_total_loss': 0.6422487}
train | step:   9300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039404025,
     'losses/train_semantic_loss': 0.62597746,
     'losses/train_total_loss': 0.62597746}
train | step:   9400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.63286346,
     'losses/train_total_loss': 0.63286346}
train | step:   9500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039172915,
     'losses/train_semantic_loss': 0.696667,
     'losses/train_total_loss': 0.696667}
train | step:   9600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6127601,
     'losses/train_total_loss': 0.6127601}
train | step:   9700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038941653,
     'losses/train_semantic_loss': 0.65358406,
     'losses/train_total_loss': 0.65358406}
train | step:   9800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.62306106,
     'losses/train_total_loss': 0.62306106}
train | step:   9900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003871024,
     'losses/train_semantic_loss': 0.6361522,
     'losses/train_total_loss': 0.6361522}
train | step:  10000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6301787,
     'losses/train_total_loss': 0.6301787}
saved checkpoint to results/exp_006/ckpt-10000.
train | step:  10100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038478675,
     'losses/train_semantic_loss': 0.5990384,
     'losses/train_total_loss': 0.5990384}
train | step:  10200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.6043525,
     'losses/train_total_loss': 0.6043525}
train | step:  10300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038246953,
     'losses/train_semantic_loss': 0.62271696,
     'losses/train_total_loss': 0.62271696}
train | step:  10400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.61494464,
     'losses/train_total_loss': 0.61494464}
train | step:  10500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00038015074,
     'losses/train_semantic_loss': 0.6219727,
     'losses/train_total_loss': 0.6219727}
train | step:  10600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.6267355,
     'losses/train_total_loss': 0.6267355}
train | step:  10700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037783038,
     'losses/train_semantic_loss': 0.61929727,
     'losses/train_total_loss': 0.61929727}
train | step:  10800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.5843945,
     'losses/train_total_loss': 0.5843945}
train | step:  10900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037550845,
     'losses/train_semantic_loss': 0.5947119,
     'losses/train_total_loss': 0.5947119}
train | step:  11000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6332436,
     'losses/train_total_loss': 0.6332436}
saved checkpoint to results/exp_006/ckpt-11000.
train | step:  11100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037318494,
     'losses/train_semantic_loss': 0.66551733,
     'losses/train_total_loss': 0.66551733}
train | step:  11200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.66082084,
     'losses/train_total_loss': 0.66082084}
train | step:  11300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00037085975,
     'losses/train_semantic_loss': 0.6382304,
     'losses/train_total_loss': 0.6382304}
train | step:  11400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.5946931,
     'losses/train_total_loss': 0.5946931}
train | step:  11500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036853302,
     'losses/train_semantic_loss': 0.61271507,
     'losses/train_total_loss': 0.61271507}
train | step:  11600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.5962216,
     'losses/train_total_loss': 0.5962216}
train | step:  11700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003662046,
     'losses/train_semantic_loss': 0.64425606,
     'losses/train_total_loss': 0.64425606}
train | step:  11800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.5912177,
     'losses/train_total_loss': 0.5912177}
train | step:  11900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003638746,
     'losses/train_semantic_loss': 0.56994885,
     'losses/train_total_loss': 0.56994885}
train | step:  12000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6273336,
     'losses/train_total_loss': 0.6273336}
saved checkpoint to results/exp_006/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   48.0 sec | output: 
    {'evaluation/iou/IoU': 0.6853378,
     'losses/eval_semantic_loss': 0.6339172,
     'losses/eval_total_loss': 0.6339172}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0003615429,
     'losses/train_semantic_loss': 0.6061995,
     'losses/train_total_loss': 0.6061995}
train | step:  12200 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.6160749,
     'losses/train_total_loss': 0.6160749}
train | step:  12300 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035920952,
     'losses/train_semantic_loss': 0.6466839,
     'losses/train_total_loss': 0.6466839}
train | step:  12400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.56352425,
     'losses/train_total_loss': 0.56352425}
train | step:  12500 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035687446,
     'losses/train_semantic_loss': 0.5971707,
     'losses/train_total_loss': 0.5971707}
train | step:  12600 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.5754049,
     'losses/train_total_loss': 0.5754049}
train | step:  12700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035453768,
     'losses/train_semantic_loss': 0.58408755,
     'losses/train_total_loss': 0.58408755}
train | step:  12800 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6049662,
     'losses/train_total_loss': 0.6049662}
train | step:  12900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035219922,
     'losses/train_semantic_loss': 0.57311445,
     'losses/train_total_loss': 0.57311445}
train | step:  13000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.5884819,
     'losses/train_total_loss': 0.5884819}
saved checkpoint to results/exp_006/ckpt-13000.I0916 04:22:33.805820 139836075194176 controller.py:466] train | step:  13100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000349859,
     'losses/train_semantic_loss': 0.5825808,
     'losses/train_total_loss': 0.5825808}
I0916 04:24:12.147879 139836075194176 controller.py:466] train | step:  13200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6183966,
     'losses/train_total_loss': 0.6183966}
I0916 04:25:50.547401 139836075194176 controller.py:466] train | step:  13300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034751708,
     'losses/train_semantic_loss': 0.6238465,
     'losses/train_total_loss': 0.6238465}
I0916 04:27:28.864079 139836075194176 controller.py:466] train | step:  13400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6008416,
     'losses/train_total_loss': 0.6008416}
I0916 04:29:06.982234 139836075194176 controller.py:466] train | step:  13500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003451734,
     'losses/train_semantic_loss': 0.57899153,
     'losses/train_total_loss': 0.57899153}
I0916 04:30:45.169892 139836075194176 controller.py:466] train | step:  13600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.5862267,
     'losses/train_total_loss': 0.5862267}
I0916 04:32:23.343941 139836075194176 controller.py:466] train | step:  13700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034282793,
     'losses/train_semantic_loss': 0.5250111,
     'losses/train_total_loss': 0.5250111}
I0916 04:34:01.351052 139836075194176 controller.py:466] train | step:  13800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.57829833,
     'losses/train_total_loss': 0.57829833}
I0916 04:35:39.432855 139836075194176 controller.py:466] train | step:  13900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003404807,
     'losses/train_semantic_loss': 0.5971064,
     'losses/train_total_loss': 0.5971064}
I0916 04:37:17.502094 139836075194176 controller.py:466] train | step:  14000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6066141,
     'losses/train_total_loss': 0.6066141}
I0916 04:37:18.116637 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-14000.
I0916 04:38:56.192727 139836075194176 controller.py:466] train | step:  14100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033813165,
     'losses/train_semantic_loss': 0.5544137,
     'losses/train_total_loss': 0.5544137}
I0916 04:40:34.722369 139836075194176 controller.py:466] train | step:  14200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.6072264,
     'losses/train_total_loss': 0.6072264}
I0916 04:42:13.085165 139836075194176 controller.py:466] train | step:  14300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033578082,
     'losses/train_semantic_loss': 0.5767694,
     'losses/train_total_loss': 0.5767694}
I0916 04:43:51.144895 139836075194176 controller.py:466] train | step:  14400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6098237,
     'losses/train_total_loss': 0.6098237}
I0916 04:45:29.428647 139836075194176 controller.py:466] train | step:  14500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003334281,
     'losses/train_semantic_loss': 0.55801183,
     'losses/train_total_loss': 0.55801183}
I0916 04:47:07.577941 139836075194176 controller.py:466] train | step:  14600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.59495384,
     'losses/train_total_loss': 0.59495384}
I0916 04:48:46.057476 139836075194176 controller.py:466] train | step:  14700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033107356,
     'losses/train_semantic_loss': 0.54898894,
     'losses/train_total_loss': 0.54898894}
I0916 04:50:24.128254 139836075194176 controller.py:466] train | step:  14800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.5509251,
     'losses/train_total_loss': 0.5509251}
I0916 04:52:02.254443 139836075194176 controller.py:466] train | step:  14900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032871717,
     'losses/train_semantic_loss': 0.6009056,
     'losses/train_total_loss': 0.6009056}
I0916 04:53:40.419020 139836075194176 controller.py:466] train | step:  15000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.5521338,
     'losses/train_total_loss': 0.5521338}
I0916 04:53:41.359354 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-15000.
I0916 04:55:19.340392 139836075194176 controller.py:466] train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003263589,
     'losses/train_semantic_loss': 0.5358854,
     'losses/train_total_loss': 0.5358854}
I0916 04:56:57.757565 139836075194176 controller.py:466] train | step:  15200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.604497,
     'losses/train_total_loss': 0.604497}
I0916 04:58:35.893298 139836075194176 controller.py:466] train | step:  15300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032399874,
     'losses/train_semantic_loss': 0.5870211,
     'losses/train_total_loss': 0.5870211}
I0916 05:00:14.539652 139836075194176 controller.py:466] train | step:  15400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.62063646,
     'losses/train_total_loss': 0.62063646}
I0916 05:01:52.765202 139836075194176 controller.py:466] train | step:  15500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032163665,
     'losses/train_semantic_loss': 0.5933806,
     'losses/train_total_loss': 0.5933806}
I0916 05:03:31.082981 139836075194176 controller.py:466] train | step:  15600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.57413065,
     'losses/train_total_loss': 0.57413065}
I0916 05:05:09.379254 139836075194176 controller.py:466] train | step:  15700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003192726,
     'losses/train_semantic_loss': 0.5876941,
     'losses/train_total_loss': 0.5876941}
I0916 05:06:47.643728 139836075194176 controller.py:466] train | step:  15800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.54948884,
     'losses/train_total_loss': 0.54948884}
I0916 05:08:25.814835 139836075194176 controller.py:466] train | step:  15900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031690663,
     'losses/train_semantic_loss': 0.5561647,
     'losses/train_total_loss': 0.5561647}
I0916 05:10:04.076293 139836075194176 controller.py:466] train | step:  16000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.5847077,
     'losses/train_total_loss': 0.5847077}
I0916 05:10:04.691631 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-16000.
I0916 05:10:04.692218 139836075194176 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0916 05:10:53.527645 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 05:10:53.547379 139836075194176 controller.py:295]  eval | step:  16000 | eval time:   48.9 sec | output: 
    {'evaluation/iou/IoU': 0.654759,
     'losses/eval_semantic_loss': 0.70811826,
     'losses/eval_total_loss': 0.70811826}
I0916 05:10:53.553262 139836075194176 controller.py:241] train | step:  16000 | training until step 20000...
I0916 05:12:32.339442 139836075194176 controller.py:466] train | step:  16100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00031453875,
     'losses/train_semantic_loss': 0.56666595,
     'losses/train_total_loss': 0.56666595}
I0916 05:14:10.833197 139836075194176 controller.py:466] train | step:  16200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.5824119,
     'losses/train_total_loss': 0.5824119}
I0916 05:15:49.104371 139836075194176 controller.py:466] train | step:  16300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031216882,
     'losses/train_semantic_loss': 0.57520425,
     'losses/train_total_loss': 0.57520425}
I0916 05:17:27.367972 139836075194176 controller.py:466] train | step:  16400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.5647457,
     'losses/train_total_loss': 0.5647457}
I0916 05:19:05.391551 139836075194176 controller.py:466] train | step:  16500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030979692,
     'losses/train_semantic_loss': 0.58090943,
     'losses/train_total_loss': 0.58090943}
I0916 05:20:43.539921 139836075194176 controller.py:466] train | step:  16600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.61488307,
     'losses/train_total_loss': 0.61488307}
I0916 05:22:21.583460 139836075194176 controller.py:466] train | step:  16700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030742298,
     'losses/train_semantic_loss': 0.5618626,
     'losses/train_total_loss': 0.5618626}
I0916 05:23:59.682677 139836075194176 controller.py:466] train | step:  16800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.58492196,
     'losses/train_total_loss': 0.58492196}
I0916 05:25:38.143709 139836075194176 controller.py:466] train | step:  16900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030504703,
     'losses/train_semantic_loss': 0.54886335,
     'losses/train_total_loss': 0.54886335}
I0916 05:27:16.600411 139836075194176 controller.py:466] train | step:  17000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.5611496,
     'losses/train_total_loss': 0.5611496}
I0916 05:27:17.218514 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-17000.
I0916 05:28:55.404688 139836075194176 controller.py:466] train | step:  17100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000302669,
     'losses/train_semantic_loss': 0.5848552,
     'losses/train_total_loss': 0.5848552}
I0916 05:30:33.697422 139836075194176 controller.py:466] train | step:  17200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.5459162,
     'losses/train_total_loss': 0.5459162}
I0916 05:32:11.841573 139836075194176 controller.py:466] train | step:  17300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030028893,
     'losses/train_semantic_loss': 0.54386175,
     'losses/train_total_loss': 0.54386175}
I0916 05:33:50.074717 139836075194176 controller.py:466] train | step:  17400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.552347,
     'losses/train_total_loss': 0.552347}

train | step:  13100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000349859,
     'losses/train_semantic_loss': 0.5825808,
     'losses/train_total_loss': 0.5825808}
train | step:  13200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.6183966,
     'losses/train_total_loss': 0.6183966}
train | step:  13300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034751708,
     'losses/train_semantic_loss': 0.6238465,
     'losses/train_total_loss': 0.6238465}
train | step:  13400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6008416,
     'losses/train_total_loss': 0.6008416}
train | step:  13500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003451734,
     'losses/train_semantic_loss': 0.57899153,
     'losses/train_total_loss': 0.57899153}
train | step:  13600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.5862267,
     'losses/train_total_loss': 0.5862267}
train | step:  13700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00034282793,
     'losses/train_semantic_loss': 0.5250111,
     'losses/train_total_loss': 0.5250111}
train | step:  13800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.57829833,
     'losses/train_total_loss': 0.57829833}
train | step:  13900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003404807,
     'losses/train_semantic_loss': 0.5971064,
     'losses/train_total_loss': 0.5971064}
train | step:  14000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.6066141,
     'losses/train_total_loss': 0.6066141}
saved checkpoint to results/exp_006/ckpt-14000.
train | step:  14100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033813165,
     'losses/train_semantic_loss': 0.5544137,
     'losses/train_total_loss': 0.5544137}
train | step:  14200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.6072264,
     'losses/train_total_loss': 0.6072264}
train | step:  14300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033578082,
     'losses/train_semantic_loss': 0.5767694,
     'losses/train_total_loss': 0.5767694}
train | step:  14400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.6098237,
     'losses/train_total_loss': 0.6098237}
train | step:  14500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003334281,
     'losses/train_semantic_loss': 0.55801183,
     'losses/train_total_loss': 0.55801183}
train | step:  14600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.59495384,
     'losses/train_total_loss': 0.59495384}
train | step:  14700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00033107356,
     'losses/train_semantic_loss': 0.54898894,
     'losses/train_total_loss': 0.54898894}
train | step:  14800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.5509251,
     'losses/train_total_loss': 0.5509251}
train | step:  14900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032871717,
     'losses/train_semantic_loss': 0.6009056,
     'losses/train_total_loss': 0.6009056}
train | step:  15000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.5521338,
     'losses/train_total_loss': 0.5521338}
saved checkpoint to results/exp_006/ckpt-15000.
train | step:  15100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003263589,
     'losses/train_semantic_loss': 0.5358854,
     'losses/train_total_loss': 0.5358854}
train | step:  15200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.604497,
     'losses/train_total_loss': 0.604497}
train | step:  15300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032399874,
     'losses/train_semantic_loss': 0.5870211,
     'losses/train_total_loss': 0.5870211}
train | step:  15400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.62063646,
     'losses/train_total_loss': 0.62063646}
train | step:  15500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032163665,
     'losses/train_semantic_loss': 0.5933806,
     'losses/train_total_loss': 0.5933806}
train | step:  15600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.57413065,
     'losses/train_total_loss': 0.57413065}
train | step:  15700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003192726,
     'losses/train_semantic_loss': 0.5876941,
     'losses/train_total_loss': 0.5876941}
train | step:  15800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.54948884,
     'losses/train_total_loss': 0.54948884}
train | step:  15900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031690663,
     'losses/train_semantic_loss': 0.5561647,
     'losses/train_total_loss': 0.5561647}
train | step:  16000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.5847077,
     'losses/train_total_loss': 0.5847077}
saved checkpoint to results/exp_006/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   48.9 sec | output: 
    {'evaluation/iou/IoU': 0.654759,
     'losses/eval_semantic_loss': 0.70811826,
     'losses/eval_total_loss': 0.70811826}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.00031453875,
     'losses/train_semantic_loss': 0.56666595,
     'losses/train_total_loss': 0.56666595}
train | step:  16200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.5824119,
     'losses/train_total_loss': 0.5824119}
train | step:  16300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031216882,
     'losses/train_semantic_loss': 0.57520425,
     'losses/train_total_loss': 0.57520425}
train | step:  16400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.5647457,
     'losses/train_total_loss': 0.5647457}
train | step:  16500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030979692,
     'losses/train_semantic_loss': 0.58090943,
     'losses/train_total_loss': 0.58090943}
train | step:  16600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.61488307,
     'losses/train_total_loss': 0.61488307}
train | step:  16700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030742298,
     'losses/train_semantic_loss': 0.5618626,
     'losses/train_total_loss': 0.5618626}
train | step:  16800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.58492196,
     'losses/train_total_loss': 0.58492196}
train | step:  16900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030504703,
     'losses/train_semantic_loss': 0.54886335,
     'losses/train_total_loss': 0.54886335}
train | step:  17000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.5611496,
     'losses/train_total_loss': 0.5611496}
saved checkpoint to results/exp_006/ckpt-17000.
train | step:  17100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000302669,
     'losses/train_semantic_loss': 0.5848552,
     'losses/train_total_loss': 0.5848552}
train | step:  17200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.5459162,
     'losses/train_total_loss': 0.5459162}
train | step:  17300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00030028893,
     'losses/train_semantic_loss': 0.54386175,
     'losses/train_total_loss': 0.54386175}
train | step:  17400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.552347,
     'losses/train_total_loss': 0.552347}I0916 05:35:28.252417 139836075194176 controller.py:466] train | step:  17500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029790672,
     'losses/train_semantic_loss': 0.6002012,
     'losses/train_total_loss': 0.6002012}
I0916 05:37:06.623268 139836075194176 controller.py:466] train | step:  17600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.5977285,
     'losses/train_total_loss': 0.5977285}
I0916 05:38:45.448968 139836075194176 controller.py:466] train | step:  17700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029552242,
     'losses/train_semantic_loss': 0.52327627,
     'losses/train_total_loss': 0.52327627}
I0916 05:40:24.308851 139836075194176 controller.py:466] train | step:  17800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.5072667,
     'losses/train_total_loss': 0.5072667}
I0916 05:42:03.293447 139836075194176 controller.py:466] train | step:  17900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029313596,
     'losses/train_semantic_loss': 0.5306825,
     'losses/train_total_loss': 0.5306825}
I0916 05:43:42.140122 139836075194176 controller.py:466] train | step:  18000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5373771,
     'losses/train_total_loss': 0.5373771}
I0916 05:43:42.743020 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-18000.
I0916 05:45:21.723431 139836075194176 controller.py:466] train | step:  18100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029074732,
     'losses/train_semantic_loss': 0.5616415,
     'losses/train_total_loss': 0.5616415}
I0916 05:47:00.630807 139836075194176 controller.py:466] train | step:  18200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.5611258,
     'losses/train_total_loss': 0.5611258}
I0916 05:48:39.832723 139836075194176 controller.py:466] train | step:  18300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028835653,
     'losses/train_semantic_loss': 0.5480976,
     'losses/train_total_loss': 0.5480976}
I0916 05:50:18.987132 139836075194176 controller.py:466] train | step:  18400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.5929371,
     'losses/train_total_loss': 0.5929371}
I0916 05:51:58.048482 139836075194176 controller.py:466] train | step:  18500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028596356,
     'losses/train_semantic_loss': 0.52519083,
     'losses/train_total_loss': 0.52519083}
I0916 05:53:36.978526 139836075194176 controller.py:466] train | step:  18600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.5776174,
     'losses/train_total_loss': 0.5776174}
I0916 05:55:15.928805 139836075194176 controller.py:466] train | step:  18700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002835683,
     'losses/train_semantic_loss': 0.54867095,
     'losses/train_total_loss': 0.54867095}
I0916 05:56:54.822777 139836075194176 controller.py:466] train | step:  18800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.5364664,
     'losses/train_total_loss': 0.5364664}
I0916 05:58:33.617576 139836075194176 controller.py:466] train | step:  18900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028117083,
     'losses/train_semantic_loss': 0.5869116,
     'losses/train_total_loss': 0.5869116}
I0916 06:00:12.652100 139836075194176 controller.py:466] train | step:  19000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.54590315,
     'losses/train_total_loss': 0.54590315}
I0916 06:00:13.251763 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-19000.
I0916 06:01:51.930103 139836075194176 controller.py:466] train | step:  19100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027877107,
     'losses/train_semantic_loss': 0.5295147,
     'losses/train_total_loss': 0.5295147}
I0916 06:03:30.580787 139836075194176 controller.py:466] train | step:  19200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.53610826,
     'losses/train_total_loss': 0.53610826}
I0916 06:05:09.316546 139836075194176 controller.py:466] train | step:  19300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000276369,
     'losses/train_semantic_loss': 0.5149852,
     'losses/train_total_loss': 0.5149852}
I0916 06:06:47.799091 139836075194176 controller.py:466] train | step:  19400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.53393316,
     'losses/train_total_loss': 0.53393316}
I0916 06:08:26.356085 139836075194176 controller.py:466] train | step:  19500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027396463,
     'losses/train_semantic_loss': 0.52209485,
     'losses/train_total_loss': 0.52209485}
I0916 06:10:05.051278 139836075194176 controller.py:466] train | step:  19600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.55073315,
     'losses/train_total_loss': 0.55073315}
I0916 06:11:43.641121 139836075194176 controller.py:466] train | step:  19700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027155795,
     'losses/train_semantic_loss': 0.5306518,
     'losses/train_total_loss': 0.5306518}
I0916 06:13:22.182500 139836075194176 controller.py:466] train | step:  19800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.55543303,
     'losses/train_total_loss': 0.55543303}
I0916 06:15:01.134800 139836075194176 controller.py:466] train | step:  19900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026914882,
     'losses/train_semantic_loss': 0.56127226,
     'losses/train_total_loss': 0.56127226}
I0916 06:16:40.018813 139836075194176 controller.py:466] train | step:  20000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.5558941,
     'losses/train_total_loss': 0.5558941}
I0916 06:16:40.617081 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-20000.
I0916 06:16:40.617643 139836075194176 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0916 06:17:28.946104 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 06:17:28.950790 139836075194176 controller.py:295]  eval | step:  20000 | eval time:   48.3 sec | output: 
    {'evaluation/iou/IoU': 0.7309723,
     'losses/eval_semantic_loss': 0.46705142,
     'losses/eval_total_loss': 0.46705142}
I0916 06:17:28.956594 139836075194176 controller.py:241] train | step:  20000 | training until step 24000...
I0916 06:19:26.300738 139836075194176 controller.py:466] train | step:  20100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00026673733,
     'losses/train_semantic_loss': 0.57323843,
     'losses/train_total_loss': 0.57323843}
I0916 06:21:24.304231 139836075194176 controller.py:466] train | step:  20200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.5517933,
     'losses/train_total_loss': 0.5517933}
I0916 06:23:22.728138 139836075194176 controller.py:466] train | step:  20300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026432343,
     'losses/train_semantic_loss': 0.5359593,
     'losses/train_total_loss': 0.5359593}
I0916 06:25:19.830783 139836075194176 controller.py:466] train | step:  20400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5429098,
     'losses/train_total_loss': 0.5429098}
I0916 06:27:18.754467 139836075194176 controller.py:466] train | step:  20500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026190706,
     'losses/train_semantic_loss': 0.5227955,
     'losses/train_total_loss': 0.5227955}
I0916 06:29:16.996117 139836075194176 controller.py:466] train | step:  20600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.538128,
     'losses/train_total_loss': 0.538128}
I0916 06:31:14.477468 139836075194176 controller.py:466] train | step:  20700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0002594882,
     'losses/train_semantic_loss': 0.53766584,
     'losses/train_total_loss': 0.53766584}
I0916 06:33:12.258568 139836075194176 controller.py:466] train | step:  20800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5331255,
     'losses/train_total_loss': 0.5331255}
I0916 06:35:09.668521 139836075194176 controller.py:466] train | step:  20900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00025706686,
     'losses/train_semantic_loss': 0.5373512,
     'losses/train_total_loss': 0.5373512}
I0916 06:37:05.974366 139836075194176 controller.py:466] train | step:  21000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.53701955,
     'losses/train_total_loss': 0.53701955}
I0916 06:37:06.609966 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-21000.
I0916 06:38:45.673564 139836075194176 controller.py:466] train | step:  21100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025464298,
     'losses/train_semantic_loss': 0.51691186,
     'losses/train_total_loss': 0.51691186}
I0916 06:40:24.559412 139836075194176 controller.py:466] train | step:  21200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.54324085,
     'losses/train_total_loss': 0.54324085}
I0916 06:42:03.352577 139836075194176 controller.py:466] train | step:  21300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025221647,
     'losses/train_semantic_loss': 0.5820972,
     'losses/train_total_loss': 0.5820972}
I0916 06:43:42.292827 139836075194176 controller.py:466] train | step:  21400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5260741,
     'losses/train_total_loss': 0.5260741}
I0916 06:45:21.147872 139836075194176 controller.py:466] train | step:  21500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002497874,
     'losses/train_semantic_loss': 0.58338463,
     'losses/train_total_loss': 0.58338463}
I0916 06:46:59.995319 139836075194176 controller.py:466] train | step:  21600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.52863926,
     'losses/train_total_loss': 0.52863926}
I0916 06:48:38.834334 139836075194176 controller.py:466] train | step:  21700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024735578,
     'losses/train_semantic_loss': 0.54961294,
     'losses/train_total_loss': 0.54961294}
I0916 06:50:18.076125 139836075194176 controller.py:466] train | step:  21800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.52529454,
     'losses/train_total_loss': 0.52529454}

train | step:  17500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029790672,
     'losses/train_semantic_loss': 0.6002012,
     'losses/train_total_loss': 0.6002012}
train | step:  17600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.5977285,
     'losses/train_total_loss': 0.5977285}
train | step:  17700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029552242,
     'losses/train_semantic_loss': 0.52327627,
     'losses/train_total_loss': 0.52327627}
train | step:  17800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.5072667,
     'losses/train_total_loss': 0.5072667}
train | step:  17900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029313596,
     'losses/train_semantic_loss': 0.5306825,
     'losses/train_total_loss': 0.5306825}
train | step:  18000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5373771,
     'losses/train_total_loss': 0.5373771}
saved checkpoint to results/exp_006/ckpt-18000.
train | step:  18100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00029074732,
     'losses/train_semantic_loss': 0.5616415,
     'losses/train_total_loss': 0.5616415}
train | step:  18200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.5611258,
     'losses/train_total_loss': 0.5611258}
train | step:  18300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028835653,
     'losses/train_semantic_loss': 0.5480976,
     'losses/train_total_loss': 0.5480976}
train | step:  18400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.5929371,
     'losses/train_total_loss': 0.5929371}
train | step:  18500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028596356,
     'losses/train_semantic_loss': 0.52519083,
     'losses/train_total_loss': 0.52519083}
train | step:  18600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.5776174,
     'losses/train_total_loss': 0.5776174}
train | step:  18700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002835683,
     'losses/train_semantic_loss': 0.54867095,
     'losses/train_total_loss': 0.54867095}
train | step:  18800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.5364664,
     'losses/train_total_loss': 0.5364664}
train | step:  18900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00028117083,
     'losses/train_semantic_loss': 0.5869116,
     'losses/train_total_loss': 0.5869116}
train | step:  19000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.54590315,
     'losses/train_total_loss': 0.54590315}
saved checkpoint to results/exp_006/ckpt-19000.
train | step:  19100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027877107,
     'losses/train_semantic_loss': 0.5295147,
     'losses/train_total_loss': 0.5295147}
train | step:  19200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.53610826,
     'losses/train_total_loss': 0.53610826}
train | step:  19300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000276369,
     'losses/train_semantic_loss': 0.5149852,
     'losses/train_total_loss': 0.5149852}
train | step:  19400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.53393316,
     'losses/train_total_loss': 0.53393316}
train | step:  19500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027396463,
     'losses/train_semantic_loss': 0.52209485,
     'losses/train_total_loss': 0.52209485}
train | step:  19600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.55073315,
     'losses/train_total_loss': 0.55073315}
train | step:  19700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027155795,
     'losses/train_semantic_loss': 0.5306518,
     'losses/train_total_loss': 0.5306518}
train | step:  19800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.55543303,
     'losses/train_total_loss': 0.55543303}
train | step:  19900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00026914882,
     'losses/train_semantic_loss': 0.56127226,
     'losses/train_total_loss': 0.56127226}
train | step:  20000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.5558941,
     'losses/train_total_loss': 0.5558941}
saved checkpoint to results/exp_006/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   48.3 sec | output: 
    {'evaluation/iou/IoU': 0.7309723,
     'losses/eval_semantic_loss': 0.46705142,
     'losses/eval_total_loss': 0.46705142}
train | step:  20000 | training until step 24000...
train | step:  20100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00026673733,
     'losses/train_semantic_loss': 0.57323843,
     'losses/train_total_loss': 0.57323843}
train | step:  20200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.5517933,
     'losses/train_total_loss': 0.5517933}
train | step:  20300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026432343,
     'losses/train_semantic_loss': 0.5359593,
     'losses/train_total_loss': 0.5359593}
train | step:  20400 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5429098,
     'losses/train_total_loss': 0.5429098}
train | step:  20500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026190706,
     'losses/train_semantic_loss': 0.5227955,
     'losses/train_total_loss': 0.5227955}
train | step:  20600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.538128,
     'losses/train_total_loss': 0.538128}
train | step:  20700 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0002594882,
     'losses/train_semantic_loss': 0.53766584,
     'losses/train_total_loss': 0.53766584}
train | step:  20800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5331255,
     'losses/train_total_loss': 0.5331255}
train | step:  20900 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.00025706686,
     'losses/train_semantic_loss': 0.5373512,
     'losses/train_total_loss': 0.5373512}
train | step:  21000 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.53701955,
     'losses/train_total_loss': 0.53701955}
saved checkpoint to results/exp_006/ckpt-21000.
train | step:  21100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025464298,
     'losses/train_semantic_loss': 0.51691186,
     'losses/train_total_loss': 0.51691186}
train | step:  21200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.54324085,
     'losses/train_total_loss': 0.54324085}
train | step:  21300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00025221647,
     'losses/train_semantic_loss': 0.5820972,
     'losses/train_total_loss': 0.5820972}
train | step:  21400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5260741,
     'losses/train_total_loss': 0.5260741}
train | step:  21500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002497874,
     'losses/train_semantic_loss': 0.58338463,
     'losses/train_total_loss': 0.58338463}
train | step:  21600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.52863926,
     'losses/train_total_loss': 0.52863926}
train | step:  21700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024735578,
     'losses/train_semantic_loss': 0.54961294,
     'losses/train_total_loss': 0.54961294}
train | step:  21800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.52529454,
     'losses/train_total_loss': 0.52529454}I0916 06:51:57.142157 139836075194176 controller.py:466] train | step:  21900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024492142,
     'losses/train_semantic_loss': 0.50228304,
     'losses/train_total_loss': 0.50228304}
I0916 06:53:36.059497 139836075194176 controller.py:466] train | step:  22000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5356199,
     'losses/train_total_loss': 0.5356199}
I0916 06:53:36.657870 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-22000.
I0916 06:55:15.592839 139836075194176 controller.py:466] train | step:  22100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024248436,
     'losses/train_semantic_loss': 0.49411437,
     'losses/train_total_loss': 0.49411437}
I0916 06:56:54.531504 139836075194176 controller.py:466] train | step:  22200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.5320823,
     'losses/train_total_loss': 0.5320823}
I0916 06:58:33.243297 139836075194176 controller.py:466] train | step:  22300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024004461,
     'losses/train_semantic_loss': 0.53962535,
     'losses/train_total_loss': 0.53962535}
I0916 07:00:12.416686 139836075194176 controller.py:466] train | step:  22400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5128134,
     'losses/train_total_loss': 0.5128134}
I0916 07:01:51.231482 139836075194176 controller.py:466] train | step:  22500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002376021,
     'losses/train_semantic_loss': 0.5778433,
     'losses/train_total_loss': 0.5778433}
I0916 07:03:30.054228 139836075194176 controller.py:466] train | step:  22600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.5206818,
     'losses/train_total_loss': 0.5206818}
I0916 07:05:09.084208 139836075194176 controller.py:466] train | step:  22700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023515681,
     'losses/train_semantic_loss': 0.53763545,
     'losses/train_total_loss': 0.53763545}
I0916 07:06:48.076941 139836075194176 controller.py:466] train | step:  22800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.54013306,
     'losses/train_total_loss': 0.54013306}
I0916 07:08:27.135275 139836075194176 controller.py:466] train | step:  22900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023270865,
     'losses/train_semantic_loss': 0.5281017,
     'losses/train_total_loss': 0.5281017}
I0916 07:10:06.633956 139836075194176 controller.py:466] train | step:  23000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5218462,
     'losses/train_total_loss': 0.5218462}
I0916 07:10:07.280388 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-23000.
I0916 07:11:46.003482 139836075194176 controller.py:466] train | step:  23100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023025766,
     'losses/train_semantic_loss': 0.51342386,
     'losses/train_total_loss': 0.51342386}
I0916 07:13:24.646049 139836075194176 controller.py:466] train | step:  23200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5561187,
     'losses/train_total_loss': 0.5561187}
I0916 07:15:03.290306 139836075194176 controller.py:466] train | step:  23300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022780376,
     'losses/train_semantic_loss': 0.53834826,
     'losses/train_total_loss': 0.53834826}
I0916 07:16:41.652992 139836075194176 controller.py:466] train | step:  23400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5209988,
     'losses/train_total_loss': 0.5209988}
I0916 07:18:20.314464 139836075194176 controller.py:466] train | step:  23500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022534691,
     'losses/train_semantic_loss': 0.5370374,
     'losses/train_total_loss': 0.5370374}
I0916 07:19:58.660798 139836075194176 controller.py:466] train | step:  23600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.51554567,
     'losses/train_total_loss': 0.51554567}
I0916 07:21:37.078145 139836075194176 controller.py:466] train | step:  23700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022288707,
     'losses/train_semantic_loss': 0.48894456,
     'losses/train_total_loss': 0.48894456}
I0916 07:23:15.490334 139836075194176 controller.py:466] train | step:  23800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.5182335,
     'losses/train_total_loss': 0.5182335}
I0916 07:24:53.739496 139836075194176 controller.py:466] train | step:  23900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002204242,
     'losses/train_semantic_loss': 0.541871,
     'losses/train_total_loss': 0.541871}
I0916 07:26:31.845321 139836075194176 controller.py:466] train | step:  24000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.53953874,
     'losses/train_total_loss': 0.53953874}
I0916 07:26:32.461983 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-24000.
I0916 07:26:32.462485 139836075194176 controller.py:282]  eval | step:  24000 | running complete evaluation...
I0916 07:27:20.173578 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 07:27:20.179219 139836075194176 controller.py:295]  eval | step:  24000 | eval time:   47.7 sec | output: 
    {'evaluation/iou/IoU': 0.73212326,
     'losses/eval_semantic_loss': 0.4832967,
     'losses/eval_total_loss': 0.4832967}
I0916 07:27:20.186202 139836075194176 controller.py:241] train | step:  24000 | training until step 28000...
I0916 07:29:20.533790 139836075194176 controller.py:466] train | step:  24100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00021795831,
     'losses/train_semantic_loss': 0.5280255,
     'losses/train_total_loss': 0.5280255}
I0916 07:31:20.552539 139836075194176 controller.py:466] train | step:  24200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.49631217,
     'losses/train_total_loss': 0.49631217}
I0916 07:33:21.332568 139836075194176 controller.py:466] train | step:  24300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021548932,
     'losses/train_semantic_loss': 0.5293791,
     'losses/train_total_loss': 0.5293791}
I0916 07:35:21.818577 139836075194176 controller.py:466] train | step:  24400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.54754424,
     'losses/train_total_loss': 0.54754424}
I0916 07:37:22.021239 139836075194176 controller.py:466] train | step:  24500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021301713,
     'losses/train_semantic_loss': 0.5255452,
     'losses/train_total_loss': 0.5255452}
I0916 07:39:22.460683 139836075194176 controller.py:466] train | step:  24600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.510301,
     'losses/train_total_loss': 0.510301}
I0916 07:41:22.303162 139836075194176 controller.py:466] train | step:  24700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002105418,
     'losses/train_semantic_loss': 0.49565685,
     'losses/train_total_loss': 0.49565685}
I0916 07:43:22.586524 139836075194176 controller.py:466] train | step:  24800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.50478584,
     'losses/train_total_loss': 0.50478584}
I0916 07:45:22.728324 139836075194176 controller.py:466] train | step:  24900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020806321,
     'losses/train_semantic_loss': 0.5077767,
     'losses/train_total_loss': 0.5077767}
I0916 07:47:22.735016 139836075194176 controller.py:466] train | step:  25000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.5465981,
     'losses/train_total_loss': 0.5465981}
I0916 07:47:23.366843 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-25000.
I0916 07:49:01.399784 139836075194176 controller.py:466] train | step:  25100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020558134,
     'losses/train_semantic_loss': 0.49496368,
     'losses/train_total_loss': 0.49496368}
I0916 07:50:39.518015 139836075194176 controller.py:466] train | step:  25200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.52207,
     'losses/train_total_loss': 0.52207}
I0916 07:52:17.717760 139836075194176 controller.py:466] train | step:  25300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020309615,
     'losses/train_semantic_loss': 0.47848892,
     'losses/train_total_loss': 0.47848892}
I0916 07:53:56.007482 139836075194176 controller.py:466] train | step:  25400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.50876266,
     'losses/train_total_loss': 0.50876266}
I0916 07:55:34.427467 139836075194176 controller.py:466] train | step:  25500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020060755,
     'losses/train_semantic_loss': 0.5199946,
     'losses/train_total_loss': 0.5199946}
I0916 07:57:12.905646 139836075194176 controller.py:466] train | step:  25600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.49873322,
     'losses/train_total_loss': 0.49873322}
I0916 07:58:51.674579 139836075194176 controller.py:466] train | step:  25700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019811552,
     'losses/train_semantic_loss': 0.48300198,
     'losses/train_total_loss': 0.48300198}
I0916 08:00:30.529173 139836075194176 controller.py:466] train | step:  25800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5294765,
     'losses/train_total_loss': 0.5294765}
I0916 08:02:09.235605 139836075194176 controller.py:466] train | step:  25900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019562001,
     'losses/train_semantic_loss': 0.5181632,
     'losses/train_total_loss': 0.5181632}
I0916 08:03:48.115206 139836075194176 controller.py:466] train | step:  26000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.48367137,
     'losses/train_total_loss': 0.48367137}
I0916 08:03:48.760565 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-26000.
I0916 08:05:27.190166 139836075194176 controller.py:466] train | step:  26100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019312096,
     'losses/train_semantic_loss': 0.5546744,
     'losses/train_total_loss': 0.5546744}

train | step:  21900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024492142,
     'losses/train_semantic_loss': 0.50228304,
     'losses/train_total_loss': 0.50228304}
train | step:  22000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5356199,
     'losses/train_total_loss': 0.5356199}
saved checkpoint to results/exp_006/ckpt-22000.
train | step:  22100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024248436,
     'losses/train_semantic_loss': 0.49411437,
     'losses/train_total_loss': 0.49411437}
train | step:  22200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.5320823,
     'losses/train_total_loss': 0.5320823}
train | step:  22300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00024004461,
     'losses/train_semantic_loss': 0.53962535,
     'losses/train_total_loss': 0.53962535}
train | step:  22400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5128134,
     'losses/train_total_loss': 0.5128134}
train | step:  22500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002376021,
     'losses/train_semantic_loss': 0.5778433,
     'losses/train_total_loss': 0.5778433}
train | step:  22600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.5206818,
     'losses/train_total_loss': 0.5206818}
train | step:  22700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023515681,
     'losses/train_semantic_loss': 0.53763545,
     'losses/train_total_loss': 0.53763545}
train | step:  22800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.54013306,
     'losses/train_total_loss': 0.54013306}
train | step:  22900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023270865,
     'losses/train_semantic_loss': 0.5281017,
     'losses/train_total_loss': 0.5281017}
train | step:  23000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5218462,
     'losses/train_total_loss': 0.5218462}
saved checkpoint to results/exp_006/ckpt-23000.
train | step:  23100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00023025766,
     'losses/train_semantic_loss': 0.51342386,
     'losses/train_total_loss': 0.51342386}
train | step:  23200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5561187,
     'losses/train_total_loss': 0.5561187}
train | step:  23300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022780376,
     'losses/train_semantic_loss': 0.53834826,
     'losses/train_total_loss': 0.53834826}
train | step:  23400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5209988,
     'losses/train_total_loss': 0.5209988}
train | step:  23500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022534691,
     'losses/train_semantic_loss': 0.5370374,
     'losses/train_total_loss': 0.5370374}
train | step:  23600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.51554567,
     'losses/train_total_loss': 0.51554567}
train | step:  23700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022288707,
     'losses/train_semantic_loss': 0.48894456,
     'losses/train_total_loss': 0.48894456}
train | step:  23800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.5182335,
     'losses/train_total_loss': 0.5182335}
train | step:  23900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0002204242,
     'losses/train_semantic_loss': 0.541871,
     'losses/train_total_loss': 0.541871}
train | step:  24000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.53953874,
     'losses/train_total_loss': 0.53953874}
saved checkpoint to results/exp_006/ckpt-24000.
 eval | step:  24000 | running complete evaluation...
 eval | step:  24000 | eval time:   47.7 sec | output: 
    {'evaluation/iou/IoU': 0.73212326,
     'losses/eval_semantic_loss': 0.4832967,
     'losses/eval_total_loss': 0.4832967}
train | step:  24000 | training until step 28000...
train | step:  24100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00021795831,
     'losses/train_semantic_loss': 0.5280255,
     'losses/train_total_loss': 0.5280255}
train | step:  24200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.49631217,
     'losses/train_total_loss': 0.49631217}
train | step:  24300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021548932,
     'losses/train_semantic_loss': 0.5293791,
     'losses/train_total_loss': 0.5293791}
train | step:  24400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.54754424,
     'losses/train_total_loss': 0.54754424}
train | step:  24500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021301713,
     'losses/train_semantic_loss': 0.5255452,
     'losses/train_total_loss': 0.5255452}
train | step:  24600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.510301,
     'losses/train_total_loss': 0.510301}
train | step:  24700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002105418,
     'losses/train_semantic_loss': 0.49565685,
     'losses/train_total_loss': 0.49565685}
train | step:  24800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.50478584,
     'losses/train_total_loss': 0.50478584}
train | step:  24900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020806321,
     'losses/train_semantic_loss': 0.5077767,
     'losses/train_total_loss': 0.5077767}
train | step:  25000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.5465981,
     'losses/train_total_loss': 0.5465981}
saved checkpoint to results/exp_006/ckpt-25000.
train | step:  25100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020558134,
     'losses/train_semantic_loss': 0.49496368,
     'losses/train_total_loss': 0.49496368}
train | step:  25200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.52207,
     'losses/train_total_loss': 0.52207}
train | step:  25300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020309615,
     'losses/train_semantic_loss': 0.47848892,
     'losses/train_total_loss': 0.47848892}
train | step:  25400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.50876266,
     'losses/train_total_loss': 0.50876266}
train | step:  25500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00020060755,
     'losses/train_semantic_loss': 0.5199946,
     'losses/train_total_loss': 0.5199946}
train | step:  25600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.49873322,
     'losses/train_total_loss': 0.49873322}
train | step:  25700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019811552,
     'losses/train_semantic_loss': 0.48300198,
     'losses/train_total_loss': 0.48300198}
train | step:  25800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5294765,
     'losses/train_total_loss': 0.5294765}
train | step:  25900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019562001,
     'losses/train_semantic_loss': 0.5181632,
     'losses/train_total_loss': 0.5181632}
train | step:  26000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.48367137,
     'losses/train_total_loss': 0.48367137}
saved checkpoint to results/exp_006/ckpt-26000.
train | step:  26100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019312096,
     'losses/train_semantic_loss': 0.5546744,
     'losses/train_total_loss': 0.5546744}I0916 08:07:05.818554 139836075194176 controller.py:466] train | step:  26200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.49346915,
     'losses/train_total_loss': 0.49346915}
I0916 08:08:44.748615 139836075194176 controller.py:466] train | step:  26300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019061826,
     'losses/train_semantic_loss': 0.5554031,
     'losses/train_total_loss': 0.5554031}
I0916 08:10:23.751439 139836075194176 controller.py:466] train | step:  26400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.53431815,
     'losses/train_total_loss': 0.53431815}
I0916 08:12:02.475687 139836075194176 controller.py:466] train | step:  26500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018811195,
     'losses/train_semantic_loss': 0.5175251,
     'losses/train_total_loss': 0.5175251}
I0916 08:13:41.432519 139836075194176 controller.py:466] train | step:  26600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.48215926,
     'losses/train_total_loss': 0.48215926}
I0916 08:15:20.354613 139836075194176 controller.py:466] train | step:  26700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018560192,
     'losses/train_semantic_loss': 0.4959636,
     'losses/train_total_loss': 0.4959636}
I0916 08:16:59.184154 139836075194176 controller.py:466] train | step:  26800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.52133596,
     'losses/train_total_loss': 0.52133596}
I0916 08:18:38.084141 139836075194176 controller.py:466] train | step:  26900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018308814,
     'losses/train_semantic_loss': 0.52770036,
     'losses/train_total_loss': 0.52770036}
I0916 08:20:16.674242 139836075194176 controller.py:466] train | step:  27000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.510154,
     'losses/train_total_loss': 0.510154}
I0916 08:20:17.313850 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-27000.
I0916 08:21:56.046337 139836075194176 controller.py:466] train | step:  27100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018057048,
     'losses/train_semantic_loss': 0.53443474,
     'losses/train_total_loss': 0.53443474}
I0916 08:23:34.808445 139836075194176 controller.py:466] train | step:  27200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.4943322,
     'losses/train_total_loss': 0.4943322}
I0916 08:25:13.352282 139836075194176 controller.py:466] train | step:  27300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017804893,
     'losses/train_semantic_loss': 0.4896573,
     'losses/train_total_loss': 0.4896573}
I0916 08:26:52.023570 139836075194176 controller.py:466] train | step:  27400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.51195,
     'losses/train_total_loss': 0.51195}
I0916 08:28:30.434988 139836075194176 controller.py:466] train | step:  27500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017552341,
     'losses/train_semantic_loss': 0.49561962,
     'losses/train_total_loss': 0.49561962}
I0916 08:30:08.998725 139836075194176 controller.py:466] train | step:  27600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.527859,
     'losses/train_total_loss': 0.527859}
I0916 08:31:47.442044 139836075194176 controller.py:466] train | step:  27700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017299385,
     'losses/train_semantic_loss': 0.51405,
     'losses/train_total_loss': 0.51405}
I0916 08:33:25.688828 139836075194176 controller.py:466] train | step:  27800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.50899136,
     'losses/train_total_loss': 0.50899136}
I0916 08:35:03.973619 139836075194176 controller.py:466] train | step:  27900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017046016,
     'losses/train_semantic_loss': 0.48278016,
     'losses/train_total_loss': 0.48278016}
I0916 08:36:42.148866 139836075194176 controller.py:466] train | step:  28000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.49893364,
     'losses/train_total_loss': 0.49893364}
I0916 08:36:42.766665 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-28000.
I0916 08:36:42.767200 139836075194176 controller.py:282]  eval | step:  28000 | running complete evaluation...
I0916 08:37:30.531605 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 08:37:30.536269 139836075194176 controller.py:295]  eval | step:  28000 | eval time:   47.8 sec | output: 
    {'evaluation/iou/IoU': 0.74217486,
     'losses/eval_semantic_loss': 0.44078293,
     'losses/eval_total_loss': 0.44078293}
I0916 08:37:30.541933 139836075194176 controller.py:241] train | step:  28000 | training until step 32000...
I0916 08:39:30.284980 139836075194176 controller.py:466] train | step:  28100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00016792228,
     'losses/train_semantic_loss': 0.49565116,
     'losses/train_total_loss': 0.49565116}
I0916 08:41:29.448404 139836075194176 controller.py:466] train | step:  28200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.46925423,
     'losses/train_total_loss': 0.46925423}
I0916 08:43:28.990041 139836075194176 controller.py:466] train | step:  28300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016538013,
     'losses/train_semantic_loss': 0.46515033,
     'losses/train_total_loss': 0.46515033}
I0916 08:45:28.730647 139836075194176 controller.py:466] train | step:  28400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.47525752,
     'losses/train_total_loss': 0.47525752}
I0916 08:47:28.200539 139836075194176 controller.py:466] train | step:  28500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016283363,
     'losses/train_semantic_loss': 0.48648763,
     'losses/train_total_loss': 0.48648763}
I0916 08:49:27.244924 139836075194176 controller.py:466] train | step:  28600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.4956022,
     'losses/train_total_loss': 0.4956022}
I0916 08:51:27.006943 139836075194176 controller.py:466] train | step:  28700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016028271,
     'losses/train_semantic_loss': 0.47066385,
     'losses/train_total_loss': 0.47066385}
I0916 08:53:25.842313 139836075194176 controller.py:466] train | step:  28800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.48575568,
     'losses/train_total_loss': 0.48575568}
I0916 08:55:24.929176 139836075194176 controller.py:466] train | step:  28900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015772722,
     'losses/train_semantic_loss': 0.491506,
     'losses/train_total_loss': 0.491506}
I0916 08:57:24.925080 139836075194176 controller.py:466] train | step:  29000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5064881,
     'losses/train_total_loss': 0.5064881}
I0916 08:57:25.555581 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-29000.
I0916 08:59:04.322311 139836075194176 controller.py:466] train | step:  29100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015516719,
     'losses/train_semantic_loss': 0.50979114,
     'losses/train_total_loss': 0.50979114}
I0916 09:00:43.353809 139836075194176 controller.py:466] train | step:  29200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.47336453,
     'losses/train_total_loss': 0.47336453}
I0916 09:02:22.212674 139836075194176 controller.py:466] train | step:  29300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015260243,
     'losses/train_semantic_loss': 0.49519387,
     'losses/train_total_loss': 0.49519387}
I0916 09:04:01.200442 139836075194176 controller.py:466] train | step:  29400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.4704857,
     'losses/train_total_loss': 0.4704857}
I0916 09:05:40.299540 139836075194176 controller.py:466] train | step:  29500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015003285,
     'losses/train_semantic_loss': 0.4850097,
     'losses/train_total_loss': 0.4850097}
I0916 09:07:19.166846 139836075194176 controller.py:466] train | step:  29600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.46254456,
     'losses/train_total_loss': 0.46254456}
I0916 09:08:57.859165 139836075194176 controller.py:466] train | step:  29700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001474584,
     'losses/train_semantic_loss': 0.5011274,
     'losses/train_total_loss': 0.5011274}
I0916 09:10:36.666193 139836075194176 controller.py:466] train | step:  29800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5006261,
     'losses/train_total_loss': 0.5006261}
I0916 09:12:15.458841 139836075194176 controller.py:466] train | step:  29900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014487894,
     'losses/train_semantic_loss': 0.5118214,
     'losses/train_total_loss': 0.5118214}
I0916 09:13:54.055559 139836075194176 controller.py:466] train | step:  30000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.49640134,
     'losses/train_total_loss': 0.49640134}
I0916 09:13:54.899936 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-30000.
I0916 09:15:33.658231 139836075194176 controller.py:466] train | step:  30100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014229439,
     'losses/train_semantic_loss': 0.5149458,
     'losses/train_total_loss': 0.5149458}
I0916 09:17:12.116363 139836075194176 controller.py:466] train | step:  30200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.47818622,
     'losses/train_total_loss': 0.47818622}
I0916 09:18:50.534514 139836075194176 controller.py:466] train | step:  30300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013970456,
     'losses/train_semantic_loss': 0.48395523,
     'losses/train_total_loss': 0.48395523}
I0916 09:20:29.035011 139836075194176 controller.py:466] train | step:  30400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.48569643,
     'losses/train_total_loss': 0.48569643}
I0916 09:22:07.819342 139836075194176 controller.py:466] train | step:  30500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013710944,
     'losses/train_semantic_loss': 0.48745143,
     'losses/train_total_loss': 0.48745143}

train | step:  26200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.49346915,
     'losses/train_total_loss': 0.49346915}
train | step:  26300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00019061826,
     'losses/train_semantic_loss': 0.5554031,
     'losses/train_total_loss': 0.5554031}
train | step:  26400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.53431815,
     'losses/train_total_loss': 0.53431815}
train | step:  26500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018811195,
     'losses/train_semantic_loss': 0.5175251,
     'losses/train_total_loss': 0.5175251}
train | step:  26600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.48215926,
     'losses/train_total_loss': 0.48215926}
train | step:  26700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018560192,
     'losses/train_semantic_loss': 0.4959636,
     'losses/train_total_loss': 0.4959636}
train | step:  26800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.52133596,
     'losses/train_total_loss': 0.52133596}
train | step:  26900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018308814,
     'losses/train_semantic_loss': 0.52770036,
     'losses/train_total_loss': 0.52770036}
train | step:  27000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.510154,
     'losses/train_total_loss': 0.510154}
saved checkpoint to results/exp_006/ckpt-27000.
train | step:  27100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00018057048,
     'losses/train_semantic_loss': 0.53443474,
     'losses/train_total_loss': 0.53443474}
train | step:  27200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.4943322,
     'losses/train_total_loss': 0.4943322}
train | step:  27300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017804893,
     'losses/train_semantic_loss': 0.4896573,
     'losses/train_total_loss': 0.4896573}
train | step:  27400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.51195,
     'losses/train_total_loss': 0.51195}
train | step:  27500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017552341,
     'losses/train_semantic_loss': 0.49561962,
     'losses/train_total_loss': 0.49561962}
train | step:  27600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.527859,
     'losses/train_total_loss': 0.527859}
train | step:  27700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017299385,
     'losses/train_semantic_loss': 0.51405,
     'losses/train_total_loss': 0.51405}
train | step:  27800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.50899136,
     'losses/train_total_loss': 0.50899136}
train | step:  27900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00017046016,
     'losses/train_semantic_loss': 0.48278016,
     'losses/train_total_loss': 0.48278016}
train | step:  28000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.49893364,
     'losses/train_total_loss': 0.49893364}
saved checkpoint to results/exp_006/ckpt-28000.
 eval | step:  28000 | running complete evaluation...
 eval | step:  28000 | eval time:   47.8 sec | output: 
    {'evaluation/iou/IoU': 0.74217486,
     'losses/eval_semantic_loss': 0.44078293,
     'losses/eval_total_loss': 0.44078293}
train | step:  28000 | training until step 32000...
train | step:  28100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00016792228,
     'losses/train_semantic_loss': 0.49565116,
     'losses/train_total_loss': 0.49565116}
train | step:  28200 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.46925423,
     'losses/train_total_loss': 0.46925423}
train | step:  28300 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016538013,
     'losses/train_semantic_loss': 0.46515033,
     'losses/train_total_loss': 0.46515033}
train | step:  28400 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.47525752,
     'losses/train_total_loss': 0.47525752}
train | step:  28500 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016283363,
     'losses/train_semantic_loss': 0.48648763,
     'losses/train_total_loss': 0.48648763}
train | step:  28600 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.4956022,
     'losses/train_total_loss': 0.4956022}
train | step:  28700 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00016028271,
     'losses/train_semantic_loss': 0.47066385,
     'losses/train_total_loss': 0.47066385}
train | step:  28800 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.48575568,
     'losses/train_total_loss': 0.48575568}
train | step:  28900 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015772722,
     'losses/train_semantic_loss': 0.491506,
     'losses/train_total_loss': 0.491506}
train | step:  29000 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.5064881,
     'losses/train_total_loss': 0.5064881}
saved checkpoint to results/exp_006/ckpt-29000.
train | step:  29100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015516719,
     'losses/train_semantic_loss': 0.50979114,
     'losses/train_total_loss': 0.50979114}
train | step:  29200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.47336453,
     'losses/train_total_loss': 0.47336453}
train | step:  29300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015260243,
     'losses/train_semantic_loss': 0.49519387,
     'losses/train_total_loss': 0.49519387}
train | step:  29400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.4704857,
     'losses/train_total_loss': 0.4704857}
train | step:  29500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00015003285,
     'losses/train_semantic_loss': 0.4850097,
     'losses/train_total_loss': 0.4850097}
train | step:  29600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.46254456,
     'losses/train_total_loss': 0.46254456}
train | step:  29700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001474584,
     'losses/train_semantic_loss': 0.5011274,
     'losses/train_total_loss': 0.5011274}
train | step:  29800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5006261,
     'losses/train_total_loss': 0.5006261}
train | step:  29900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014487894,
     'losses/train_semantic_loss': 0.5118214,
     'losses/train_total_loss': 0.5118214}
train | step:  30000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.49640134,
     'losses/train_total_loss': 0.49640134}
saved checkpoint to results/exp_006/ckpt-30000.
train | step:  30100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014229439,
     'losses/train_semantic_loss': 0.5149458,
     'losses/train_total_loss': 0.5149458}
train | step:  30200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.47818622,
     'losses/train_total_loss': 0.47818622}
train | step:  30300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013970456,
     'losses/train_semantic_loss': 0.48395523,
     'losses/train_total_loss': 0.48395523}
train | step:  30400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.48569643,
     'losses/train_total_loss': 0.48569643}
train | step:  30500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013710944,
     'losses/train_semantic_loss': 0.48745143,
     'losses/train_total_loss': 0.48745143}I0916 09:23:46.371639 139836075194176 controller.py:466] train | step:  30600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.48758766,
     'losses/train_total_loss': 0.48758766}
I0916 09:25:24.999876 139836075194176 controller.py:466] train | step:  30700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013450881,
     'losses/train_semantic_loss': 0.50863683,
     'losses/train_total_loss': 0.50863683}
I0916 09:27:03.660211 139836075194176 controller.py:466] train | step:  30800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.46848014,
     'losses/train_total_loss': 0.46848014}
I0916 09:28:42.340231 139836075194176 controller.py:466] train | step:  30900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013190259,
     'losses/train_semantic_loss': 0.48409703,
     'losses/train_total_loss': 0.48409703}
I0916 09:30:20.918245 139836075194176 controller.py:466] train | step:  31000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.46819228,
     'losses/train_total_loss': 0.46819228}
I0916 09:30:21.518080 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-31000.
I0916 09:31:59.982142 139836075194176 controller.py:466] train | step:  31100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012929064,
     'losses/train_semantic_loss': 0.5140781,
     'losses/train_total_loss': 0.5140781}
I0916 09:33:38.491070 139836075194176 controller.py:466] train | step:  31200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.50371,
     'losses/train_total_loss': 0.50371}
I0916 09:35:16.801125 139836075194176 controller.py:466] train | step:  31300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012667278,
     'losses/train_semantic_loss': 0.46712708,
     'losses/train_total_loss': 0.46712708}
I0916 09:36:55.524701 139836075194176 controller.py:466] train | step:  31400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.45652106,
     'losses/train_total_loss': 0.45652106}
I0916 09:38:33.945871 139836075194176 controller.py:466] train | step:  31500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012404894,
     'losses/train_semantic_loss': 0.45400017,
     'losses/train_total_loss': 0.45400017}
I0916 09:40:12.583627 139836075194176 controller.py:466] train | step:  31600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.45491505,
     'losses/train_total_loss': 0.45491505}
I0916 09:41:51.105250 139836075194176 controller.py:466] train | step:  31700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012141889,
     'losses/train_semantic_loss': 0.48654193,
     'losses/train_total_loss': 0.48654193}
I0916 09:43:29.980582 139836075194176 controller.py:466] train | step:  31800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.4799265,
     'losses/train_total_loss': 0.4799265}
I0916 09:45:08.611291 139836075194176 controller.py:466] train | step:  31900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011878252,
     'losses/train_semantic_loss': 0.4829024,
     'losses/train_total_loss': 0.4829024}
I0916 09:46:47.371256 139836075194176 controller.py:466] train | step:  32000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.49962857,
     'losses/train_total_loss': 0.49962857}
I0916 09:46:47.968921 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-32000.
I0916 09:46:47.969413 139836075194176 controller.py:282]  eval | step:  32000 | running complete evaluation...
I0916 09:47:34.993539 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 09:47:35.009321 139836075194176 controller.py:295]  eval | step:  32000 | eval time:   47.0 sec | output: 
    {'evaluation/iou/IoU': 0.7436038,
     'losses/eval_semantic_loss': 0.43654978,
     'losses/eval_total_loss': 0.43654978}
I0916 09:47:35.015594 139836075194176 controller.py:241] train | step:  32000 | training until step 36000...
I0916 09:49:13.696169 139836075194176 controller.py:466] train | step:  32100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.000116139614,
     'losses/train_semantic_loss': 0.4829261,
     'losses/train_total_loss': 0.4829261}
I0916 09:50:52.732530 139836075194176 controller.py:466] train | step:  32200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.48938343,
     'losses/train_total_loss': 0.48938343}
I0916 09:52:31.577694 139836075194176 controller.py:466] train | step:  32300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011349003,
     'losses/train_semantic_loss': 0.46817562,
     'losses/train_total_loss': 0.46817562}
I0916 09:54:10.466696 139836075194176 controller.py:466] train | step:  32400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.49929458,
     'losses/train_total_loss': 0.49929458}
I0916 09:55:49.566271 139836075194176 controller.py:466] train | step:  32500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011083353,
     'losses/train_semantic_loss': 0.47258252,
     'losses/train_total_loss': 0.47258252}
I0916 09:57:28.673699 139836075194176 controller.py:466] train | step:  32600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.4933194,
     'losses/train_total_loss': 0.4933194}
I0916 09:59:07.931139 139836075194176 controller.py:466] train | step:  32700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010816996,
     'losses/train_semantic_loss': 0.45882294,
     'losses/train_total_loss': 0.45882294}
I0916 10:00:47.198541 139836075194176 controller.py:466] train | step:  32800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.47177356,
     'losses/train_total_loss': 0.47177356}
I0916 10:02:26.385760 139836075194176 controller.py:466] train | step:  32900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010549906,
     'losses/train_semantic_loss': 0.47611177,
     'losses/train_total_loss': 0.47611177}
I0916 10:04:05.616067 139836075194176 controller.py:466] train | step:  33000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.4898998,
     'losses/train_total_loss': 0.4898998}
I0916 10:04:06.222952 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-33000.
I0916 10:05:45.475499 139836075194176 controller.py:466] train | step:  33100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010282063,
     'losses/train_semantic_loss': 0.47741184,
     'losses/train_total_loss': 0.47741184}
I0916 10:07:24.737004 139836075194176 controller.py:466] train | step:  33200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.48192856,
     'losses/train_total_loss': 0.48192856}
I0916 10:09:04.064122 139836075194176 controller.py:466] train | step:  33300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010013443,
     'losses/train_semantic_loss': 0.48606578,
     'losses/train_total_loss': 0.48606578}
I0916 10:10:43.151395 139836075194176 controller.py:466] train | step:  33400 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.4349373,
     'losses/train_total_loss': 0.4349373}
I0916 10:12:22.475405 139836075194176 controller.py:466] train | step:  33500 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.7440185e-05,
     'losses/train_semantic_loss': 0.50129175,
     'losses/train_total_loss': 0.50129175}
I0916 10:14:01.635224 139836075194176 controller.py:466] train | step:  33600 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.47826385,
     'losses/train_total_loss': 0.47826385}
I0916 10:15:40.908798 139836075194176 controller.py:466] train | step:  33700 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.473764e-05,
     'losses/train_semantic_loss': 0.47339278,
     'losses/train_total_loss': 0.47339278}
I0916 10:17:19.971275 139836075194176 controller.py:466] train | step:  33800 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.44720674,
     'losses/train_total_loss': 0.44720674}
I0916 10:18:59.216836 139836075194176 controller.py:466] train | step:  33900 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.2026494e-05,
     'losses/train_semantic_loss': 0.48268047,
     'losses/train_total_loss': 0.48268047}
I0916 10:20:38.418991 139836075194176 controller.py:466] train | step:  34000 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.44934922,
     'losses/train_total_loss': 0.44934922}
I0916 10:20:39.020010 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-34000.
I0916 10:22:18.168929 139836075194176 controller.py:466] train | step:  34100 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.930646e-05,
     'losses/train_semantic_loss': 0.4709979,
     'losses/train_total_loss': 0.4709979}
I0916 10:23:57.549965 139836075194176 controller.py:466] train | step:  34200 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.46206626,
     'losses/train_total_loss': 0.46206626}
I0916 10:25:36.837854 139836075194176 controller.py:466] train | step:  34300 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.6577165e-05,
     'losses/train_semantic_loss': 0.47021317,
     'losses/train_total_loss': 0.47021317}
I0916 10:27:16.046285 139836075194176 controller.py:466] train | step:  34400 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.45677105,
     'losses/train_total_loss': 0.45677105}
I0916 10:28:55.372529 139836075194176 controller.py:466] train | step:  34500 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.3838306e-05,
     'losses/train_semantic_loss': 0.47612727,
     'losses/train_total_loss': 0.47612727}
I0916 10:30:34.758838 139836075194176 controller.py:466] train | step:  34600 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.44912234,
     'losses/train_total_loss': 0.44912234}
I0916 10:32:14.162837 139836075194176 controller.py:466] train | step:  34700 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.1089434e-05,
     'losses/train_semantic_loss': 0.48257104,
     'losses/train_total_loss': 0.48257104}
I0916 10:33:53.495524 139836075194176 controller.py:466] train | step:  34800 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.47187218,
     'losses/train_total_loss': 0.47187218}
I0916 10:35:32.880638 139836075194176 controller.py:466] train | step:  34900 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.8330195e-05,
     'losses/train_semantic_loss': 0.46503502,
     'losses/train_total_loss': 0.46503502}

train | step:  30600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.48758766,
     'losses/train_total_loss': 0.48758766}
train | step:  30700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013450881,
     'losses/train_semantic_loss': 0.50863683,
     'losses/train_total_loss': 0.50863683}
train | step:  30800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.46848014,
     'losses/train_total_loss': 0.46848014}
train | step:  30900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013190259,
     'losses/train_semantic_loss': 0.48409703,
     'losses/train_total_loss': 0.48409703}
train | step:  31000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.46819228,
     'losses/train_total_loss': 0.46819228}
saved checkpoint to results/exp_006/ckpt-31000.
train | step:  31100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012929064,
     'losses/train_semantic_loss': 0.5140781,
     'losses/train_total_loss': 0.5140781}
train | step:  31200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.50371,
     'losses/train_total_loss': 0.50371}
train | step:  31300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012667278,
     'losses/train_semantic_loss': 0.46712708,
     'losses/train_total_loss': 0.46712708}
train | step:  31400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.45652106,
     'losses/train_total_loss': 0.45652106}
train | step:  31500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012404894,
     'losses/train_semantic_loss': 0.45400017,
     'losses/train_total_loss': 0.45400017}
train | step:  31600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.45491505,
     'losses/train_total_loss': 0.45491505}
train | step:  31700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012141889,
     'losses/train_semantic_loss': 0.48654193,
     'losses/train_total_loss': 0.48654193}
train | step:  31800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.4799265,
     'losses/train_total_loss': 0.4799265}
train | step:  31900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011878252,
     'losses/train_semantic_loss': 0.4829024,
     'losses/train_total_loss': 0.4829024}
train | step:  32000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.49962857,
     'losses/train_total_loss': 0.49962857}
saved checkpoint to results/exp_006/ckpt-32000.
 eval | step:  32000 | running complete evaluation...
 eval | step:  32000 | eval time:   47.0 sec | output: 
    {'evaluation/iou/IoU': 0.7436038,
     'losses/eval_semantic_loss': 0.43654978,
     'losses/eval_total_loss': 0.43654978}
train | step:  32000 | training until step 36000...
train | step:  32100 | steps/sec:    0.7 | output: 
    {'learning_rate': 0.000116139614,
     'losses/train_semantic_loss': 0.4829261,
     'losses/train_total_loss': 0.4829261}
train | step:  32200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.48938343,
     'losses/train_total_loss': 0.48938343}
train | step:  32300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011349003,
     'losses/train_semantic_loss': 0.46817562,
     'losses/train_total_loss': 0.46817562}
train | step:  32400 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.49929458,
     'losses/train_total_loss': 0.49929458}
train | step:  32500 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00011083353,
     'losses/train_semantic_loss': 0.47258252,
     'losses/train_total_loss': 0.47258252}
train | step:  32600 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.4933194,
     'losses/train_total_loss': 0.4933194}
train | step:  32700 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010816996,
     'losses/train_semantic_loss': 0.45882294,
     'losses/train_total_loss': 0.45882294}
train | step:  32800 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.47177356,
     'losses/train_total_loss': 0.47177356}
train | step:  32900 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010549906,
     'losses/train_semantic_loss': 0.47611177,
     'losses/train_total_loss': 0.47611177}
train | step:  33000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.4898998,
     'losses/train_total_loss': 0.4898998}
saved checkpoint to results/exp_006/ckpt-33000.
train | step:  33100 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010282063,
     'losses/train_semantic_loss': 0.47741184,
     'losses/train_total_loss': 0.47741184}
train | step:  33200 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.48192856,
     'losses/train_total_loss': 0.48192856}
train | step:  33300 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.00010013443,
     'losses/train_semantic_loss': 0.48606578,
     'losses/train_total_loss': 0.48606578}
train | step:  33400 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.4349373,
     'losses/train_total_loss': 0.4349373}
train | step:  33500 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.7440185e-05,
     'losses/train_semantic_loss': 0.50129175,
     'losses/train_total_loss': 0.50129175}
train | step:  33600 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.47826385,
     'losses/train_total_loss': 0.47826385}
train | step:  33700 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.473764e-05,
     'losses/train_semantic_loss': 0.47339278,
     'losses/train_total_loss': 0.47339278}
train | step:  33800 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.44720674,
     'losses/train_total_loss': 0.44720674}
train | step:  33900 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.2026494e-05,
     'losses/train_semantic_loss': 0.48268047,
     'losses/train_total_loss': 0.48268047}
train | step:  34000 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.44934922,
     'losses/train_total_loss': 0.44934922}
saved checkpoint to results/exp_006/ckpt-34000.
train | step:  34100 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.930646e-05,
     'losses/train_semantic_loss': 0.4709979,
     'losses/train_total_loss': 0.4709979}
train | step:  34200 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.46206626,
     'losses/train_total_loss': 0.46206626}
train | step:  34300 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.6577165e-05,
     'losses/train_semantic_loss': 0.47021317,
     'losses/train_total_loss': 0.47021317}
train | step:  34400 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.45677105,
     'losses/train_total_loss': 0.45677105}
train | step:  34500 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.3838306e-05,
     'losses/train_semantic_loss': 0.47612727,
     'losses/train_total_loss': 0.47612727}
train | step:  34600 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.44912234,
     'losses/train_total_loss': 0.44912234}
train | step:  34700 | steps/sec:    1.0 | output: 
    {'learning_rate': 8.1089434e-05,
     'losses/train_semantic_loss': 0.48257104,
     'losses/train_total_loss': 0.48257104}
train | step:  34800 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.47187218,
     'losses/train_total_loss': 0.47187218}
train | step:  34900 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.8330195e-05,
     'losses/train_semantic_loss': 0.46503502,
     'losses/train_total_loss': 0.46503502}I0916 10:37:12.187340 139836075194176 controller.py:466] train | step:  35000 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.47495097,
     'losses/train_total_loss': 0.47495097}
I0916 10:37:12.800432 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-35000.
I0916 10:38:52.214880 139836075194176 controller.py:466] train | step:  35100 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.55601e-05,
     'losses/train_semantic_loss': 0.46520352,
     'losses/train_total_loss': 0.46520352}
I0916 10:40:31.570690 139836075194176 controller.py:466] train | step:  35200 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.50655127,
     'losses/train_total_loss': 0.50655127}
I0916 10:42:10.833529 139836075194176 controller.py:466] train | step:  35300 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.2778676e-05,
     'losses/train_semantic_loss': 0.48647344,
     'losses/train_total_loss': 0.48647344}
I0916 10:43:50.022206 139836075194176 controller.py:466] train | step:  35400 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.44157016,
     'losses/train_total_loss': 0.44157016}
I0916 10:45:29.338799 139836075194176 controller.py:466] train | step:  35500 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.9985384e-05,
     'losses/train_semantic_loss': 0.4844873,
     'losses/train_total_loss': 0.4844873}
I0916 10:47:08.528743 139836075194176 controller.py:466] train | step:  35600 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.43954656,
     'losses/train_total_loss': 0.43954656}
I0916 10:48:47.901209 139836075194176 controller.py:466] train | step:  35700 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.7179644e-05,
     'losses/train_semantic_loss': 0.46072057,
     'losses/train_total_loss': 0.46072057}
I0916 10:50:27.100551 139836075194176 controller.py:466] train | step:  35800 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.45229858,
     'losses/train_total_loss': 0.45229858}
I0916 10:52:06.364966 139836075194176 controller.py:466] train | step:  35900 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.436082e-05,
     'losses/train_semantic_loss': 0.46148494,
     'losses/train_total_loss': 0.46148494}
I0916 10:53:45.737232 139836075194176 controller.py:466] train | step:  36000 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.43095782,
     'losses/train_total_loss': 0.43095782}
I0916 10:53:46.366693 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-36000.
I0916 10:53:46.367275 139836075194176 controller.py:282]  eval | step:  36000 | running complete evaluation...
I0916 10:54:34.124051 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 10:54:34.128914 139836075194176 controller.py:295]  eval | step:  36000 | eval time:   47.8 sec | output: 
    {'evaluation/iou/IoU': 0.74796975,
     'losses/eval_semantic_loss': 0.4285659,
     'losses/eval_total_loss': 0.4285659}
I0916 10:54:34.135020 139836075194176 controller.py:241] train | step:  36000 | training until step 40000...
I0916 10:56:27.359929 139836075194176 controller.py:466] train | step:  36100 | steps/sec:    0.6 | output: 
    {'learning_rate': 6.152822e-05,
     'losses/train_semantic_loss': 0.46335,
     'losses/train_total_loss': 0.46335}
I0916 10:58:20.017635 139836075194176 controller.py:466] train | step:  36200 | steps/sec:    0.9 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.47030425,
     'losses/train_total_loss': 0.47030425}
I0916 11:00:12.052089 139836075194176 controller.py:466] train | step:  36300 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.8680995e-05,
     'losses/train_semantic_loss': 0.4652404,
     'losses/train_total_loss': 0.4652404}
I0916 11:02:03.297346 139836075194176 controller.py:466] train | step:  36400 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.4479919,
     'losses/train_total_loss': 0.4479919}
I0916 11:03:54.784203 139836075194176 controller.py:466] train | step:  36500 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.581837e-05,
     'losses/train_semantic_loss': 0.4551056,
     'losses/train_total_loss': 0.4551056}
I0916 11:05:48.093667 139836075194176 controller.py:466] train | step:  36600 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.42005703,
     'losses/train_total_loss': 0.42005703}
I0916 11:07:40.471007 139836075194176 controller.py:466] train | step:  36700 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.2939344e-05,
     'losses/train_semantic_loss': 0.4582898,
     'losses/train_total_loss': 0.4582898}
I0916 11:09:33.582915 139836075194176 controller.py:466] train | step:  36800 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.449165,
     'losses/train_total_loss': 0.449165}
I0916 11:11:26.426792 139836075194176 controller.py:466] train | step:  36900 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.0042792e-05,
     'losses/train_semantic_loss': 0.4423102,
     'losses/train_total_loss': 0.4423102}
I0916 11:13:18.360842 139836075194176 controller.py:466] train | step:  37000 | steps/sec:    0.9 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.42992455,
     'losses/train_total_loss': 0.42992455}
I0916 11:13:18.986685 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-37000.
I0916 11:14:58.308779 139836075194176 controller.py:466] train | step:  37100 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.712748e-05,
     'losses/train_semantic_loss': 0.4533223,
     'losses/train_total_loss': 0.4533223}
I0916 11:16:37.637145 139836075194176 controller.py:466] train | step:  37200 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.4432891,
     'losses/train_total_loss': 0.4432891}
I0916 11:18:17.267834 139836075194176 controller.py:466] train | step:  37300 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.4191976e-05,
     'losses/train_semantic_loss': 0.46503016,
     'losses/train_total_loss': 0.46503016}
I0916 11:19:56.736340 139836075194176 controller.py:466] train | step:  37400 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.44257367,
     'losses/train_total_loss': 0.44257367}
I0916 11:21:36.273157 139836075194176 controller.py:466] train | step:  37500 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.123463e-05,
     'losses/train_semantic_loss': 0.44361,
     'losses/train_total_loss': 0.44361}
I0916 11:23:15.748022 139836075194176 controller.py:466] train | step:  37600 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.49073228,
     'losses/train_total_loss': 0.49073228}
I0916 11:24:55.283521 139836075194176 controller.py:466] train | step:  37700 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.8253496e-05,
     'losses/train_semantic_loss': 0.45037296,
     'losses/train_total_loss': 0.45037296}
I0916 11:26:34.966099 139836075194176 controller.py:466] train | step:  37800 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.40434045,
     'losses/train_total_loss': 0.40434045}
I0916 11:28:14.442214 139836075194176 controller.py:466] train | step:  37900 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.52463e-05,
     'losses/train_semantic_loss': 0.4596587,
     'losses/train_total_loss': 0.4596587}
I0916 11:29:53.848482 139836075194176 controller.py:466] train | step:  38000 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.42117518,
     'losses/train_total_loss': 0.42117518}
I0916 11:29:54.444574 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-38000.
I0916 11:31:33.986176 139836075194176 controller.py:466] train | step:  38100 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.221028e-05,
     'losses/train_semantic_loss': 0.46471244,
     'losses/train_total_loss': 0.46471244}
I0916 11:33:13.317850 139836075194176 controller.py:466] train | step:  38200 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.42932248,
     'losses/train_total_loss': 0.42932248}
I0916 11:34:52.962654 139836075194176 controller.py:466] train | step:  38300 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.914206e-05,
     'losses/train_semantic_loss': 0.45223847,
     'losses/train_total_loss': 0.45223847}
I0916 11:36:32.489231 139836075194176 controller.py:466] train | step:  38400 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.4647664,
     'losses/train_total_loss': 0.4647664}
I0916 11:38:11.876781 139836075194176 controller.py:466] train | step:  38500 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.6037449e-05,
     'losses/train_semantic_loss': 0.47273475,
     'losses/train_total_loss': 0.47273475}
I0916 11:39:51.316722 139836075194176 controller.py:466] train | step:  38600 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.44213584,
     'losses/train_total_loss': 0.44213584}
I0916 11:41:31.005481 139836075194176 controller.py:466] train | step:  38700 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.2891034e-05,
     'losses/train_semantic_loss': 0.41428566,
     'losses/train_total_loss': 0.41428566}
I0916 11:43:10.414420 139836075194176 controller.py:466] train | step:  38800 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.44197854,
     'losses/train_total_loss': 0.44197854}
I0916 11:44:49.906119 139836075194176 controller.py:466] train | step:  38900 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.9695593e-05,
     'losses/train_semantic_loss': 0.4590898,
     'losses/train_total_loss': 0.4590898}
I0916 11:46:29.625431 139836075194176 controller.py:466] train | step:  39000 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.4342955,
     'losses/train_total_loss': 0.4342955}
I0916 11:46:30.223000 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-39000.
I0916 11:48:09.678442 139836075194176 controller.py:466] train | step:  39100 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.644122e-05,
     'losses/train_semantic_loss': 0.46304265,
     'losses/train_total_loss': 0.46304265}
I0916 11:49:49.181794 139836075194176 controller.py:466] train | step:  39200 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.4911645,
     'losses/train_total_loss': 0.4911645}

train | step:  35000 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.47495097,
     'losses/train_total_loss': 0.47495097}
saved checkpoint to results/exp_006/ckpt-35000.
train | step:  35100 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.55601e-05,
     'losses/train_semantic_loss': 0.46520352,
     'losses/train_total_loss': 0.46520352}
train | step:  35200 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.50655127,
     'losses/train_total_loss': 0.50655127}
train | step:  35300 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.2778676e-05,
     'losses/train_semantic_loss': 0.48647344,
     'losses/train_total_loss': 0.48647344}
train | step:  35400 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.44157016,
     'losses/train_total_loss': 0.44157016}
train | step:  35500 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.9985384e-05,
     'losses/train_semantic_loss': 0.4844873,
     'losses/train_total_loss': 0.4844873}
train | step:  35600 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.43954656,
     'losses/train_total_loss': 0.43954656}
train | step:  35700 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.7179644e-05,
     'losses/train_semantic_loss': 0.46072057,
     'losses/train_total_loss': 0.46072057}
train | step:  35800 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.45229858,
     'losses/train_total_loss': 0.45229858}
train | step:  35900 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.436082e-05,
     'losses/train_semantic_loss': 0.46148494,
     'losses/train_total_loss': 0.46148494}
train | step:  36000 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.43095782,
     'losses/train_total_loss': 0.43095782}
saved checkpoint to results/exp_006/ckpt-36000.
 eval | step:  36000 | running complete evaluation...
 eval | step:  36000 | eval time:   47.8 sec | output: 
    {'evaluation/iou/IoU': 0.74796975,
     'losses/eval_semantic_loss': 0.4285659,
     'losses/eval_total_loss': 0.4285659}
train | step:  36000 | training until step 40000...
train | step:  36100 | steps/sec:    0.6 | output: 
    {'learning_rate': 6.152822e-05,
     'losses/train_semantic_loss': 0.46335,
     'losses/train_total_loss': 0.46335}
train | step:  36200 | steps/sec:    0.9 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.47030425,
     'losses/train_total_loss': 0.47030425}
train | step:  36300 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.8680995e-05,
     'losses/train_semantic_loss': 0.4652404,
     'losses/train_total_loss': 0.4652404}
train | step:  36400 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.4479919,
     'losses/train_total_loss': 0.4479919}
train | step:  36500 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.581837e-05,
     'losses/train_semantic_loss': 0.4551056,
     'losses/train_total_loss': 0.4551056}
train | step:  36600 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.42005703,
     'losses/train_total_loss': 0.42005703}
train | step:  36700 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.2939344e-05,
     'losses/train_semantic_loss': 0.4582898,
     'losses/train_total_loss': 0.4582898}
train | step:  36800 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.449165,
     'losses/train_total_loss': 0.449165}
train | step:  36900 | steps/sec:    0.9 | output: 
    {'learning_rate': 5.0042792e-05,
     'losses/train_semantic_loss': 0.4423102,
     'losses/train_total_loss': 0.4423102}
train | step:  37000 | steps/sec:    0.9 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.42992455,
     'losses/train_total_loss': 0.42992455}
saved checkpoint to results/exp_006/ckpt-37000.
train | step:  37100 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.712748e-05,
     'losses/train_semantic_loss': 0.4533223,
     'losses/train_total_loss': 0.4533223}
train | step:  37200 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.4432891,
     'losses/train_total_loss': 0.4432891}
train | step:  37300 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.4191976e-05,
     'losses/train_semantic_loss': 0.46503016,
     'losses/train_total_loss': 0.46503016}
train | step:  37400 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.44257367,
     'losses/train_total_loss': 0.44257367}
train | step:  37500 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.123463e-05,
     'losses/train_semantic_loss': 0.44361,
     'losses/train_total_loss': 0.44361}
train | step:  37600 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.49073228,
     'losses/train_total_loss': 0.49073228}
train | step:  37700 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.8253496e-05,
     'losses/train_semantic_loss': 0.45037296,
     'losses/train_total_loss': 0.45037296}
train | step:  37800 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.40434045,
     'losses/train_total_loss': 0.40434045}
train | step:  37900 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.52463e-05,
     'losses/train_semantic_loss': 0.4596587,
     'losses/train_total_loss': 0.4596587}
train | step:  38000 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.42117518,
     'losses/train_total_loss': 0.42117518}
saved checkpoint to results/exp_006/ckpt-38000.
train | step:  38100 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.221028e-05,
     'losses/train_semantic_loss': 0.46471244,
     'losses/train_total_loss': 0.46471244}
train | step:  38200 | steps/sec:    1.0 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.42932248,
     'losses/train_total_loss': 0.42932248}
train | step:  38300 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.914206e-05,
     'losses/train_semantic_loss': 0.45223847,
     'losses/train_total_loss': 0.45223847}
train | step:  38400 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.4647664,
     'losses/train_total_loss': 0.4647664}
train | step:  38500 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.6037449e-05,
     'losses/train_semantic_loss': 0.47273475,
     'losses/train_total_loss': 0.47273475}
train | step:  38600 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.44213584,
     'losses/train_total_loss': 0.44213584}
train | step:  38700 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.2891034e-05,
     'losses/train_semantic_loss': 0.41428566,
     'losses/train_total_loss': 0.41428566}
train | step:  38800 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.44197854,
     'losses/train_total_loss': 0.44197854}
train | step:  38900 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.9695593e-05,
     'losses/train_semantic_loss': 0.4590898,
     'losses/train_total_loss': 0.4590898}
train | step:  39000 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.4342955,
     'losses/train_total_loss': 0.4342955}
saved checkpoint to results/exp_006/ckpt-39000.
train | step:  39100 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.644122e-05,
     'losses/train_semantic_loss': 0.46304265,
     'losses/train_total_loss': 0.46304265}
train | step:  39200 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.4911645,
     'losses/train_total_loss': 0.4911645}I0916 11:51:28.686171 139836075194176 controller.py:466] train | step:  39300 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.3113057e-05,
     'losses/train_semantic_loss': 0.4652741,
     'losses/train_total_loss': 0.4652741}
I0916 11:53:08.649466 139836075194176 controller.py:466] train | step:  39400 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.44034716,
     'losses/train_total_loss': 0.44034716}
I0916 11:54:48.423219 139836075194176 controller.py:466] train | step:  39500 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.686987e-06,
     'losses/train_semantic_loss': 0.44743416,
     'losses/train_total_loss': 0.44743416}
I0916 11:56:28.154562 139836075194176 controller.py:466] train | step:  39600 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.42306563,
     'losses/train_total_loss': 0.42306563}
I0916 11:58:07.737264 139836075194176 controller.py:466] train | step:  39700 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.116807e-06,
     'losses/train_semantic_loss': 0.4614852,
     'losses/train_total_loss': 0.4614852}
I0916 11:59:47.489850 139836075194176 controller.py:466] train | step:  39800 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.43634877,
     'losses/train_total_loss': 0.43634877}
I0916 12:01:26.959181 139836075194176 controller.py:466] train | step:  39900 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.2757035e-06,
     'losses/train_semantic_loss': 0.4569193,
     'losses/train_total_loss': 0.4569193}
I0916 12:03:06.640205 139836075194176 controller.py:466] train | step:  40000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.44702378,
     'losses/train_total_loss': 0.44702378}
I0916 12:03:07.263149 139836075194176 controller.py:495] saved checkpoint to results/exp_006/ckpt-40000.
I0916 12:03:07.263658 139836075194176 controller.py:282]  eval | step:  40000 | running complete evaluation...
I0916 12:03:55.377255 139836075194176 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0916 12:03:55.381986 139836075194176 controller.py:295]  eval | step:  40000 | eval time:   48.1 sec | output: 
    {'evaluation/iou/IoU': 0.75317657,
     'losses/eval_semantic_loss': 0.40854245,
     'losses/eval_total_loss': 0.40854245}

train | step:  39300 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.3113057e-05,
     'losses/train_semantic_loss': 0.4652741,
     'losses/train_total_loss': 0.4652741}
train | step:  39400 | steps/sec:    1.0 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.44034716,
     'losses/train_total_loss': 0.44034716}
train | step:  39500 | steps/sec:    1.0 | output: 
    {'learning_rate': 9.686987e-06,
     'losses/train_semantic_loss': 0.44743416,
     'losses/train_total_loss': 0.44743416}
train | step:  39600 | steps/sec:    1.0 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.42306563,
     'losses/train_total_loss': 0.42306563}
train | step:  39700 | steps/sec:    1.0 | output: 
    {'learning_rate': 6.116807e-06,
     'losses/train_semantic_loss': 0.4614852,
     'losses/train_total_loss': 0.4614852}
train | step:  39800 | steps/sec:    1.0 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.43634877,
     'losses/train_total_loss': 0.43634877}
train | step:  39900 | steps/sec:    1.0 | output: 
    {'learning_rate': 2.2757035e-06,
     'losses/train_semantic_loss': 0.4569193,
     'losses/train_total_loss': 0.4569193}
train | step:  40000 | steps/sec:    1.0 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.44702378,
     'losses/train_total_loss': 0.44702378}
saved checkpoint to results/exp_006/ckpt-40000.
 eval | step:  40000 | running complete evaluation...
 eval | step:  40000 | eval time:   48.1 sec | output: 
    {'evaluation/iou/IoU': 0.75317657,
     'losses/eval_semantic_loss': 0.40854245,
     'losses/eval_total_loss': 0.40854245}
