I0917 01:55:09.751364 140221887547200 train.py:65] Reading the config file.
I0917 01:55:09.756730 140221887547200 train.py:69] Starting the experiment.
2022-09-17 01:55:09.757788: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-17 01:55:11.049866: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0917 01:55:11.054181 140221887547200 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0917 01:55:11.220665 140221887547200 deeplab.py:57] Synchronized Batchnorm is used.
I0917 01:55:11.221721 140221887547200 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0917 01:55:11.322260 140221887547200 deeplab.py:96] Setting pooling size to (65, 65)
I0917 01:55:11.322380 140221887547200 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0917 01:55:14.257159 140221887547200 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0917 01:55:14.283960 140221887547200 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0917 01:55:14.295785 140221887547200 controller.py:399] initialized model.
I0917 01:55:15.008883 140221887547200 api.py:447] Eval with scales ListWrapper([1.0])
I0917 01:55:15.795992 140221887547200 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0917 01:55:15.814104 140221887547200 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0917 01:55:18.769775 140221887547200 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0917 01:55:19.149749 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-0.
I0917 01:55:19.150341 140221887547200 controller.py:241] train | step:      0 | training until step 4000...
2022-09-17 01:55:44.751431: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:380] Filling up shuffle buffer (this may take a while): 716 of 1000
2022-09-17 01:55:49.358540: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:405] Shuffle buffer filled.
2022-09-17 01:55:55.772877: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0917 01:57:32.360129 140221887547200 controller.py:466] train | step:    100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.1216837,
     'losses/train_total_loss': 1.1216837}
I0917 01:59:04.277161 140221887547200 controller.py:466] train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 1.0322767,
     'losses/train_total_loss': 1.0322767}
I0917 02:00:36.283525 140221887547200 controller.py:466] train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.97557986,
     'losses/train_total_loss': 0.97557986}
I0917 02:02:07.637733 140221887547200 controller.py:466] train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.9733137,
     'losses/train_total_loss': 0.9733137}
I0917 02:03:39.255459 140221887547200 controller.py:466] train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.9285469,
     'losses/train_total_loss': 0.9285469}
I0917 02:05:11.203495 140221887547200 controller.py:466] train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.9171649,
     'losses/train_total_loss': 0.9171649}
I0917 02:06:42.049887 140221887547200 controller.py:466] train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.9336788,
     'losses/train_total_loss': 0.9336788}
I0917 02:08:13.568425 140221887547200 controller.py:466] train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.9000078,
     'losses/train_total_loss': 0.9000078}
I0917 02:09:44.908146 140221887547200 controller.py:466] train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.8636121,
     'losses/train_total_loss': 0.8636121}
I0917 02:11:17.131987 140221887547200 controller.py:466] train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.872513,
     'losses/train_total_loss': 0.872513}
I0917 02:11:17.958483 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-1000.
I0917 02:12:49.936221 140221887547200 controller.py:466] train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.8653492,
     'losses/train_total_loss': 0.8653492}
I0917 02:14:21.139099 140221887547200 controller.py:466] train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.7869224,
     'losses/train_total_loss': 0.7869224}
I0917 02:15:53.302019 140221887547200 controller.py:466] train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.83366966,
     'losses/train_total_loss': 0.83366966}
I0917 02:17:25.048007 140221887547200 controller.py:466] train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.8288942,
     'losses/train_total_loss': 0.8288942}
I0917 02:18:57.271176 140221887547200 controller.py:466] train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.84617287,
     'losses/train_total_loss': 0.84617287}
I0917 02:20:28.841848 140221887547200 controller.py:466] train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.83180696,
     'losses/train_total_loss': 0.83180696}
I0917 02:22:00.511625 140221887547200 controller.py:466] train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.864696,
     'losses/train_total_loss': 0.864696}
I0917 02:23:32.374785 140221887547200 controller.py:466] train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.78044707,
     'losses/train_total_loss': 0.78044707}
I0917 02:25:04.644204 140221887547200 controller.py:466] train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.82165414,
     'losses/train_total_loss': 0.82165414}
I0917 02:26:35.981090 140221887547200 controller.py:466] train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.8126663,
     'losses/train_total_loss': 0.8126663}
I0917 02:26:36.811531 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-2000.
I0917 02:28:08.389420 140221887547200 controller.py:466] train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.8036815,
     'losses/train_total_loss': 0.8036815}
I0917 02:29:39.503448 140221887547200 controller.py:466] train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.81168824,
     'losses/train_total_loss': 0.81168824}
I0917 02:31:11.084108 140221887547200 controller.py:466] train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.8202234,
     'losses/train_total_loss': 0.8202234}
I0917 02:32:42.923718 140221887547200 controller.py:466] train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.82432806,
     'losses/train_total_loss': 0.82432806}
I0917 02:34:14.565148 140221887547200 controller.py:466] train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7973906,
     'losses/train_total_loss': 0.7973906}
I0917 02:35:45.596012 140221887547200 controller.py:466] train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.85233706,
     'losses/train_total_loss': 0.85233706}
I0917 02:37:16.921748 140221887547200 controller.py:466] train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.8022812,
     'losses/train_total_loss': 0.8022812}
I0917 02:38:48.617419 140221887547200 controller.py:466] train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.78372985,
     'losses/train_total_loss': 0.78372985}
I0917 02:40:20.234118 140221887547200 controller.py:466] train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.81309557,
     'losses/train_total_loss': 0.81309557}
I0917 02:41:52.030222 140221887547200 controller.py:466] train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7698963,
     'losses/train_total_loss': 0.7698963}
I0917 02:41:53.081258 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-3000.
I0917 02:43:24.805648 140221887547200 controller.py:466] train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.7915674,
     'losses/train_total_loss': 0.7915674}
I0917 02:44:56.642914 140221887547200 controller.py:466] train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.7578997,
     'losses/train_total_loss': 0.7578997}
I0917 02:46:28.174196 140221887547200 controller.py:466] train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.763623,
     'losses/train_total_loss': 0.763623}
I0917 02:48:00.092464 140221887547200 controller.py:466] train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.7535033,
     'losses/train_total_loss': 0.7535033}
I0917 02:49:32.202390 140221887547200 controller.py:466] train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.7549045,
     'losses/train_total_loss': 0.7549045}
I0917 02:51:03.979665 140221887547200 controller.py:466] train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.7384598,
     'losses/train_total_loss': 0.7384598}
I0917 02:52:35.640407 140221887547200 controller.py:466] train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.7256787,
     'losses/train_total_loss': 0.7256787}
I0917 02:54:07.153913 140221887547200 controller.py:466] train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.7595305,
     'losses/train_total_loss': 0.7595305}
I0917 02:55:38.504248 140221887547200 controller.py:466] train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.7658336,
     'losses/train_total_loss': 0.7658336}
I0917 02:57:10.226885 140221887547200 controller.py:466] train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.736169,
     'losses/train_total_loss': 0.736169}
I0917 02:57:11.082260 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-4000.
I0917 02:57:11.083162 140221887547200 controller.py:282]  eval | step:   4000 | running complete evaluation...
I0917 02:57:11.466503 140221887547200 api.py:447] Eval with scales ListWrapper([1.0])
I0917 02:57:11.494604 140221887547200 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0917 02:57:11.518992 140221887547200 api.py:447] Eval scale 1.0; setting pooling size to [65, 65]
I0917 02:57:12.147854 140221887547200 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0917 02:58:12.760317 140221887547200 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 02:58:12.785360 140221887547200 controller.py:295]  eval | step:   4000 | eval time:   61.7 sec | output: 
    {'evaluation/iou/IoU': 0.534544,
     'losses/eval_semantic_loss': 0.87209207,
     'losses/eval_total_loss': 0.87209207}
I0917 02:58:12.789927 140221887547200 controller.py:241] train | step:   4000 | training until step 8000...
I0917 02:59:44.374268 140221887547200 controller.py:466] train | step:   4100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.7622707,
     'losses/train_total_loss': 0.7622707}
I0917 03:01:15.849566 140221887547200 controller.py:466] train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.7888838,
     'losses/train_total_loss': 0.7888838}
I0917 03:02:47.599008 140221887547200 controller.py:466] train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.72598493,
     'losses/train_total_loss': 0.72598493}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_011/ckpt-0.
train | step:      0 | training until step 4000...
train | step:    100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0009954988,
     'losses/train_semantic_loss': 1.1216837,
     'losses/train_total_loss': 1.1216837}
train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009909956,
     'losses/train_semantic_loss': 1.0322767,
     'losses/train_total_loss': 1.0322767}
train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009864898,
     'losses/train_semantic_loss': 0.97557986,
     'losses/train_total_loss': 0.97557986}
train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009819819,
     'losses/train_semantic_loss': 0.9733137,
     'losses/train_total_loss': 0.9733137}
train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009774717,
     'losses/train_semantic_loss': 0.9285469,
     'losses/train_total_loss': 0.9285469}
train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009729591,
     'losses/train_semantic_loss': 0.9171649,
     'losses/train_total_loss': 0.9171649}
train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009684442,
     'losses/train_semantic_loss': 0.9336788,
     'losses/train_total_loss': 0.9336788}
train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00096392696,
     'losses/train_semantic_loss': 0.9000078,
     'losses/train_total_loss': 0.9000078}
train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00095940736,
     'losses/train_semantic_loss': 0.8636121,
     'losses/train_total_loss': 0.8636121}
train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009548854,
     'losses/train_semantic_loss': 0.872513,
     'losses/train_total_loss': 0.872513}
saved checkpoint to results/exp_011/ckpt-1000.
train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009503611,
     'losses/train_semantic_loss': 0.8653492,
     'losses/train_total_loss': 0.8653492}
train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009458344,
     'losses/train_semantic_loss': 0.7869224,
     'losses/train_total_loss': 0.7869224}
train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009413052,
     'losses/train_semantic_loss': 0.83366966,
     'losses/train_total_loss': 0.83366966}
train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00093677366,
     'losses/train_semantic_loss': 0.8288942,
     'losses/train_total_loss': 0.8288942}
train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009322397,
     'losses/train_semantic_loss': 0.84617287,
     'losses/train_total_loss': 0.84617287}
train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009277032,
     'losses/train_semantic_loss': 0.83180696,
     'losses/train_total_loss': 0.83180696}
train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00092316436,
     'losses/train_semantic_loss': 0.864696,
     'losses/train_total_loss': 0.864696}
train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009186229,
     'losses/train_semantic_loss': 0.78044707,
     'losses/train_total_loss': 0.78044707}
train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000914079,
     'losses/train_semantic_loss': 0.82165414,
     'losses/train_total_loss': 0.82165414}
train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0009095326,
     'losses/train_semantic_loss': 0.8126663,
     'losses/train_total_loss': 0.8126663}
saved checkpoint to results/exp_011/ckpt-2000.
train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090498367,
     'losses/train_semantic_loss': 0.8036815,
     'losses/train_total_loss': 0.8036815}
train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00090043223,
     'losses/train_semantic_loss': 0.81168824,
     'losses/train_total_loss': 0.81168824}
train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089587824,
     'losses/train_semantic_loss': 0.8202234,
     'losses/train_total_loss': 0.8202234}
train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00089132163,
     'losses/train_semantic_loss': 0.82432806,
     'losses/train_total_loss': 0.82432806}
train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088676234,
     'losses/train_semantic_loss': 0.7973906,
     'losses/train_total_loss': 0.7973906}
train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00088220055,
     'losses/train_semantic_loss': 0.85233706,
     'losses/train_total_loss': 0.85233706}
train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00087763614,
     'losses/train_semantic_loss': 0.8022812,
     'losses/train_total_loss': 0.8022812}
train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008730691,
     'losses/train_semantic_loss': 0.78372985,
     'losses/train_total_loss': 0.78372985}
train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008684994,
     'losses/train_semantic_loss': 0.81309557,
     'losses/train_total_loss': 0.81309557}
train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000863927,
     'losses/train_semantic_loss': 0.7698963,
     'losses/train_total_loss': 0.7698963}
saved checkpoint to results/exp_011/ckpt-3000.
train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085935195,
     'losses/train_semantic_loss': 0.7915674,
     'losses/train_total_loss': 0.7915674}
train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00085477415,
     'losses/train_semantic_loss': 0.7578997,
     'losses/train_total_loss': 0.7578997}
train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008501936,
     'losses/train_semantic_loss': 0.763623,
     'losses/train_total_loss': 0.763623}
train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084561034,
     'losses/train_semantic_loss': 0.7535033,
     'losses/train_total_loss': 0.7535033}
train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00084102433,
     'losses/train_semantic_loss': 0.7549045,
     'losses/train_total_loss': 0.7549045}
train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00083643553,
     'losses/train_semantic_loss': 0.7384598,
     'losses/train_total_loss': 0.7384598}
train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008318439,
     'losses/train_semantic_loss': 0.7256787,
     'losses/train_total_loss': 0.7256787}
train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00082724955,
     'losses/train_semantic_loss': 0.7595305,
     'losses/train_total_loss': 0.7595305}
train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008226523,
     'losses/train_semantic_loss': 0.7658336,
     'losses/train_total_loss': 0.7658336}
train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00081805215,
     'losses/train_semantic_loss': 0.736169,
     'losses/train_total_loss': 0.736169}
saved checkpoint to results/exp_011/ckpt-4000.
 eval | step:   4000 | running complete evaluation...
 eval | step:   4000 | eval time:   61.7 sec | output: 
    {'evaluation/iou/IoU': 0.534544,
     'losses/eval_semantic_loss': 0.87209207,
     'losses/eval_total_loss': 0.87209207}
train | step:   4000 | training until step 8000...
train | step:   4100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.0008134492,
     'losses/train_semantic_loss': 0.7622707,
     'losses/train_total_loss': 0.7622707}
train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0008088433,
     'losses/train_semantic_loss': 0.7888838,
     'losses/train_total_loss': 0.7888838}
train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00080423447,
     'losses/train_semantic_loss': 0.72598493,
     'losses/train_total_loss': 0.72598493}I0917 03:04:19.365577 140221887547200 controller.py:466] train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.74068964,
     'losses/train_total_loss': 0.74068964}
I0917 03:05:50.236704 140221887547200 controller.py:466] train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.7663255,
     'losses/train_total_loss': 0.7663255}
I0917 03:07:21.739837 140221887547200 controller.py:466] train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.78845334,
     'losses/train_total_loss': 0.78845334}
I0917 03:08:52.678767 140221887547200 controller.py:466] train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.73124045,
     'losses/train_total_loss': 0.73124045}
I0917 03:10:23.959897 140221887547200 controller.py:466] train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.740351,
     'losses/train_total_loss': 0.740351}
I0917 03:11:55.484580 140221887547200 controller.py:466] train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.7393145,
     'losses/train_total_loss': 0.7393145}
I0917 03:13:26.678693 140221887547200 controller.py:466] train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.7506667,
     'losses/train_total_loss': 0.7506667}
I0917 03:13:27.510942 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-5000.
I0917 03:14:59.165419 140221887547200 controller.py:466] train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.7618495,
     'losses/train_total_loss': 0.7618495}
I0917 03:16:31.628380 140221887547200 controller.py:466] train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.7725523,
     'losses/train_total_loss': 0.7725523}
I0917 03:18:04.123100 140221887547200 controller.py:466] train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.7522679,
     'losses/train_total_loss': 0.7522679}
I0917 03:19:35.531336 140221887547200 controller.py:466] train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.7029288,
     'losses/train_total_loss': 0.7029288}
I0917 03:21:06.726382 140221887547200 controller.py:466] train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.7640901,
     'losses/train_total_loss': 0.7640901}
I0917 03:22:38.028603 140221887547200 controller.py:466] train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.7363106,
     'losses/train_total_loss': 0.7363106}
I0917 03:24:09.708911 140221887547200 controller.py:466] train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.73506117,
     'losses/train_total_loss': 0.73506117}
I0917 03:25:41.161271 140221887547200 controller.py:466] train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.7432648,
     'losses/train_total_loss': 0.7432648}
I0917 03:27:12.750858 140221887547200 controller.py:466] train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.7191522,
     'losses/train_total_loss': 0.7191522}
I0917 03:28:45.014441 140221887547200 controller.py:466] train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.7660223,
     'losses/train_total_loss': 0.7660223}
I0917 03:28:45.891174 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-6000.
I0917 03:30:17.741330 140221887547200 controller.py:466] train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.69268256,
     'losses/train_total_loss': 0.69268256}
I0917 03:31:49.289740 140221887547200 controller.py:466] train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.73025787,
     'losses/train_total_loss': 0.73025787}
I0917 03:33:20.792699 140221887547200 controller.py:466] train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.73182577,
     'losses/train_total_loss': 0.73182577}
I0917 03:34:52.709852 140221887547200 controller.py:466] train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.7144584,
     'losses/train_total_loss': 0.7144584}
I0917 03:36:24.485117 140221887547200 controller.py:466] train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.71131295,
     'losses/train_total_loss': 0.71131295}
I0917 03:37:55.842607 140221887547200 controller.py:466] train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.7008533,
     'losses/train_total_loss': 0.7008533}
I0917 03:39:27.043698 140221887547200 controller.py:466] train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6726155,
     'losses/train_total_loss': 0.6726155}
I0917 03:40:59.143082 140221887547200 controller.py:466] train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.7526261,
     'losses/train_total_loss': 0.7526261}
I0917 03:42:31.067929 140221887547200 controller.py:466] train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.7143591,
     'losses/train_total_loss': 0.7143591}
I0917 03:44:02.678894 140221887547200 controller.py:466] train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.71861404,
     'losses/train_total_loss': 0.71861404}
I0917 03:44:03.512453 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-7000.
I0917 03:45:35.448183 140221887547200 controller.py:466] train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.7076335,
     'losses/train_total_loss': 0.7076335}
I0917 03:47:07.034403 140221887547200 controller.py:466] train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.6913438,
     'losses/train_total_loss': 0.6913438}
I0917 03:48:39.054033 140221887547200 controller.py:466] train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.68563384,
     'losses/train_total_loss': 0.68563384}
I0917 03:50:10.745715 140221887547200 controller.py:466] train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.7567569,
     'losses/train_total_loss': 0.7567569}
I0917 03:51:42.531171 140221887547200 controller.py:466] train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.70068365,
     'losses/train_total_loss': 0.70068365}
I0917 03:53:14.352070 140221887547200 controller.py:466] train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.6837125,
     'losses/train_total_loss': 0.6837125}
I0917 03:54:45.679055 140221887547200 controller.py:466] train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.7275566,
     'losses/train_total_loss': 0.7275566}
I0917 03:56:17.540427 140221887547200 controller.py:466] train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.68760103,
     'losses/train_total_loss': 0.68760103}
I0917 03:57:48.987501 140221887547200 controller.py:466] train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.6738384,
     'losses/train_total_loss': 0.6738384}
I0917 03:59:20.570931 140221887547200 controller.py:466] train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.68621504,
     'losses/train_total_loss': 0.68621504}
I0917 03:59:21.356496 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-8000.
I0917 03:59:21.357534 140221887547200 controller.py:282]  eval | step:   8000 | running complete evaluation...
I0917 04:00:22.583377 140221887547200 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 04:00:22.588205 140221887547200 controller.py:295]  eval | step:   8000 | eval time:   61.2 sec | output: 
    {'evaluation/iou/IoU': 0.52175045,
     'losses/eval_semantic_loss': 0.8995806,
     'losses/eval_total_loss': 0.8995806}
I0917 04:00:22.594434 140221887547200 controller.py:241] train | step:   8000 | training until step 12000...
I0917 04:01:54.468650 140221887547200 controller.py:466] train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.7114858,
     'losses/train_total_loss': 0.7114858}
I0917 04:03:25.940157 140221887547200 controller.py:466] train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.6834682,
     'losses/train_total_loss': 0.6834682}
I0917 04:04:58.278277 140221887547200 controller.py:466] train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.7169075,
     'losses/train_total_loss': 0.7169075}
I0917 04:06:30.476007 140221887547200 controller.py:466] train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.6603645,
     'losses/train_total_loss': 0.6603645}
I0917 04:08:02.486810 140221887547200 controller.py:466] train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.6830113,
     'losses/train_total_loss': 0.6830113}
I0917 04:09:34.352424 140221887547200 controller.py:466] train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.69731575,
     'losses/train_total_loss': 0.69731575}
I0917 04:11:06.788027 140221887547200 controller.py:466] train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.6886103,
     'losses/train_total_loss': 0.6886103}

train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079962274,
     'losses/train_semantic_loss': 0.74068964,
     'losses/train_total_loss': 0.74068964}
train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00079500803,
     'losses/train_semantic_loss': 0.7663255,
     'losses/train_total_loss': 0.7663255}
train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007903904,
     'losses/train_semantic_loss': 0.78845334,
     'losses/train_total_loss': 0.78845334}
train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007857697,
     'losses/train_semantic_loss': 0.73124045,
     'losses/train_total_loss': 0.73124045}
train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00078114605,
     'losses/train_semantic_loss': 0.740351,
     'losses/train_total_loss': 0.740351}
train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007765194,
     'losses/train_semantic_loss': 0.7393145,
     'losses/train_total_loss': 0.7393145}
train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00077188946,
     'losses/train_semantic_loss': 0.7506667,
     'losses/train_total_loss': 0.7506667}
saved checkpoint to results/exp_011/ckpt-5000.
train | step:   5100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076725666,
     'losses/train_semantic_loss': 0.7618495,
     'losses/train_total_loss': 0.7618495}
train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00076262065,
     'losses/train_semantic_loss': 0.7725523,
     'losses/train_total_loss': 0.7725523}
train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007579815,
     'losses/train_semantic_loss': 0.7522679,
     'losses/train_total_loss': 0.7522679}
train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00075333926,
     'losses/train_semantic_loss': 0.7029288,
     'losses/train_total_loss': 0.7029288}
train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007486938,
     'losses/train_semantic_loss': 0.7640901,
     'losses/train_total_loss': 0.7640901}
train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00074404513,
     'losses/train_semantic_loss': 0.7363106,
     'losses/train_total_loss': 0.7363106}
train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073939323,
     'losses/train_semantic_loss': 0.73506117,
     'losses/train_total_loss': 0.73506117}
train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00073473813,
     'losses/train_semantic_loss': 0.7432648,
     'losses/train_total_loss': 0.7432648}
train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007300796,
     'losses/train_semantic_loss': 0.7191522,
     'losses/train_total_loss': 0.7191522}
train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00072541786,
     'losses/train_semantic_loss': 0.7660223,
     'losses/train_total_loss': 0.7660223}
saved checkpoint to results/exp_011/ckpt-6000.
train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007207528,
     'losses/train_semantic_loss': 0.69268256,
     'losses/train_total_loss': 0.69268256}
train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00071608444,
     'losses/train_semantic_loss': 0.73025787,
     'losses/train_total_loss': 0.73025787}
train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007114125,
     'losses/train_semantic_loss': 0.73182577,
     'losses/train_total_loss': 0.73182577}
train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0007067374,
     'losses/train_semantic_loss': 0.7144584,
     'losses/train_total_loss': 0.7144584}
train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00070205866,
     'losses/train_semantic_loss': 0.71131295,
     'losses/train_total_loss': 0.71131295}
train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00069737644,
     'losses/train_semantic_loss': 0.7008533,
     'losses/train_total_loss': 0.7008533}
train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006926909,
     'losses/train_semantic_loss': 0.6726155,
     'losses/train_total_loss': 0.6726155}
train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00068800175,
     'losses/train_semantic_loss': 0.7526261,
     'losses/train_total_loss': 0.7526261}
train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000683309,
     'losses/train_semantic_loss': 0.7143591,
     'losses/train_total_loss': 0.7143591}
train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067861273,
     'losses/train_semantic_loss': 0.71861404,
     'losses/train_total_loss': 0.71861404}
saved checkpoint to results/exp_011/ckpt-7000.
train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00067391293,
     'losses/train_semantic_loss': 0.7076335,
     'losses/train_total_loss': 0.7076335}
train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00066920934,
     'losses/train_semantic_loss': 0.6913438,
     'losses/train_total_loss': 0.6913438}
train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006645021,
     'losses/train_semantic_loss': 0.68563384,
     'losses/train_total_loss': 0.68563384}
train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006597912,
     'losses/train_semantic_loss': 0.7567569,
     'losses/train_total_loss': 0.7567569}
train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006550765,
     'losses/train_semantic_loss': 0.70068365,
     'losses/train_total_loss': 0.70068365}
train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006503581,
     'losses/train_semantic_loss': 0.6837125,
     'losses/train_total_loss': 0.6837125}
train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006456358,
     'losses/train_semantic_loss': 0.7275566,
     'losses/train_total_loss': 0.7275566}
train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00064090977,
     'losses/train_semantic_loss': 0.68760103,
     'losses/train_total_loss': 0.68760103}
train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00063617976,
     'losses/train_semantic_loss': 0.6738384,
     'losses/train_total_loss': 0.6738384}
train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006314459,
     'losses/train_semantic_loss': 0.68621504,
     'losses/train_total_loss': 0.68621504}
saved checkpoint to results/exp_011/ckpt-8000.
 eval | step:   8000 | running complete evaluation...
 eval | step:   8000 | eval time:   61.2 sec | output: 
    {'evaluation/iou/IoU': 0.52175045,
     'losses/eval_semantic_loss': 0.8995806,
     'losses/eval_total_loss': 0.8995806}
train | step:   8000 | training until step 12000...
train | step:   8100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00062670815,
     'losses/train_semantic_loss': 0.7114858,
     'losses/train_total_loss': 0.7114858}
train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00062196626,
     'losses/train_semantic_loss': 0.6834682,
     'losses/train_total_loss': 0.6834682}
train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006172204,
     'losses/train_semantic_loss': 0.7169075,
     'losses/train_total_loss': 0.7169075}
train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006124706,
     'losses/train_semantic_loss': 0.6603645,
     'losses/train_total_loss': 0.6603645}
train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006077166,
     'losses/train_semantic_loss': 0.6830113,
     'losses/train_total_loss': 0.6830113}
train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0006029585,
     'losses/train_semantic_loss': 0.69731575,
     'losses/train_total_loss': 0.69731575}
train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005981962,
     'losses/train_semantic_loss': 0.6886103,
     'losses/train_total_loss': 0.6886103}I0917 04:12:38.735646 140221887547200 controller.py:466] train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.6697151,
     'losses/train_total_loss': 0.6697151}
I0917 04:14:10.482388 140221887547200 controller.py:466] train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.6587704,
     'losses/train_total_loss': 0.6587704}
I0917 04:15:42.385685 140221887547200 controller.py:466] train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.6689426,
     'losses/train_total_loss': 0.6689426}
I0917 04:15:43.002393 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-9000.
I0917 04:17:14.540569 140221887547200 controller.py:466] train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.67559767,
     'losses/train_total_loss': 0.67559767}
I0917 04:18:46.267755 140221887547200 controller.py:466] train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.6408166,
     'losses/train_total_loss': 0.6408166}
I0917 04:20:18.059835 140221887547200 controller.py:466] train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.6734335,
     'losses/train_total_loss': 0.6734335}
I0917 04:21:50.101368 140221887547200 controller.py:466] train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.6288307,
     'losses/train_total_loss': 0.6288307}
I0917 04:23:21.957333 140221887547200 controller.py:466] train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.65274537,
     'losses/train_total_loss': 0.65274537}
I0917 04:24:53.676186 140221887547200 controller.py:466] train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.6661559,
     'losses/train_total_loss': 0.6661559}
I0917 04:26:25.243396 140221887547200 controller.py:466] train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.71857584,
     'losses/train_total_loss': 0.71857584}
I0917 04:27:57.120003 140221887547200 controller.py:466] train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.7071223,
     'losses/train_total_loss': 0.7071223}
I0917 04:29:29.124101 140221887547200 controller.py:466] train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.6461214,
     'losses/train_total_loss': 0.6461214}
I0917 04:31:00.853226 140221887547200 controller.py:466] train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.66467357,
     'losses/train_total_loss': 0.66467357}
I0917 04:31:01.470572 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-10000.
I0917 04:32:33.079040 140221887547200 controller.py:466] train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.70986366,
     'losses/train_total_loss': 0.70986366}
I0917 04:34:05.091562 140221887547200 controller.py:466] train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.6420577,
     'losses/train_total_loss': 0.6420577}
I0917 04:35:37.316807 140221887547200 controller.py:466] train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.70567435,
     'losses/train_total_loss': 0.70567435}
I0917 04:37:09.008033 140221887547200 controller.py:466] train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.6948319,
     'losses/train_total_loss': 0.6948319}
I0917 04:38:40.771463 140221887547200 controller.py:466] train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.68429124,
     'losses/train_total_loss': 0.68429124}
I0917 04:40:12.804226 140221887547200 controller.py:466] train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.667766,
     'losses/train_total_loss': 0.667766}
I0917 04:41:44.650726 140221887547200 controller.py:466] train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.66774803,
     'losses/train_total_loss': 0.66774803}
I0917 04:43:16.479919 140221887547200 controller.py:466] train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.6490352,
     'losses/train_total_loss': 0.6490352}
I0917 04:44:48.176580 140221887547200 controller.py:466] train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.6591879,
     'losses/train_total_loss': 0.6591879}
I0917 04:46:20.005539 140221887547200 controller.py:466] train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.6786523,
     'losses/train_total_loss': 0.6786523}
I0917 04:46:20.608642 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-11000.
I0917 04:47:51.876707 140221887547200 controller.py:466] train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.6140437,
     'losses/train_total_loss': 0.6140437}
I0917 04:49:23.954942 140221887547200 controller.py:466] train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.6763786,
     'losses/train_total_loss': 0.6763786}
I0917 04:50:56.058694 140221887547200 controller.py:466] train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.6473008,
     'losses/train_total_loss': 0.6473008}
I0917 04:52:27.688883 140221887547200 controller.py:466] train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.6516573,
     'losses/train_total_loss': 0.6516573}
I0917 04:53:59.708482 140221887547200 controller.py:466] train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.68074346,
     'losses/train_total_loss': 0.68074346}
I0917 04:55:31.558842 140221887547200 controller.py:466] train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.6316148,
     'losses/train_total_loss': 0.6316148}
I0917 04:57:03.321409 140221887547200 controller.py:466] train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.6493939,
     'losses/train_total_loss': 0.6493939}
I0917 04:58:35.441811 140221887547200 controller.py:466] train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.67294717,
     'losses/train_total_loss': 0.67294717}
I0917 05:00:07.372165 140221887547200 controller.py:466] train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.67517614,
     'losses/train_total_loss': 0.67517614}
I0917 05:01:39.273878 140221887547200 controller.py:466] train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.64985967,
     'losses/train_total_loss': 0.64985967}
I0917 05:01:40.341551 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-12000.
I0917 05:01:40.342044 140221887547200 controller.py:282]  eval | step:  12000 | running complete evaluation...
I0917 05:02:45.947304 140221887547200 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 05:02:45.975993 140221887547200 controller.py:295]  eval | step:  12000 | eval time:   65.6 sec | output: 
    {'evaluation/iou/IoU': 0.7034148,
     'losses/eval_semantic_loss': 0.58329546,
     'losses/eval_total_loss': 0.58329546}
I0917 05:02:45.982209 140221887547200 controller.py:241] train | step:  12000 | training until step 16000...
I0917 05:04:17.287977 140221887547200 controller.py:466] train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.6668525,
     'losses/train_total_loss': 0.6668525}
I0917 05:05:49.427628 140221887547200 controller.py:466] train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.676532,
     'losses/train_total_loss': 0.676532}
I0917 05:07:21.586786 140221887547200 controller.py:466] train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.6697993,
     'losses/train_total_loss': 0.6697993}
I0917 05:08:53.624204 140221887547200 controller.py:466] train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.6707788,
     'losses/train_total_loss': 0.6707788}
I0917 05:10:25.952148 140221887547200 controller.py:466] train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.66994596,
     'losses/train_total_loss': 0.66994596}
I0917 05:11:58.277008 140221887547200 controller.py:466] train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.65462387,
     'losses/train_total_loss': 0.65462387}
I0917 05:13:30.175266 140221887547200 controller.py:466] train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.63487595,
     'losses/train_total_loss': 0.63487595}
I0917 05:15:02.245477 140221887547200 controller.py:466] train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.6089361,
     'losses/train_total_loss': 0.6089361}
I0917 05:16:34.075254 140221887547200 controller.py:466] train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.6361854,
     'losses/train_total_loss': 0.6361854}
I0917 05:18:05.868621 140221887547200 controller.py:466] train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5965867,
     'losses/train_total_loss': 0.5965867}
I0917 05:18:06.482143 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-13000.
I0917 05:19:38.353719 140221887547200 controller.py:466] train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.6635516,
     'losses/train_total_loss': 0.6635516}

train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00059342966,
     'losses/train_semantic_loss': 0.6697151,
     'losses/train_total_loss': 0.6697151}
train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005886589,
     'losses/train_semantic_loss': 0.6587704,
     'losses/train_total_loss': 0.6587704}
train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005838838,
     'losses/train_semantic_loss': 0.6689426,
     'losses/train_total_loss': 0.6689426}
saved checkpoint to results/exp_011/ckpt-9000.
train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005791044,
     'losses/train_semantic_loss': 0.67559767,
     'losses/train_total_loss': 0.67559767}
train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00057432055,
     'losses/train_semantic_loss': 0.6408166,
     'losses/train_total_loss': 0.6408166}
train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00056953233,
     'losses/train_semantic_loss': 0.6734335,
     'losses/train_total_loss': 0.6734335}
train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005647397,
     'losses/train_semantic_loss': 0.6288307,
     'losses/train_total_loss': 0.6288307}
train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005599424,
     'losses/train_semantic_loss': 0.65274537,
     'losses/train_total_loss': 0.65274537}
train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055514066,
     'losses/train_semantic_loss': 0.6661559,
     'losses/train_total_loss': 0.6661559}
train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00055033417,
     'losses/train_semantic_loss': 0.71857584,
     'losses/train_total_loss': 0.71857584}
train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00054552313,
     'losses/train_semantic_loss': 0.7071223,
     'losses/train_total_loss': 0.7071223}
train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005407073,
     'losses/train_semantic_loss': 0.6461214,
     'losses/train_total_loss': 0.6461214}
train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005358868,
     'losses/train_semantic_loss': 0.66467357,
     'losses/train_total_loss': 0.66467357}
saved checkpoint to results/exp_011/ckpt-10000.
train | step:  10100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005310614,
     'losses/train_semantic_loss': 0.70986366,
     'losses/train_total_loss': 0.70986366}
train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005262311,
     'losses/train_semantic_loss': 0.6420577,
     'losses/train_total_loss': 0.6420577}
train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005213959,
     'losses/train_semantic_loss': 0.70567435,
     'losses/train_total_loss': 0.70567435}
train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005165557,
     'losses/train_semantic_loss': 0.6948319,
     'losses/train_total_loss': 0.6948319}
train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005117104,
     'losses/train_semantic_loss': 0.68429124,
     'losses/train_total_loss': 0.68429124}
train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005068601,
     'losses/train_semantic_loss': 0.667766,
     'losses/train_total_loss': 0.667766}
train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0005020046,
     'losses/train_semantic_loss': 0.66774803,
     'losses/train_total_loss': 0.66774803}
train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049714383,
     'losses/train_semantic_loss': 0.6490352,
     'losses/train_total_loss': 0.6490352}
train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049227785,
     'losses/train_semantic_loss': 0.6591879,
     'losses/train_total_loss': 0.6591879}
train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048740642,
     'losses/train_semantic_loss': 0.6786523,
     'losses/train_total_loss': 0.6786523}
saved checkpoint to results/exp_011/ckpt-11000.
train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004825297,
     'losses/train_semantic_loss': 0.6140437,
     'losses/train_total_loss': 0.6140437}
train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004776474,
     'losses/train_semantic_loss': 0.6763786,
     'losses/train_total_loss': 0.6763786}
train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047275962,
     'losses/train_semantic_loss': 0.6473008,
     'losses/train_total_loss': 0.6473008}
train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046786614,
     'losses/train_semantic_loss': 0.6516573,
     'losses/train_total_loss': 0.6516573}
train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046296703,
     'losses/train_semantic_loss': 0.68074346,
     'losses/train_total_loss': 0.68074346}
train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045806213,
     'losses/train_semantic_loss': 0.6316148,
     'losses/train_total_loss': 0.6316148}
train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004531514,
     'losses/train_semantic_loss': 0.6493939,
     'losses/train_total_loss': 0.6493939}
train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044823476,
     'losses/train_semantic_loss': 0.67294717,
     'losses/train_total_loss': 0.67294717}
train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044331205,
     'losses/train_semantic_loss': 0.67517614,
     'losses/train_total_loss': 0.67517614}
train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043838331,
     'losses/train_semantic_loss': 0.64985967,
     'losses/train_total_loss': 0.64985967}
saved checkpoint to results/exp_011/ckpt-12000.
 eval | step:  12000 | running complete evaluation...
 eval | step:  12000 | eval time:   65.6 sec | output: 
    {'evaluation/iou/IoU': 0.7034148,
     'losses/eval_semantic_loss': 0.58329546,
     'losses/eval_total_loss': 0.58329546}
train | step:  12000 | training until step 16000...
train | step:  12100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00043344835,
     'losses/train_semantic_loss': 0.6668525,
     'losses/train_total_loss': 0.6668525}
train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042850722,
     'losses/train_semantic_loss': 0.676532,
     'losses/train_total_loss': 0.676532}
train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042355974,
     'losses/train_semantic_loss': 0.6697993,
     'losses/train_total_loss': 0.6697993}
train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041860584,
     'losses/train_semantic_loss': 0.6707788,
     'losses/train_total_loss': 0.6707788}
train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041364535,
     'losses/train_semantic_loss': 0.66994596,
     'losses/train_total_loss': 0.66994596}
train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004086783,
     'losses/train_semantic_loss': 0.65462387,
     'losses/train_total_loss': 0.65462387}
train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004037045,
     'losses/train_semantic_loss': 0.63487595,
     'losses/train_total_loss': 0.63487595}
train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039872393,
     'losses/train_semantic_loss': 0.6089361,
     'losses/train_total_loss': 0.6089361}
train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039373638,
     'losses/train_semantic_loss': 0.6361854,
     'losses/train_total_loss': 0.6361854}
train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038874187,
     'losses/train_semantic_loss': 0.5965867,
     'losses/train_total_loss': 0.5965867}
saved checkpoint to results/exp_011/ckpt-13000.
train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038374015,
     'losses/train_semantic_loss': 0.6635516,
     'losses/train_total_loss': 0.6635516}I0917 05:21:09.827041 140221887547200 controller.py:466] train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.60820234,
     'losses/train_total_loss': 0.60820234}
I0917 05:22:41.981464 140221887547200 controller.py:466] train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.6412,
     'losses/train_total_loss': 0.6412}
I0917 05:24:14.039635 140221887547200 controller.py:466] train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.66179377,
     'losses/train_total_loss': 0.66179377}
I0917 05:25:46.244149 140221887547200 controller.py:466] train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.6230777,
     'losses/train_total_loss': 0.6230777}
I0917 05:27:18.107306 140221887547200 controller.py:466] train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.6231614,
     'losses/train_total_loss': 0.6231614}
I0917 05:28:50.390572 140221887547200 controller.py:466] train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.63225627,
     'losses/train_total_loss': 0.63225627}
I0917 05:30:22.154945 140221887547200 controller.py:466] train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.64045286,
     'losses/train_total_loss': 0.64045286}
I0917 05:31:53.898855 140221887547200 controller.py:466] train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.61528957,
     'losses/train_total_loss': 0.61528957}
I0917 05:33:24.833780 140221887547200 controller.py:466] train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.64066714,
     'losses/train_total_loss': 0.64066714}
I0917 05:33:25.434433 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-14000.
I0917 05:34:57.618160 140221887547200 controller.py:466] train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.60730207,
     'losses/train_total_loss': 0.60730207}
I0917 05:36:29.475965 140221887547200 controller.py:466] train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.6465819,
     'losses/train_total_loss': 0.6465819}
I0917 05:38:00.924227 140221887547200 controller.py:466] train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.6118426,
     'losses/train_total_loss': 0.6118426}
I0917 05:39:32.691810 140221887547200 controller.py:466] train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.6327886,
     'losses/train_total_loss': 0.6327886}
I0917 05:41:04.746599 140221887547200 controller.py:466] train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.58246416,
     'losses/train_total_loss': 0.58246416}
I0917 05:42:35.988579 140221887547200 controller.py:466] train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.62116057,
     'losses/train_total_loss': 0.62116057}
I0917 05:44:07.783229 140221887547200 controller.py:466] train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.5910915,
     'losses/train_total_loss': 0.5910915}
I0917 05:45:39.359058 140221887547200 controller.py:466] train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.6216314,
     'losses/train_total_loss': 0.6216314}
I0917 05:47:11.348072 140221887547200 controller.py:466] train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.58215845,
     'losses/train_total_loss': 0.58215845}
I0917 05:48:43.298764 140221887547200 controller.py:466] train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.6222438,
     'losses/train_total_loss': 0.6222438}
I0917 05:48:43.920343 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-15000.
I0917 05:50:15.577793 140221887547200 controller.py:466] train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.6205693,
     'losses/train_total_loss': 0.6205693}
I0917 05:51:47.484054 140221887547200 controller.py:466] train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.59080565,
     'losses/train_total_loss': 0.59080565}
I0917 05:53:19.274071 140221887547200 controller.py:466] train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.6115399,
     'losses/train_total_loss': 0.6115399}
I0917 05:54:50.856000 140221887547200 controller.py:466] train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.6165845,
     'losses/train_total_loss': 0.6165845}
I0917 05:56:22.790761 140221887547200 controller.py:466] train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.624194,
     'losses/train_total_loss': 0.624194}
I0917 05:57:54.834548 140221887547200 controller.py:466] train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.5702385,
     'losses/train_total_loss': 0.5702385}
I0917 05:59:27.007934 140221887547200 controller.py:466] train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.59939474,
     'losses/train_total_loss': 0.59939474}
I0917 06:00:58.405546 140221887547200 controller.py:466] train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.6299899,
     'losses/train_total_loss': 0.6299899}
I0917 06:02:30.248842 140221887547200 controller.py:466] train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.60044914,
     'losses/train_total_loss': 0.60044914}
I0917 06:04:02.164895 140221887547200 controller.py:466] train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.653095,
     'losses/train_total_loss': 0.653095}
I0917 06:04:02.756445 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-16000.
I0917 06:04:02.756994 140221887547200 controller.py:282]  eval | step:  16000 | running complete evaluation...
I0917 06:05:07.444419 140221887547200 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 06:05:07.449196 140221887547200 controller.py:295]  eval | step:  16000 | eval time:   64.7 sec | output: 
    {'evaluation/iou/IoU': 0.7089953,
     'losses/eval_semantic_loss': 0.61491644,
     'losses/eval_total_loss': 0.61491644}
I0917 06:05:07.455405 140221887547200 controller.py:241] train | step:  16000 | training until step 20000...
I0917 06:06:38.679445 140221887547200 controller.py:466] train | step:  16100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.5701937,
     'losses/train_total_loss': 0.5701937}
I0917 06:08:09.881800 140221887547200 controller.py:466] train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.68433034,
     'losses/train_total_loss': 0.68433034}
I0917 06:09:41.232783 140221887547200 controller.py:466] train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.6117459,
     'losses/train_total_loss': 0.6117459}
I0917 06:11:12.412682 140221887547200 controller.py:466] train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.61839783,
     'losses/train_total_loss': 0.61839783}
I0917 06:12:43.986341 140221887547200 controller.py:466] train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.6519654,
     'losses/train_total_loss': 0.6519654}
I0917 06:14:15.399858 140221887547200 controller.py:466] train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.6336409,
     'losses/train_total_loss': 0.6336409}
I0917 06:15:46.123903 140221887547200 controller.py:466] train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.60991406,
     'losses/train_total_loss': 0.60991406}
I0917 06:17:17.016428 140221887547200 controller.py:466] train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.6538403,
     'losses/train_total_loss': 0.6538403}
I0917 06:18:48.193476 140221887547200 controller.py:466] train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.6306965,
     'losses/train_total_loss': 0.6306965}
I0917 06:20:19.302676 140221887547200 controller.py:466] train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.65937257,
     'losses/train_total_loss': 0.65937257}
I0917 06:20:19.920713 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-17000.
I0917 06:21:51.285918 140221887547200 controller.py:466] train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.59155476,
     'losses/train_total_loss': 0.59155476}
I0917 06:23:23.119716 140221887547200 controller.py:466] train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.6528228,
     'losses/train_total_loss': 0.6528228}
I0917 06:24:54.794423 140221887547200 controller.py:466] train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.5926569,
     'losses/train_total_loss': 0.5926569}
I0917 06:26:26.375865 140221887547200 controller.py:466] train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.6055323,
     'losses/train_total_loss': 0.6055323}
I0917 06:27:58.261363 140221887547200 controller.py:466] train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.60751694,
     'losses/train_total_loss': 0.60751694}

train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037873114,
     'losses/train_semantic_loss': 0.60820234,
     'losses/train_total_loss': 0.60820234}
train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037371484,
     'losses/train_semantic_loss': 0.6412,
     'losses/train_total_loss': 0.6412}
train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036869102,
     'losses/train_semantic_loss': 0.66179377,
     'losses/train_total_loss': 0.66179377}
train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036365958,
     'losses/train_semantic_loss': 0.6230777,
     'losses/train_total_loss': 0.6230777}
train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003586204,
     'losses/train_semantic_loss': 0.6231614,
     'losses/train_total_loss': 0.6231614}
train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035357333,
     'losses/train_semantic_loss': 0.63225627,
     'losses/train_total_loss': 0.63225627}
train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034851825,
     'losses/train_semantic_loss': 0.64045286,
     'losses/train_total_loss': 0.64045286}
train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000343455,
     'losses/train_semantic_loss': 0.61528957,
     'losses/train_total_loss': 0.61528957}
train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033838348,
     'losses/train_semantic_loss': 0.64066714,
     'losses/train_total_loss': 0.64066714}
saved checkpoint to results/exp_011/ckpt-14000.
train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033330347,
     'losses/train_semantic_loss': 0.60730207,
     'losses/train_total_loss': 0.60730207}
train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003282149,
     'losses/train_semantic_loss': 0.6465819,
     'losses/train_total_loss': 0.6465819}
train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032311748,
     'losses/train_semantic_loss': 0.6118426,
     'losses/train_total_loss': 0.6118426}
train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031801107,
     'losses/train_semantic_loss': 0.6327886,
     'losses/train_total_loss': 0.6327886}
train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031289557,
     'losses/train_semantic_loss': 0.58246416,
     'losses/train_total_loss': 0.58246416}
train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030777077,
     'losses/train_semantic_loss': 0.62116057,
     'losses/train_total_loss': 0.62116057}
train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030263647,
     'losses/train_semantic_loss': 0.5910915,
     'losses/train_total_loss': 0.5910915}
train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002974925,
     'losses/train_semantic_loss': 0.6216314,
     'losses/train_total_loss': 0.6216314}
train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002923386,
     'losses/train_semantic_loss': 0.58215845,
     'losses/train_total_loss': 0.58215845}
train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028717463,
     'losses/train_semantic_loss': 0.6222438,
     'losses/train_total_loss': 0.6222438}
saved checkpoint to results/exp_011/ckpt-15000.
train | step:  15100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028200028,
     'losses/train_semantic_loss': 0.6205693,
     'losses/train_total_loss': 0.6205693}
train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027681538,
     'losses/train_semantic_loss': 0.59080565,
     'losses/train_total_loss': 0.59080565}
train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027161962,
     'losses/train_semantic_loss': 0.6115399,
     'losses/train_total_loss': 0.6115399}
train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002664128,
     'losses/train_semantic_loss': 0.6165845,
     'losses/train_total_loss': 0.6165845}
train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002611947,
     'losses/train_semantic_loss': 0.624194,
     'losses/train_total_loss': 0.624194}
train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025596493,
     'losses/train_semantic_loss': 0.5702385,
     'losses/train_total_loss': 0.5702385}
train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025072324,
     'losses/train_semantic_loss': 0.59939474,
     'losses/train_total_loss': 0.59939474}
train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002454694,
     'losses/train_semantic_loss': 0.6299899,
     'losses/train_total_loss': 0.6299899}
train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024020304,
     'losses/train_semantic_loss': 0.60044914,
     'losses/train_total_loss': 0.60044914}
train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023492378,
     'losses/train_semantic_loss': 0.653095,
     'losses/train_total_loss': 0.653095}
saved checkpoint to results/exp_011/ckpt-16000.
 eval | step:  16000 | running complete evaluation...
 eval | step:  16000 | eval time:   64.7 sec | output: 
    {'evaluation/iou/IoU': 0.7089953,
     'losses/eval_semantic_loss': 0.61491644,
     'losses/eval_total_loss': 0.61491644}
train | step:  16000 | training until step 20000...
train | step:  16100 | steps/sec:    0.6 | output: 
    {'learning_rate': 0.00022963133,
     'losses/train_semantic_loss': 0.5701937,
     'losses/train_total_loss': 0.5701937}
train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022432528,
     'losses/train_semantic_loss': 0.68433034,
     'losses/train_total_loss': 0.68433034}
train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021900526,
     'losses/train_semantic_loss': 0.6117459,
     'losses/train_total_loss': 0.6117459}
train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021367088,
     'losses/train_semantic_loss': 0.61839783,
     'losses/train_total_loss': 0.61839783}
train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002083216,
     'losses/train_semantic_loss': 0.6519654,
     'losses/train_total_loss': 0.6519654}
train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020295706,
     'losses/train_semantic_loss': 0.6336409,
     'losses/train_total_loss': 0.6336409}
train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019757665,
     'losses/train_semantic_loss': 0.60991406,
     'losses/train_total_loss': 0.60991406}
train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019217996,
     'losses/train_semantic_loss': 0.6538403,
     'losses/train_total_loss': 0.6538403}
train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018676628,
     'losses/train_semantic_loss': 0.6306965,
     'losses/train_total_loss': 0.6306965}
train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018133518,
     'losses/train_semantic_loss': 0.65937257,
     'losses/train_total_loss': 0.65937257}
saved checkpoint to results/exp_011/ckpt-17000.
train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017588597,
     'losses/train_semantic_loss': 0.59155476,
     'losses/train_total_loss': 0.59155476}
train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017041792,
     'losses/train_semantic_loss': 0.6528228,
     'losses/train_total_loss': 0.6528228}
train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016493027,
     'losses/train_semantic_loss': 0.5926569,
     'losses/train_total_loss': 0.5926569}
train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015942228,
     'losses/train_semantic_loss': 0.6055323,
     'losses/train_total_loss': 0.6055323}
train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015389308,
     'losses/train_semantic_loss': 0.60751694,
     'losses/train_total_loss': 0.60751694}I0917 06:29:30.216576 140221887547200 controller.py:466] train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.56113046,
     'losses/train_total_loss': 0.56113046}
I0917 06:31:01.883382 140221887547200 controller.py:466] train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.61308557,
     'losses/train_total_loss': 0.61308557}
I0917 06:32:33.588385 140221887547200 controller.py:466] train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.6088644,
     'losses/train_total_loss': 0.6088644}
I0917 06:34:05.405120 140221887547200 controller.py:466] train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.58207583,
     'losses/train_total_loss': 0.58207583}
I0917 06:35:37.255813 140221887547200 controller.py:466] train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.57912993,
     'losses/train_total_loss': 0.57912993}
I0917 06:35:37.862200 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-18000.
I0917 06:37:09.891873 140221887547200 controller.py:466] train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.5939858,
     'losses/train_total_loss': 0.5939858}
I0917 06:38:41.601049 140221887547200 controller.py:466] train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.6395511,
     'losses/train_total_loss': 0.6395511}
I0917 06:40:13.036372 140221887547200 controller.py:466] train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.60227007,
     'losses/train_total_loss': 0.60227007}
I0917 06:41:44.824147 140221887547200 controller.py:466] train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.5884905,
     'losses/train_total_loss': 0.5884905}
I0917 06:43:16.202257 140221887547200 controller.py:466] train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.6173513,
     'losses/train_total_loss': 0.6173513}
I0917 06:44:48.080391 140221887547200 controller.py:466] train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.5745687,
     'losses/train_total_loss': 0.5745687}
I0917 06:46:19.957427 140221887547200 controller.py:466] train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.5801741,
     'losses/train_total_loss': 0.5801741}
I0917 06:47:51.789220 140221887547200 controller.py:466] train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.5932621,
     'losses/train_total_loss': 0.5932621}
I0917 06:49:23.768758 140221887547200 controller.py:466] train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.62041736,
     'losses/train_total_loss': 0.62041736}
I0917 06:50:55.681215 140221887547200 controller.py:466] train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.5991164,
     'losses/train_total_loss': 0.5991164}
I0917 06:50:56.342226 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-19000.
I0917 06:52:28.041724 140221887547200 controller.py:466] train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.64326644,
     'losses/train_total_loss': 0.64326644}
I0917 06:54:00.005180 140221887547200 controller.py:466] train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.57346475,
     'losses/train_total_loss': 0.57346475}
I0917 06:55:31.970274 140221887547200 controller.py:466] train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.6003524,
     'losses/train_total_loss': 0.6003524}
I0917 06:57:03.747572 140221887547200 controller.py:466] train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.55701107,
     'losses/train_total_loss': 0.55701107}
I0917 06:58:35.547587 140221887547200 controller.py:466] train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.5979945,
     'losses/train_total_loss': 0.5979945}
I0917 07:00:07.334588 140221887547200 controller.py:466] train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.58208555,
     'losses/train_total_loss': 0.58208555}
I0917 07:01:39.569936 140221887547200 controller.py:466] train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.56999403,
     'losses/train_total_loss': 0.56999403}
I0917 07:03:11.294778 140221887547200 controller.py:466] train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.61973256,
     'losses/train_total_loss': 0.61973256}
I0917 07:04:42.557448 140221887547200 controller.py:466] train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.5870712,
     'losses/train_total_loss': 0.5870712}
I0917 07:06:13.795549 140221887547200 controller.py:466] train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5984667,
     'losses/train_total_loss': 0.5984667}
I0917 07:06:14.437657 140221887547200 controller.py:495] saved checkpoint to results/exp_011/ckpt-20000.
I0917 07:06:14.438513 140221887547200 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0917 07:07:16.118148 140221887547200 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0917 07:07:16.122822 140221887547200 controller.py:295]  eval | step:  20000 | eval time:   61.7 sec | output: 
    {'evaluation/iou/IoU': 0.7427465,
     'losses/eval_semantic_loss': 0.50682306,
     'losses/eval_total_loss': 0.50682306}

train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014834169,
     'losses/train_semantic_loss': 0.56113046,
     'losses/train_total_loss': 0.56113046}
train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001427671,
     'losses/train_semantic_loss': 0.61308557,
     'losses/train_total_loss': 0.61308557}
train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013716822,
     'losses/train_semantic_loss': 0.6088644,
     'losses/train_total_loss': 0.6088644}
train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013154384,
     'losses/train_semantic_loss': 0.58207583,
     'losses/train_total_loss': 0.58207583}
train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001258926,
     'losses/train_semantic_loss': 0.57912993,
     'losses/train_total_loss': 0.57912993}
saved checkpoint to results/exp_011/ckpt-18000.
train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012021299,
     'losses/train_semantic_loss': 0.5939858,
     'losses/train_total_loss': 0.5939858}
train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114503346,
     'losses/train_semantic_loss': 0.6395511,
     'losses/train_total_loss': 0.6395511}
train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000108761946,
     'losses/train_semantic_loss': 0.60227007,
     'losses/train_total_loss': 0.60227007}
train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010298665,
     'losses/train_semantic_loss': 0.5884905,
     'losses/train_total_loss': 0.5884905}
train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.7175136e-05,
     'losses/train_semantic_loss': 0.6173513,
     'losses/train_total_loss': 0.6173513}
train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.1324684e-05,
     'losses/train_semantic_loss': 0.5745687,
     'losses/train_total_loss': 0.5745687}
train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.5432286e-05,
     'losses/train_semantic_loss': 0.5801741,
     'losses/train_total_loss': 0.5801741}
train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.949435e-05,
     'losses/train_semantic_loss': 0.5932621,
     'losses/train_total_loss': 0.5932621}
train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.3506635e-05,
     'losses/train_semantic_loss': 0.62041736,
     'losses/train_total_loss': 0.62041736}
train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.746418e-05,
     'losses/train_semantic_loss': 0.5991164,
     'losses/train_total_loss': 0.5991164}
saved checkpoint to results/exp_011/ckpt-19000.
train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.136086e-05,
     'losses/train_semantic_loss': 0.64326644,
     'losses/train_total_loss': 0.64326644}
train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.5189215e-05,
     'losses/train_semantic_loss': 0.57346475,
     'losses/train_total_loss': 0.57346475}
train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8939724e-05,
     'losses/train_semantic_loss': 0.6003524,
     'losses/train_total_loss': 0.6003524}
train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2599917e-05,
     'losses/train_semantic_loss': 0.55701107,
     'losses/train_total_loss': 0.55701107}
train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6153113e-05,
     'losses/train_semantic_loss': 0.5979945,
     'losses/train_total_loss': 0.5979945}
train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.957513e-05,
     'losses/train_semantic_loss': 0.58208555,
     'losses/train_total_loss': 0.58208555}
train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.2828734e-05,
     'losses/train_semantic_loss': 0.56999403,
     'losses/train_total_loss': 0.56999403}
train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.5848918e-05,
     'losses/train_semantic_loss': 0.61973256,
     'losses/train_total_loss': 0.61973256}
train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.493227e-06,
     'losses/train_semantic_loss': 0.5870712,
     'losses/train_total_loss': 0.5870712}
train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.5984667,
     'losses/train_total_loss': 0.5984667}
saved checkpoint to results/exp_011/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   61.7 sec | output: 
    {'evaluation/iou/IoU': 0.7427465,
     'losses/eval_semantic_loss': 0.50682306,
     'losses/eval_total_loss': 0.50682306}
