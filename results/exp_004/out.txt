I0914 18:59:58.751976 140208644908864 train.py:65] Reading the config file.
I0914 18:59:58.754234 140208644908864 train.py:69] Starting the experiment.
2022-09-14 18:59:58.754623: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-09-14 18:59:59.145552: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 11416 MB memory:  -> device: 0, name: NVIDIA TITAN Xp, pci bus id: 0000:65:00.0, compute capability: 6.1
I0914 18:59:59.147073 140208644908864 train_lib.py:108] Using strategy <class 'tensorflow.python.distribute.one_device_strategy.OneDeviceStrategy'> with 1 replicas
I0914 18:59:59.270913 140208644908864 deeplab.py:57] Synchronized Batchnorm is used.
I0914 18:59:59.271945 140208644908864 axial_resnet_instances.py:144] Axial-ResNet final config: {'num_blocks': [3, 4, 6, 3], 'backbone_layer_multiplier': 1.0, 'width_multiplier': 1.0, 'stem_width_multiplier': 1.0, 'output_stride': 16, 'classification_mode': True, 'backbone_type': 'resnet', 'use_axial_beyond_stride': 0, 'backbone_use_transformer_beyond_stride': 0, 'extra_decoder_use_transformer_beyond_stride': 32, 'backbone_decoder_num_stacks': 0, 'backbone_decoder_blocks_per_stage': 1, 'extra_decoder_num_stacks': 0, 'extra_decoder_blocks_per_stage': 1, 'max_num_mask_slots': 128, 'num_mask_slots': 128, 'memory_channels': 256, 'base_transformer_expansion': 1.0, 'global_feed_forward_network_channels': 256, 'high_resolution_output_stride': 4, 'activation': 'relu', 'block_group_config': {'attention_bottleneck_expansion': 2, 'drop_path_keep_prob': 1.0, 'drop_path_beyond_stride': 16, 'drop_path_schedule': 'constant', 'positional_encoding_type': None, 'use_global_beyond_stride': 0, 'use_sac_beyond_stride': -1, 'use_squeeze_and_excite': False, 'conv_use_recompute_grad': False, 'axial_use_recompute_grad': True, 'recompute_within_stride': 0, 'transformer_use_recompute_grad': False, 'axial_layer_config': {'query_shape': (129, 129), 'key_expansion': 1, 'value_expansion': 2, 'memory_flange': (32, 32), 'double_global_attention': False, 'num_heads': 8, 'use_query_rpe_similarity': True, 'use_key_rpe_similarity': True, 'use_content_similarity': True, 'retrieve_value_rpe': True, 'retrieve_value_content': True, 'initialization_std_for_query_key_rpe': 1.0, 'initialization_std_for_value_rpe': 1.0, 'self_attention_activation': 'softmax'}, 'dual_path_transformer_layer_config': {'num_heads': 8, 'bottleneck_expansion': 2, 'key_expansion': 1, 'value_expansion': 2, 'feed_forward_network_channels': 2048, 'use_memory_self_attention': True, 'use_pixel2memory_feedback_attention': True, 'transformer_activation': 'softmax'}}, 'bn_layer': functools.partial(<class 'keras.layers.normalization.batch_normalization.SyncBatchNormalization'>, momentum=0.9900000095367432, epsilon=0.0010000000474974513), 'conv_kernel_weight_decay': 0.0}
I0914 18:59:59.372922 140208644908864 deeplab.py:96] Setting pooling size to (33, 33)
I0914 18:59:59.373038 140208644908864 aspp.py:141] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0914 19:00:02.279196 140208644908864 controller.py:393] restoring or initializing model...
WARNING:tensorflow:From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
W0914 19:00:02.297158 140208644908864 deprecation.py:341] From /home/titanas/anaconda3/envs/alex_deeplab/lib/python3.8/site-packages/tensorflow/python/training/tracking/util.py:1343: NameBasedSaverStatus.__init__ (from tensorflow.python.training.tracking.util) is deprecated and will be removed in a future version.
Instructions for updating:
Restoring a name-based tf.train.Saver checkpoint using the object-based restore API. This mode uses global names to match variables, and so is somewhat fragile. It also adds new restore ops to the graph each time it is called when graph building. Prefer re-encoding training checkpoints in the object-based format: run save() on the object-based saver (the same one this message is coming from) and use that checkpoint in the future.
I0914 19:00:02.309327 140208644908864 controller.py:399] initialized model.
I0914 19:00:02.944512 140208644908864 api.py:447] Eval with scales ListWrapper([1.0])
I0914 19:00:03.824437 140208644908864 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0914 19:00:03.842844 140208644908864 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0914 19:00:06.788767 140208644908864 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0914 19:00:07.150467 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-0.
I0914 19:00:07.151063 140208644908864 controller.py:241] train | step:      0 | training until step 5000...
2022-09-14 19:00:26.844316: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8500
I0914 19:01:58.932881 140208644908864 controller.py:466] train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.100813,
     'losses/train_total_loss': 1.100813}
I0914 19:03:29.354763 140208644908864 controller.py:466] train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 0.97064584,
     'losses/train_total_loss': 0.97064584}
I0914 19:05:00.584602 140208644908864 controller.py:466] train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.91238976,
     'losses/train_total_loss': 0.91238976}
I0914 19:06:31.561504 140208644908864 controller.py:466] train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.90964407,
     'losses/train_total_loss': 0.90964407}
2022-09-14 19:07:49.284119: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1084128768 exceeds 10% of free system memory.
2022-09-14 19:07:49.284705: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1084128768 exceeds 10% of free system memory.
I0914 19:08:03.098684 140208644908864 controller.py:466] train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.88368344,
     'losses/train_total_loss': 0.88368344}
I0914 19:09:35.556177 140208644908864 controller.py:466] train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8417004,
     'losses/train_total_loss': 0.8417004}
I0914 19:11:07.603897 140208644908864 controller.py:466] train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.8187532,
     'losses/train_total_loss': 0.8187532}
I0914 19:12:39.699715 140208644908864 controller.py:466] train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.8209194,
     'losses/train_total_loss': 0.8209194}
2022-09-14 19:13:16.339782: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1084128768 exceeds 10% of free system memory.
2022-09-14 19:13:16.340166: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1084128768 exceeds 10% of free system memory.
I0914 19:14:11.024066 140208644908864 controller.py:466] train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.8139825,
     'losses/train_total_loss': 0.8139825}
I0914 19:15:42.413525 140208644908864 controller.py:466] train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.8003595,
     'losses/train_total_loss': 0.8003595}
I0914 19:15:43.195542 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-1000.
I0914 19:17:15.224027 140208644908864 controller.py:466] train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7587468,
     'losses/train_total_loss': 0.7587468}
2022-09-14 19:18:04.835913: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 1084128768 exceeds 10% of free system memory.
I0914 19:18:47.021372 140208644908864 controller.py:466] train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7526863,
     'losses/train_total_loss': 0.7526863}
I0914 19:20:18.791113 140208644908864 controller.py:466] train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.7754903,
     'losses/train_total_loss': 0.7754903}
I0914 19:21:49.959840 140208644908864 controller.py:466] train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7767878,
     'losses/train_total_loss': 0.7767878}
I0914 19:23:21.458818 140208644908864 controller.py:466] train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7605263,
     'losses/train_total_loss': 0.7605263}
I0914 19:24:53.709350 140208644908864 controller.py:466] train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.73379225,
     'losses/train_total_loss': 0.73379225}
I0914 19:26:25.668348 140208644908864 controller.py:466] train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.73922366,
     'losses/train_total_loss': 0.73922366}
I0914 19:27:57.247169 140208644908864 controller.py:466] train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.73893857,
     'losses/train_total_loss': 0.73893857}
I0914 19:29:29.084396 140208644908864 controller.py:466] train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.7477963,
     'losses/train_total_loss': 0.7477963}
I0914 19:31:01.128889 140208644908864 controller.py:466] train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.72332436,
     'losses/train_total_loss': 0.72332436}
I0914 19:31:01.947953 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-2000.
I0914 19:32:33.410952 140208644908864 controller.py:466] train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.70691293,
     'losses/train_total_loss': 0.70691293}
I0914 19:34:05.716440 140208644908864 controller.py:466] train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.69816107,
     'losses/train_total_loss': 0.69816107}
I0914 19:35:37.826206 140208644908864 controller.py:466] train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.7056642,
     'losses/train_total_loss': 0.7056642}
I0914 19:37:10.474273 140208644908864 controller.py:466] train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.72382575,
     'losses/train_total_loss': 0.72382575}
I0914 19:38:42.353865 140208644908864 controller.py:466] train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.7179905,
     'losses/train_total_loss': 0.7179905}
I0914 19:40:14.008479 140208644908864 controller.py:466] train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.6987188,
     'losses/train_total_loss': 0.6987188}
I0914 19:41:45.082134 140208644908864 controller.py:466] train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.711105,
     'losses/train_total_loss': 0.711105}
I0914 19:43:16.541055 140208644908864 controller.py:466] train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.71954066,
     'losses/train_total_loss': 0.71954066}
I0914 19:44:48.452025 140208644908864 controller.py:466] train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.68463975,
     'losses/train_total_loss': 0.68463975}
I0914 19:46:20.104533 140208644908864 controller.py:466] train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.68718874,
     'losses/train_total_loss': 0.68718874}
I0914 19:46:21.141160 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-3000.
I0914 19:47:52.635003 140208644908864 controller.py:466] train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.7036717,
     'losses/train_total_loss': 0.7036717}
I0914 19:49:25.143855 140208644908864 controller.py:466] train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.70708007,
     'losses/train_total_loss': 0.70708007}
I0914 19:50:56.620456 140208644908864 controller.py:466] train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.6788039,
     'losses/train_total_loss': 0.6788039}
I0914 19:52:28.440101 140208644908864 controller.py:466] train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.6987669,
     'losses/train_total_loss': 0.6987669}
I0914 19:54:00.628170 140208644908864 controller.py:466] train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.6811704,
     'losses/train_total_loss': 0.6811704}
I0914 19:55:32.660115 140208644908864 controller.py:466] train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6730098,
     'losses/train_total_loss': 0.6730098}
I0914 19:57:03.926205 140208644908864 controller.py:466] train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6567465,
     'losses/train_total_loss': 0.6567465}
I0914 19:58:35.585130 140208644908864 controller.py:466] train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.6929563,
     'losses/train_total_loss': 0.6929563}
I0914 20:00:08.346271 140208644908864 controller.py:466] train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.646489,
     'losses/train_total_loss': 0.646489}
I0914 20:01:39.910372 140208644908864 controller.py:466] train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.7180195,
     'losses/train_total_loss': 0.7180195}
I0914 20:01:40.705431 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-4000.
I0914 20:03:12.292398 140208644908864 controller.py:466] train | step:   4100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6718099,
     'losses/train_total_loss': 0.6718099}
I0914 20:04:44.954882 140208644908864 controller.py:466] train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.65285224,
     'losses/train_total_loss': 0.65285224}
I0914 20:06:17.665298 140208644908864 controller.py:466] train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.65605927,
     'losses/train_total_loss': 0.65605927}
I0914 20:07:49.660636 140208644908864 controller.py:466] train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.652796,
     'losses/train_total_loss': 0.652796}
I0914 20:09:21.203452 140208644908864 controller.py:466] train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.66154975,
     'losses/train_total_loss': 0.66154975}
restoring or initializing model...
initialized model.
saved checkpoint to results/exp_004/ckpt-0.
train | step:      0 | training until step 5000...
train | step:    100 | steps/sec:    0.9 | output: 
    {'learning_rate': 0.0004977494,
     'losses/train_semantic_loss': 1.100813,
     'losses/train_total_loss': 1.100813}
train | step:    200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004954978,
     'losses/train_semantic_loss': 0.97064584,
     'losses/train_total_loss': 0.97064584}
train | step:    300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004932449,
     'losses/train_semantic_loss': 0.91238976,
     'losses/train_total_loss': 0.91238976}
train | step:    400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00049099093,
     'losses/train_semantic_loss': 0.90964407,
     'losses/train_total_loss': 0.90964407}
train | step:    500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048873585,
     'losses/train_semantic_loss': 0.88368344,
     'losses/train_total_loss': 0.88368344}
train | step:    600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048647955,
     'losses/train_semantic_loss': 0.8417004,
     'losses/train_total_loss': 0.8417004}
train | step:    700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004842221,
     'losses/train_semantic_loss': 0.8187532,
     'losses/train_total_loss': 0.8187532}
train | step:    800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00048196348,
     'losses/train_semantic_loss': 0.8209194,
     'losses/train_total_loss': 0.8209194}
train | step:    900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047970368,
     'losses/train_semantic_loss': 0.8139825,
     'losses/train_total_loss': 0.8139825}
train | step:   1000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004774427,
     'losses/train_semantic_loss': 0.8003595,
     'losses/train_total_loss': 0.8003595}
saved checkpoint to results/exp_004/ckpt-1000.
train | step:   1100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00047518054,
     'losses/train_semantic_loss': 0.7587468,
     'losses/train_total_loss': 0.7587468}
train | step:   1200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004729172,
     'losses/train_semantic_loss': 0.7526863,
     'losses/train_total_loss': 0.7526863}
train | step:   1300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004706526,
     'losses/train_semantic_loss': 0.7754903,
     'losses/train_total_loss': 0.7754903}
train | step:   1400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046838683,
     'losses/train_semantic_loss': 0.7767878,
     'losses/train_total_loss': 0.7767878}
train | step:   1500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046611985,
     'losses/train_semantic_loss': 0.7605263,
     'losses/train_total_loss': 0.7605263}
train | step:   1600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004638516,
     'losses/train_semantic_loss': 0.73379225,
     'losses/train_total_loss': 0.73379225}
train | step:   1700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00046158218,
     'losses/train_semantic_loss': 0.73922366,
     'losses/train_total_loss': 0.73922366}
train | step:   1800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045931144,
     'losses/train_semantic_loss': 0.73893857,
     'losses/train_total_loss': 0.73893857}
train | step:   1900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004570395,
     'losses/train_semantic_loss': 0.7477963,
     'losses/train_total_loss': 0.7477963}
train | step:   2000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004547663,
     'losses/train_semantic_loss': 0.72332436,
     'losses/train_total_loss': 0.72332436}
saved checkpoint to results/exp_004/ckpt-2000.
train | step:   2100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045249183,
     'losses/train_semantic_loss': 0.70691293,
     'losses/train_total_loss': 0.70691293}
train | step:   2200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00045021612,
     'losses/train_semantic_loss': 0.69816107,
     'losses/train_total_loss': 0.69816107}
train | step:   2300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044793912,
     'losses/train_semantic_loss': 0.7056642,
     'losses/train_total_loss': 0.7056642}
train | step:   2400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044566081,
     'losses/train_semantic_loss': 0.72382575,
     'losses/train_total_loss': 0.72382575}
train | step:   2500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044338117,
     'losses/train_semantic_loss': 0.7179905,
     'losses/train_total_loss': 0.7179905}
train | step:   2600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00044110027,
     'losses/train_semantic_loss': 0.6987188,
     'losses/train_total_loss': 0.6987188}
train | step:   2700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043881807,
     'losses/train_semantic_loss': 0.711105,
     'losses/train_total_loss': 0.711105}
train | step:   2800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00043653455,
     'losses/train_semantic_loss': 0.71954066,
     'losses/train_total_loss': 0.71954066}
train | step:   2900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004342497,
     'losses/train_semantic_loss': 0.68463975,
     'losses/train_total_loss': 0.68463975}
train | step:   3000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004319635,
     'losses/train_semantic_loss': 0.68718874,
     'losses/train_total_loss': 0.68718874}
saved checkpoint to results/exp_004/ckpt-3000.
train | step:   3100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042967597,
     'losses/train_semantic_loss': 0.7036717,
     'losses/train_total_loss': 0.7036717}
train | step:   3200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042738707,
     'losses/train_semantic_loss': 0.70708007,
     'losses/train_total_loss': 0.70708007}
train | step:   3300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004250968,
     'losses/train_semantic_loss': 0.6788039,
     'losses/train_total_loss': 0.6788039}
train | step:   3400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042280517,
     'losses/train_semantic_loss': 0.6987669,
     'losses/train_total_loss': 0.6987669}
train | step:   3500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00042051217,
     'losses/train_semantic_loss': 0.6811704,
     'losses/train_total_loss': 0.6811704}
train | step:   3600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041821777,
     'losses/train_semantic_loss': 0.6730098,
     'losses/train_total_loss': 0.6730098}
train | step:   3700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041592194,
     'losses/train_semantic_loss': 0.6567465,
     'losses/train_total_loss': 0.6567465}
train | step:   3800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041362477,
     'losses/train_semantic_loss': 0.6929563,
     'losses/train_total_loss': 0.6929563}
train | step:   3900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00041132615,
     'losses/train_semantic_loss': 0.646489,
     'losses/train_total_loss': 0.646489}
train | step:   4000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040902608,
     'losses/train_semantic_loss': 0.7180195,
     'losses/train_total_loss': 0.7180195}
saved checkpoint to results/exp_004/ckpt-4000.
train | step:   4100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0004067246,
     'losses/train_semantic_loss': 0.6718099,
     'losses/train_total_loss': 0.6718099}
train | step:   4200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040442165,
     'losses/train_semantic_loss': 0.65285224,
     'losses/train_total_loss': 0.65285224}
train | step:   4300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00040211724,
     'losses/train_semantic_loss': 0.65605927,
     'losses/train_total_loss': 0.65605927}
train | step:   4400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039981137,
     'losses/train_semantic_loss': 0.652796,
     'losses/train_total_loss': 0.652796}
train | step:   4500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039750402,
     'losses/train_semantic_loss': 0.66154975,
     'losses/train_total_loss': 0.66154975}I0914 20:10:53.534483 140208644908864 controller.py:466] train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.658758,
     'losses/train_total_loss': 0.658758}
I0914 20:12:26.230384 140208644908864 controller.py:466] train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.6683167,
     'losses/train_total_loss': 0.6683167}
I0914 20:13:57.741146 140208644908864 controller.py:466] train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6625002,
     'losses/train_total_loss': 0.6625002}
I0914 20:15:29.904898 140208644908864 controller.py:466] train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.6409918,
     'losses/train_total_loss': 0.6409918}
I0914 20:17:01.347280 140208644908864 controller.py:466] train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6544434,
     'losses/train_total_loss': 0.6544434}
I0914 20:17:04.390890 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-5000.
I0914 20:17:04.391421 140208644908864 controller.py:282]  eval | step:   5000 | running complete evaluation...
I0914 20:17:05.102975 140208644908864 api.py:447] Eval with scales ListWrapper([1.0])
I0914 20:17:05.131702 140208644908864 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0914 20:17:05.156311 140208644908864 api.py:447] Eval scale 1.0; setting pooling size to [33, 33]
I0914 20:17:05.794140 140208644908864 api.py:447] Global average pooling in the ASPP pooling layer was replaced with tiled average pooling using the provided pool_size. Please make sure this behavior is intended.
I0914 20:17:38.498860 140208644908864 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0914 20:17:38.513626 140208644908864 controller.py:295]  eval | step:   5000 | eval time:   34.1 sec | output: 
    {'evaluation/iou/IoU': 0.600062,
     'losses/eval_semantic_loss': 0.7606784,
     'losses/eval_total_loss': 0.7606784}
I0914 20:17:38.517601 140208644908864 controller.py:241] train | step:   5000 | training until step 10000...
I0914 20:19:11.274762 140208644908864 controller.py:466] train | step:   5100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.6522596,
     'losses/train_total_loss': 0.6522596}
I0914 20:20:42.882683 140208644908864 controller.py:466] train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.64229536,
     'losses/train_total_loss': 0.64229536}
I0914 20:22:14.574697 140208644908864 controller.py:466] train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.62884575,
     'losses/train_total_loss': 0.62884575}
I0914 20:23:46.686795 140208644908864 controller.py:466] train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.63805956,
     'losses/train_total_loss': 0.63805956}
I0914 20:25:19.001023 140208644908864 controller.py:466] train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6346356,
     'losses/train_total_loss': 0.6346356}
I0914 20:26:50.415878 140208644908864 controller.py:466] train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6268677,
     'losses/train_total_loss': 0.6268677}
I0914 20:28:21.673715 140208644908864 controller.py:466] train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.62045306,
     'losses/train_total_loss': 0.62045306}
I0914 20:29:53.465084 140208644908864 controller.py:466] train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.63327587,
     'losses/train_total_loss': 0.63327587}
I0914 20:31:25.434673 140208644908864 controller.py:466] train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.6018521,
     'losses/train_total_loss': 0.6018521}
I0914 20:32:57.151847 140208644908864 controller.py:466] train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6280524,
     'losses/train_total_loss': 0.6280524}
I0914 20:32:58.026527 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-6000.
I0914 20:34:29.519053 140208644908864 controller.py:466] train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.5927427,
     'losses/train_total_loss': 0.5927427}
I0914 20:36:01.714073 140208644908864 controller.py:466] train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6167667,
     'losses/train_total_loss': 0.6167667}
I0914 20:37:32.807093 140208644908864 controller.py:466] train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.63819766,
     'losses/train_total_loss': 0.63819766}
I0914 20:39:04.876551 140208644908864 controller.py:466] train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6069447,
     'losses/train_total_loss': 0.6069447}
I0914 20:40:36.902647 140208644908864 controller.py:466] train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.6363153,
     'losses/train_total_loss': 0.6363153}
I0914 20:42:09.310494 140208644908864 controller.py:466] train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.63303673,
     'losses/train_total_loss': 0.63303673}
I0914 20:43:40.498797 140208644908864 controller.py:466] train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6101174,
     'losses/train_total_loss': 0.6101174}
I0914 20:45:12.125753 140208644908864 controller.py:466] train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.6315855,
     'losses/train_total_loss': 0.6315855}
I0914 20:46:44.125520 140208644908864 controller.py:466] train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.5926673,
     'losses/train_total_loss': 0.5926673}
I0914 20:48:15.640327 140208644908864 controller.py:466] train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.60360605,
     'losses/train_total_loss': 0.60360605}
I0914 20:48:16.847439 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-7000.
I0914 20:49:48.435000 140208644908864 controller.py:466] train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.6166068,
     'losses/train_total_loss': 0.6166068}
I0914 20:51:20.500597 140208644908864 controller.py:466] train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.61594754,
     'losses/train_total_loss': 0.61594754}
I0914 20:52:51.540856 140208644908864 controller.py:466] train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.5813129,
     'losses/train_total_loss': 0.5813129}
I0914 20:54:22.988495 140208644908864 controller.py:466] train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.6068959,
     'losses/train_total_loss': 0.6068959}
I0914 20:55:54.240462 140208644908864 controller.py:466] train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.60705495,
     'losses/train_total_loss': 0.60705495}
I0914 20:57:25.884222 140208644908864 controller.py:466] train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.61942714,
     'losses/train_total_loss': 0.61942714}
I0914 20:58:57.975890 140208644908864 controller.py:466] train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.61255014,
     'losses/train_total_loss': 0.61255014}
I0914 21:00:30.339050 140208644908864 controller.py:466] train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.59437567,
     'losses/train_total_loss': 0.59437567}
I0914 21:02:03.028467 140208644908864 controller.py:466] train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.5975163,
     'losses/train_total_loss': 0.5975163}
I0914 21:03:35.291754 140208644908864 controller.py:466] train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.5683067,
     'losses/train_total_loss': 0.5683067}
I0914 21:03:36.085912 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-8000.
I0914 21:05:07.285179 140208644908864 controller.py:466] train | step:   8100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.5833128,
     'losses/train_total_loss': 0.5833128}
I0914 21:06:38.962231 140208644908864 controller.py:466] train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.5806283,
     'losses/train_total_loss': 0.5806283}
I0914 21:08:10.903175 140208644908864 controller.py:466] train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.61282647,
     'losses/train_total_loss': 0.61282647}
I0914 21:09:43.116188 140208644908864 controller.py:466] train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.5707824,
     'losses/train_total_loss': 0.5707824}
I0914 21:11:14.742851 140208644908864 controller.py:466] train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.5704276,
     'losses/train_total_loss': 0.5704276}
I0914 21:12:45.564136 140208644908864 controller.py:466] train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.56044674,
     'losses/train_total_loss': 0.56044674}
I0914 21:14:17.152970 140208644908864 controller.py:466] train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.6233952,
     'losses/train_total_loss': 0.6233952}
I0914 21:15:49.361489 140208644908864 controller.py:466] train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.589594,
     'losses/train_total_loss': 0.589594}
I0914 21:17:21.152354 140208644908864 controller.py:466] train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.5806987,
     'losses/train_total_loss': 0.5806987}

train | step:   4600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003951952,
     'losses/train_semantic_loss': 0.658758,
     'losses/train_total_loss': 0.658758}
train | step:   4700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039288486,
     'losses/train_semantic_loss': 0.6683167,
     'losses/train_total_loss': 0.6683167}
train | step:   4800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00039057303,
     'losses/train_semantic_loss': 0.6625002,
     'losses/train_total_loss': 0.6625002}
train | step:   4900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003882597,
     'losses/train_semantic_loss': 0.6409918,
     'losses/train_total_loss': 0.6409918}
train | step:   5000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038594473,
     'losses/train_semantic_loss': 0.6544434,
     'losses/train_total_loss': 0.6544434}
saved checkpoint to results/exp_004/ckpt-5000.
 eval | step:   5000 | running complete evaluation...
 eval | step:   5000 | eval time:   34.1 sec | output: 
    {'evaluation/iou/IoU': 0.600062,
     'losses/eval_semantic_loss': 0.7606784,
     'losses/eval_total_loss': 0.7606784}
train | step:   5000 | training until step 10000...
train | step:   5100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00038362833,
     'losses/train_semantic_loss': 0.6522596,
     'losses/train_total_loss': 0.6522596}
train | step:   5200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00038131032,
     'losses/train_semantic_loss': 0.64229536,
     'losses/train_total_loss': 0.64229536}
train | step:   5300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037899075,
     'losses/train_semantic_loss': 0.62884575,
     'losses/train_total_loss': 0.62884575}
train | step:   5400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037666963,
     'losses/train_semantic_loss': 0.63805956,
     'losses/train_total_loss': 0.63805956}
train | step:   5500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003743469,
     'losses/train_semantic_loss': 0.6346356,
     'losses/train_total_loss': 0.6346356}
train | step:   5600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00037202256,
     'losses/train_semantic_loss': 0.6268677,
     'losses/train_total_loss': 0.6268677}
train | step:   5700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036969662,
     'losses/train_semantic_loss': 0.62045306,
     'losses/train_total_loss': 0.62045306}
train | step:   5800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036736907,
     'losses/train_semantic_loss': 0.63327587,
     'losses/train_total_loss': 0.63327587}
train | step:   5900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003650398,
     'losses/train_semantic_loss': 0.6018521,
     'losses/train_total_loss': 0.6018521}
train | step:   6000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00036270893,
     'losses/train_semantic_loss': 0.6280524,
     'losses/train_total_loss': 0.6280524}
saved checkpoint to results/exp_004/ckpt-6000.
train | step:   6100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003603764,
     'losses/train_semantic_loss': 0.5927427,
     'losses/train_total_loss': 0.5927427}
train | step:   6200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035804222,
     'losses/train_semantic_loss': 0.6167667,
     'losses/train_total_loss': 0.6167667}
train | step:   6300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035570626,
     'losses/train_semantic_loss': 0.63819766,
     'losses/train_total_loss': 0.63819766}
train | step:   6400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003533687,
     'losses/train_semantic_loss': 0.6069447,
     'losses/train_total_loss': 0.6069447}
train | step:   6500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00035102933,
     'losses/train_semantic_loss': 0.6363153,
     'losses/train_total_loss': 0.6363153}
train | step:   6600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034868822,
     'losses/train_semantic_loss': 0.63303673,
     'losses/train_total_loss': 0.63303673}
train | step:   6700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034634545,
     'losses/train_semantic_loss': 0.6101174,
     'losses/train_total_loss': 0.6101174}
train | step:   6800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00034400087,
     'losses/train_semantic_loss': 0.6315855,
     'losses/train_total_loss': 0.6315855}
train | step:   6900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003416545,
     'losses/train_semantic_loss': 0.5926673,
     'losses/train_total_loss': 0.5926673}
train | step:   7000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033930637,
     'losses/train_semantic_loss': 0.60360605,
     'losses/train_total_loss': 0.60360605}
saved checkpoint to results/exp_004/ckpt-7000.
train | step:   7100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033695647,
     'losses/train_semantic_loss': 0.6166068,
     'losses/train_total_loss': 0.6166068}
train | step:   7200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033460467,
     'losses/train_semantic_loss': 0.61594754,
     'losses/train_total_loss': 0.61594754}
train | step:   7300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00033225105,
     'losses/train_semantic_loss': 0.5813129,
     'losses/train_total_loss': 0.5813129}
train | step:   7400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003298956,
     'losses/train_semantic_loss': 0.6068959,
     'losses/train_total_loss': 0.6068959}
train | step:   7500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032753826,
     'losses/train_semantic_loss': 0.60705495,
     'losses/train_total_loss': 0.60705495}
train | step:   7600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032517905,
     'losses/train_semantic_loss': 0.61942714,
     'losses/train_total_loss': 0.61942714}
train | step:   7700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003228179,
     'losses/train_semantic_loss': 0.61255014,
     'losses/train_total_loss': 0.61255014}
train | step:   7800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00032045488,
     'losses/train_semantic_loss': 0.59437567,
     'losses/train_total_loss': 0.59437567}
train | step:   7900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031808988,
     'losses/train_semantic_loss': 0.5975163,
     'losses/train_total_loss': 0.5975163}
train | step:   8000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031572295,
     'losses/train_semantic_loss': 0.5683067,
     'losses/train_total_loss': 0.5683067}
saved checkpoint to results/exp_004/ckpt-8000.
train | step:   8100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031335407,
     'losses/train_semantic_loss': 0.5833128,
     'losses/train_total_loss': 0.5833128}
train | step:   8200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00031098313,
     'losses/train_semantic_loss': 0.5806283,
     'losses/train_total_loss': 0.5806283}
train | step:   8300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003086102,
     'losses/train_semantic_loss': 0.61282647,
     'losses/train_total_loss': 0.61282647}
train | step:   8400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003062353,
     'losses/train_semantic_loss': 0.5707824,
     'losses/train_total_loss': 0.5707824}
train | step:   8500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0003038583,
     'losses/train_semantic_loss': 0.5704276,
     'losses/train_total_loss': 0.5704276}
train | step:   8600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00030147925,
     'losses/train_semantic_loss': 0.56044674,
     'losses/train_total_loss': 0.56044674}
train | step:   8700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002990981,
     'losses/train_semantic_loss': 0.6233952,
     'losses/train_total_loss': 0.6233952}
train | step:   8800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00029671483,
     'losses/train_semantic_loss': 0.589594,
     'losses/train_total_loss': 0.589594}
train | step:   8900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00029432945,
     'losses/train_semantic_loss': 0.5806987,
     'losses/train_total_loss': 0.5806987}I0914 21:18:52.333249 140208644908864 controller.py:466] train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5805769,
     'losses/train_total_loss': 0.5805769}
I0914 21:18:53.151128 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-9000.
I0914 21:20:25.240971 140208644908864 controller.py:466] train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.57588315,
     'losses/train_total_loss': 0.57588315}
I0914 21:21:57.442537 140208644908864 controller.py:466] train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.57817346,
     'losses/train_total_loss': 0.57817346}
I0914 21:23:29.905336 140208644908864 controller.py:466] train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.57630956,
     'losses/train_total_loss': 0.57630956}
I0914 21:25:02.081703 140208644908864 controller.py:466] train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.546108,
     'losses/train_total_loss': 0.546108}
I0914 21:26:33.106417 140208644908864 controller.py:466] train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.59907526,
     'losses/train_total_loss': 0.59907526}
I0914 21:28:04.343570 140208644908864 controller.py:466] train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.5274124,
     'losses/train_total_loss': 0.5274124}
I0914 21:29:35.917076 140208644908864 controller.py:466] train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.563431,
     'losses/train_total_loss': 0.563431}
I0914 21:31:07.609558 140208644908864 controller.py:466] train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.6062379,
     'losses/train_total_loss': 0.6062379}
I0914 21:32:39.614745 140208644908864 controller.py:466] train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.55074,
     'losses/train_total_loss': 0.55074}
I0914 21:34:11.081507 140208644908864 controller.py:466] train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.58098525,
     'losses/train_total_loss': 0.58098525}
I0914 21:34:11.844576 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-10000.
I0914 21:34:11.845528 140208644908864 controller.py:282]  eval | step:  10000 | running complete evaluation...
I0914 21:34:42.990514 140208644908864 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0914 21:34:43.006220 140208644908864 controller.py:295]  eval | step:  10000 | eval time:   31.2 sec | output: 
    {'evaluation/iou/IoU': 0.6982622,
     'losses/eval_semantic_loss': 0.55964667,
     'losses/eval_total_loss': 0.55964667}
I0914 21:34:43.011989 140208644908864 controller.py:241] train | step:  10000 | training until step 15000...
I0914 21:36:14.543485 140208644908864 controller.py:466] train | step:  10100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.54660684,
     'losses/train_total_loss': 0.54660684}
I0914 21:37:45.600588 140208644908864 controller.py:466] train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5406409,
     'losses/train_total_loss': 0.5406409}
I0914 21:39:17.495434 140208644908864 controller.py:466] train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.5519238,
     'losses/train_total_loss': 0.5519238}
I0914 21:40:49.496070 140208644908864 controller.py:466] train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5468097,
     'losses/train_total_loss': 0.5468097}
I0914 21:42:21.449952 140208644908864 controller.py:466] train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.5560253,
     'losses/train_total_loss': 0.5560253}
I0914 21:43:53.513619 140208644908864 controller.py:466] train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.5577515,
     'losses/train_total_loss': 0.5577515}
I0914 21:45:26.105121 140208644908864 controller.py:466] train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5424184,
     'losses/train_total_loss': 0.5424184}
I0914 21:46:57.036106 140208644908864 controller.py:466] train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.5464894,
     'losses/train_total_loss': 0.5464894}
I0914 21:48:29.349472 140208644908864 controller.py:466] train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5894665,
     'losses/train_total_loss': 0.5894665}
I0914 21:50:01.132547 140208644908864 controller.py:466] train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5267495,
     'losses/train_total_loss': 0.5267495}
I0914 21:50:02.076659 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-11000.
I0914 21:51:34.514923 140208644908864 controller.py:466] train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.5734141,
     'losses/train_total_loss': 0.5734141}
I0914 21:53:05.904146 140208644908864 controller.py:466] train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5447216,
     'losses/train_total_loss': 0.5447216}
I0914 21:54:38.563173 140208644908864 controller.py:466] train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.565834,
     'losses/train_total_loss': 0.565834}
I0914 21:56:11.495353 140208644908864 controller.py:466] train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.57183874,
     'losses/train_total_loss': 0.57183874}
I0914 21:57:43.213586 140208644908864 controller.py:466] train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5206628,
     'losses/train_total_loss': 0.5206628}
I0914 21:59:14.937354 140208644908864 controller.py:466] train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5493756,
     'losses/train_total_loss': 0.5493756}
I0914 22:00:46.926510 140208644908864 controller.py:466] train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5308736,
     'losses/train_total_loss': 0.5308736}
I0914 22:02:18.816326 140208644908864 controller.py:466] train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.5301795,
     'losses/train_total_loss': 0.5301795}
I0914 22:03:50.636820 140208644908864 controller.py:466] train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.56014097,
     'losses/train_total_loss': 0.56014097}
I0914 22:05:22.589955 140208644908864 controller.py:466] train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.5362753,
     'losses/train_total_loss': 0.5362753}
I0914 22:05:23.395123 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-12000.
I0914 22:06:55.405959 140208644908864 controller.py:466] train | step:  12100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.55490166,
     'losses/train_total_loss': 0.55490166}
I0914 22:08:26.976536 140208644908864 controller.py:466] train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.5272576,
     'losses/train_total_loss': 0.5272576}
I0914 22:09:58.676578 140208644908864 controller.py:466] train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.5288318,
     'losses/train_total_loss': 0.5288318}
I0914 22:11:31.026844 140208644908864 controller.py:466] train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.54145044,
     'losses/train_total_loss': 0.54145044}
I0914 22:13:03.192563 140208644908864 controller.py:466] train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.55278605,
     'losses/train_total_loss': 0.55278605}
I0914 22:14:35.965420 140208644908864 controller.py:466] train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.53055,
     'losses/train_total_loss': 0.53055}
I0914 22:16:07.450204 140208644908864 controller.py:466] train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.5372641,
     'losses/train_total_loss': 0.5372641}
I0914 22:17:39.682629 140208644908864 controller.py:466] train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.52966166,
     'losses/train_total_loss': 0.52966166}
I0914 22:19:11.882244 140208644908864 controller.py:466] train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5606164,
     'losses/train_total_loss': 0.5606164}
I0914 22:20:44.442035 140208644908864 controller.py:466] train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.56971854,
     'losses/train_total_loss': 0.56971854}
I0914 22:20:45.337800 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-13000.
I0914 22:22:17.783839 140208644908864 controller.py:466] train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.5157129,
     'losses/train_total_loss': 0.5157129}
I0914 22:23:49.976768 140208644908864 controller.py:466] train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.5058742,
     'losses/train_total_loss': 0.5058742}
I0914 22:25:21.832259 140208644908864 controller.py:466] train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.51956123,
     'losses/train_total_loss': 0.51956123}

train | step:   9000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002919419,
     'losses/train_semantic_loss': 0.5805769,
     'losses/train_total_loss': 0.5805769}
saved checkpoint to results/exp_004/ckpt-9000.
train | step:   9100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002895522,
     'losses/train_semantic_loss': 0.57588315,
     'losses/train_total_loss': 0.57588315}
train | step:   9200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028716028,
     'losses/train_semantic_loss': 0.57817346,
     'losses/train_total_loss': 0.57817346}
train | step:   9300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028476617,
     'losses/train_semantic_loss': 0.57630956,
     'losses/train_total_loss': 0.57630956}
train | step:   9400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00028236985,
     'losses/train_semantic_loss': 0.546108,
     'losses/train_total_loss': 0.546108}
train | step:   9500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002799712,
     'losses/train_semantic_loss': 0.59907526,
     'losses/train_total_loss': 0.59907526}
train | step:   9600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027757033,
     'losses/train_semantic_loss': 0.5274124,
     'losses/train_total_loss': 0.5274124}
train | step:   9700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027516708,
     'losses/train_semantic_loss': 0.563431,
     'losses/train_total_loss': 0.563431}
train | step:   9800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027276156,
     'losses/train_semantic_loss': 0.6062379,
     'losses/train_total_loss': 0.6062379}
train | step:   9900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00027035366,
     'losses/train_semantic_loss': 0.55074,
     'losses/train_total_loss': 0.55074}
train | step:  10000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002679434,
     'losses/train_semantic_loss': 0.58098525,
     'losses/train_total_loss': 0.58098525}
saved checkpoint to results/exp_004/ckpt-10000.
 eval | step:  10000 | running complete evaluation...
 eval | step:  10000 | eval time:   31.2 sec | output: 
    {'evaluation/iou/IoU': 0.6982622,
     'losses/eval_semantic_loss': 0.55964667,
     'losses/eval_total_loss': 0.55964667}
train | step:  10000 | training until step 15000...
train | step:  10100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.0002655307,
     'losses/train_semantic_loss': 0.54660684,
     'losses/train_total_loss': 0.54660684}
train | step:  10200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00026311554,
     'losses/train_semantic_loss': 0.5406409,
     'losses/train_total_loss': 0.5406409}
train | step:  10300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00026069794,
     'losses/train_semantic_loss': 0.5519238,
     'losses/train_total_loss': 0.5519238}
train | step:  10400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025827784,
     'losses/train_semantic_loss': 0.5468097,
     'losses/train_total_loss': 0.5468097}
train | step:  10500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002558552,
     'losses/train_semantic_loss': 0.5560253,
     'losses/train_total_loss': 0.5560253}
train | step:  10600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00025343004,
     'losses/train_semantic_loss': 0.5577515,
     'losses/train_total_loss': 0.5577515}
train | step:  10700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002510023,
     'losses/train_semantic_loss': 0.5424184,
     'losses/train_total_loss': 0.5424184}
train | step:  10800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024857192,
     'losses/train_semantic_loss': 0.5464894,
     'losses/train_total_loss': 0.5464894}
train | step:  10900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024613892,
     'losses/train_semantic_loss': 0.5894665,
     'losses/train_total_loss': 0.5894665}
train | step:  11000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024370321,
     'losses/train_semantic_loss': 0.5267495,
     'losses/train_total_loss': 0.5267495}
saved checkpoint to results/exp_004/ckpt-11000.
train | step:  11100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00024126485,
     'losses/train_semantic_loss': 0.5734141,
     'losses/train_total_loss': 0.5734141}
train | step:  11200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002388237,
     'losses/train_semantic_loss': 0.5447216,
     'losses/train_total_loss': 0.5447216}
train | step:  11300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023637981,
     'losses/train_semantic_loss': 0.565834,
     'losses/train_total_loss': 0.565834}
train | step:  11400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023393307,
     'losses/train_semantic_loss': 0.57183874,
     'losses/train_total_loss': 0.57183874}
train | step:  11500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00023148351,
     'losses/train_semantic_loss': 0.5206628,
     'losses/train_total_loss': 0.5206628}
train | step:  11600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022903107,
     'losses/train_semantic_loss': 0.5493756,
     'losses/train_total_loss': 0.5493756}
train | step:  11700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0002265757,
     'losses/train_semantic_loss': 0.5308736,
     'losses/train_total_loss': 0.5308736}
train | step:  11800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022411738,
     'losses/train_semantic_loss': 0.5301795,
     'losses/train_total_loss': 0.5301795}
train | step:  11900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00022165602,
     'losses/train_semantic_loss': 0.56014097,
     'losses/train_total_loss': 0.56014097}
train | step:  12000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021919166,
     'losses/train_semantic_loss': 0.5362753,
     'losses/train_total_loss': 0.5362753}
saved checkpoint to results/exp_004/ckpt-12000.
train | step:  12100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021672418,
     'losses/train_semantic_loss': 0.55490166,
     'losses/train_total_loss': 0.55490166}
train | step:  12200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021425361,
     'losses/train_semantic_loss': 0.5272576,
     'losses/train_total_loss': 0.5272576}
train | step:  12300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00021177987,
     'losses/train_semantic_loss': 0.5288318,
     'losses/train_total_loss': 0.5288318}
train | step:  12400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020930292,
     'losses/train_semantic_loss': 0.54145044,
     'losses/train_total_loss': 0.54145044}
train | step:  12500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020682267,
     'losses/train_semantic_loss': 0.55278605,
     'losses/train_total_loss': 0.55278605}
train | step:  12600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020433914,
     'losses/train_semantic_loss': 0.53055,
     'losses/train_total_loss': 0.53055}
train | step:  12700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00020185225,
     'losses/train_semantic_loss': 0.5372641,
     'losses/train_total_loss': 0.5372641}
train | step:  12800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019936197,
     'losses/train_semantic_loss': 0.52966166,
     'losses/train_total_loss': 0.52966166}
train | step:  12900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019686819,
     'losses/train_semantic_loss': 0.5606164,
     'losses/train_total_loss': 0.5606164}
train | step:  13000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019437094,
     'losses/train_semantic_loss': 0.56971854,
     'losses/train_total_loss': 0.56971854}
saved checkpoint to results/exp_004/ckpt-13000.
train | step:  13100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00019187007,
     'losses/train_semantic_loss': 0.5157129,
     'losses/train_total_loss': 0.5157129}
train | step:  13200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018936557,
     'losses/train_semantic_loss': 0.5058742,
     'losses/train_total_loss': 0.5058742}
train | step:  13300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018685742,
     'losses/train_semantic_loss': 0.51956123,
     'losses/train_total_loss': 0.51956123}I0914 22:26:53.659849 140208644908864 controller.py:466] train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.518172,
     'losses/train_total_loss': 0.518172}
I0914 22:28:25.871083 140208644908864 controller.py:466] train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.5355677,
     'losses/train_total_loss': 0.5355677}
I0914 22:29:57.682779 140208644908864 controller.py:466] train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.52244776,
     'losses/train_total_loss': 0.52244776}
I0914 22:31:30.039863 140208644908864 controller.py:466] train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.5225195,
     'losses/train_total_loss': 0.5225195}
I0914 22:33:02.140156 140208644908864 controller.py:466] train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.50992846,
     'losses/train_total_loss': 0.50992846}
I0914 22:34:34.081217 140208644908864 controller.py:466] train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.5258102,
     'losses/train_total_loss': 0.5258102}
I0914 22:36:06.415277 140208644908864 controller.py:466] train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.5200048,
     'losses/train_total_loss': 0.5200048}
I0914 22:36:07.269627 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-14000.
I0914 22:37:39.614854 140208644908864 controller.py:466] train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.5151796,
     'losses/train_total_loss': 0.5151796}
I0914 22:39:11.477870 140208644908864 controller.py:466] train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.51107496,
     'losses/train_total_loss': 0.51107496}
I0914 22:40:43.487022 140208644908864 controller.py:466] train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.49501842,
     'losses/train_total_loss': 0.49501842}
I0914 22:42:15.180882 140208644908864 controller.py:466] train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.5471812,
     'losses/train_total_loss': 0.5471812}
I0914 22:43:46.389243 140208644908864 controller.py:466] train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.540694,
     'losses/train_total_loss': 0.540694}
I0914 22:45:18.116420 140208644908864 controller.py:466] train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.50705403,
     'losses/train_total_loss': 0.50705403}
I0914 22:46:49.835312 140208644908864 controller.py:466] train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.50907683,
     'losses/train_total_loss': 0.50907683}
I0914 22:48:21.952777 140208644908864 controller.py:466] train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.5093596,
     'losses/train_total_loss': 0.5093596}
I0914 22:49:54.513739 140208644908864 controller.py:466] train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5271994,
     'losses/train_total_loss': 0.5271994}
I0914 22:51:26.806174 140208644908864 controller.py:466] train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.539373,
     'losses/train_total_loss': 0.539373}
I0914 22:51:28.007069 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-15000.
I0914 22:51:28.007991 140208644908864 controller.py:282]  eval | step:  15000 | running complete evaluation...
I0914 22:51:59.128893 140208644908864 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0914 22:51:59.133428 140208644908864 controller.py:295]  eval | step:  15000 | eval time:   31.1 sec | output: 
    {'evaluation/iou/IoU': 0.73093975,
     'losses/eval_semantic_loss': 0.45749462,
     'losses/eval_total_loss': 0.45749462}
I0914 22:51:59.139369 140208644908864 controller.py:241] train | step:  15000 | training until step 20000...
I0914 22:53:31.632611 140208644908864 controller.py:466] train | step:  15100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.5178395,
     'losses/train_total_loss': 0.5178395}
I0914 22:55:03.878824 140208644908864 controller.py:466] train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.49246785,
     'losses/train_total_loss': 0.49246785}
I0914 22:56:35.756241 140208644908864 controller.py:466] train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.49468875,
     'losses/train_total_loss': 0.49468875}
I0914 22:58:08.009282 140208644908864 controller.py:466] train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.50991976,
     'losses/train_total_loss': 0.50991976}
I0914 22:59:40.752104 140208644908864 controller.py:466] train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.51995474,
     'losses/train_total_loss': 0.51995474}
I0914 23:01:13.294147 140208644908864 controller.py:466] train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.48879692,
     'losses/train_total_loss': 0.48879692}
I0914 23:02:44.880191 140208644908864 controller.py:466] train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.540954,
     'losses/train_total_loss': 0.540954}
I0914 23:04:17.592012 140208644908864 controller.py:466] train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.5204768,
     'losses/train_total_loss': 0.5204768}
I0914 23:05:50.372460 140208644908864 controller.py:466] train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.49348858,
     'losses/train_total_loss': 0.49348858}
I0914 23:07:22.522257 140208644908864 controller.py:466] train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.4716842,
     'losses/train_total_loss': 0.4716842}
I0914 23:07:23.491626 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-16000.
I0914 23:08:55.166562 140208644908864 controller.py:466] train | step:  16100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.51538336,
     'losses/train_total_loss': 0.51538336}
I0914 23:10:26.157836 140208644908864 controller.py:466] train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.5004225,
     'losses/train_total_loss': 0.5004225}
I0914 23:11:58.181605 140208644908864 controller.py:466] train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.4719736,
     'losses/train_total_loss': 0.4719736}
I0914 23:13:30.390523 140208644908864 controller.py:466] train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.49297833,
     'losses/train_total_loss': 0.49297833}
I0914 23:15:01.792577 140208644908864 controller.py:466] train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5142849,
     'losses/train_total_loss': 0.5142849}
I0914 23:16:33.707627 140208644908864 controller.py:466] train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.4975797,
     'losses/train_total_loss': 0.4975797}
I0914 23:18:05.516051 140208644908864 controller.py:466] train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.48860452,
     'losses/train_total_loss': 0.48860452}
I0914 23:19:36.881160 140208644908864 controller.py:466] train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.486051,
     'losses/train_total_loss': 0.486051}
I0914 23:21:08.920959 140208644908864 controller.py:466] train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.47802112,
     'losses/train_total_loss': 0.47802112}
I0914 23:22:41.211011 140208644908864 controller.py:466] train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.49691585,
     'losses/train_total_loss': 0.49691585}
I0914 23:22:41.924481 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-17000.
I0914 23:24:14.056711 140208644908864 controller.py:466] train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.49980986,
     'losses/train_total_loss': 0.49980986}
I0914 23:25:46.249574 140208644908864 controller.py:466] train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.49699375,
     'losses/train_total_loss': 0.49699375}
I0914 23:27:18.178905 140208644908864 controller.py:466] train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.48305753,
     'losses/train_total_loss': 0.48305753}
I0914 23:28:50.035287 140208644908864 controller.py:466] train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.47641358,
     'losses/train_total_loss': 0.47641358}
I0914 23:30:22.203514 140208644908864 controller.py:466] train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.4960297,
     'losses/train_total_loss': 0.4960297}
I0914 23:31:53.270735 140208644908864 controller.py:466] train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.49013433,
     'losses/train_total_loss': 0.49013433}
I0914 23:33:25.263493 140208644908864 controller.py:466] train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.50430644,
     'losses/train_total_loss': 0.50430644}

train | step:  13400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018434551,
     'losses/train_semantic_loss': 0.518172,
     'losses/train_total_loss': 0.518172}
train | step:  13500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00018182979,
     'losses/train_semantic_loss': 0.5355677,
     'losses/train_total_loss': 0.5355677}
train | step:  13600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001793102,
     'losses/train_semantic_loss': 0.52244776,
     'losses/train_total_loss': 0.52244776}
train | step:  13700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017678666,
     'losses/train_semantic_loss': 0.5225195,
     'losses/train_total_loss': 0.5225195}
train | step:  13800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00017425913,
     'losses/train_semantic_loss': 0.50992846,
     'losses/train_total_loss': 0.50992846}
train | step:  13900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001717275,
     'losses/train_semantic_loss': 0.5258102,
     'losses/train_total_loss': 0.5258102}
train | step:  14000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016919174,
     'losses/train_semantic_loss': 0.5200048,
     'losses/train_total_loss': 0.5200048}
saved checkpoint to results/exp_004/ckpt-14000.
train | step:  14100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016665173,
     'losses/train_semantic_loss': 0.5151796,
     'losses/train_total_loss': 0.5151796}
train | step:  14200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016410745,
     'losses/train_semantic_loss': 0.51107496,
     'losses/train_total_loss': 0.51107496}
train | step:  14300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00016155874,
     'losses/train_semantic_loss': 0.49501842,
     'losses/train_total_loss': 0.49501842}
train | step:  14400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015900553,
     'losses/train_semantic_loss': 0.5471812,
     'losses/train_total_loss': 0.5471812}
train | step:  14500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015644779,
     'losses/train_semantic_loss': 0.540694,
     'losses/train_total_loss': 0.540694}
train | step:  14600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015388538,
     'losses/train_semantic_loss': 0.50705403,
     'losses/train_total_loss': 0.50705403}
train | step:  14700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00015131824,
     'losses/train_semantic_loss': 0.50907683,
     'losses/train_total_loss': 0.50907683}
train | step:  14800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014874624,
     'losses/train_semantic_loss': 0.5093596,
     'losses/train_total_loss': 0.5093596}
train | step:  14900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001461693,
     'losses/train_semantic_loss': 0.5271994,
     'losses/train_total_loss': 0.5271994}
train | step:  15000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00014358731,
     'losses/train_semantic_loss': 0.539373,
     'losses/train_total_loss': 0.539373}
saved checkpoint to results/exp_004/ckpt-15000.
 eval | step:  15000 | running complete evaluation...
 eval | step:  15000 | eval time:   31.1 sec | output: 
    {'evaluation/iou/IoU': 0.73093975,
     'losses/eval_semantic_loss': 0.45749462,
     'losses/eval_total_loss': 0.45749462}
train | step:  15000 | training until step 20000...
train | step:  15100 | steps/sec:    0.8 | output: 
    {'learning_rate': 0.00014100014,
     'losses/train_semantic_loss': 0.5178395,
     'losses/train_total_loss': 0.5178395}
train | step:  15200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013840769,
     'losses/train_semantic_loss': 0.49246785,
     'losses/train_total_loss': 0.49246785}
train | step:  15300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013580981,
     'losses/train_semantic_loss': 0.49468875,
     'losses/train_total_loss': 0.49468875}
train | step:  15400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001332064,
     'losses/train_semantic_loss': 0.50991976,
     'losses/train_total_loss': 0.50991976}
train | step:  15500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00013059736,
     'losses/train_semantic_loss': 0.51995474,
     'losses/train_total_loss': 0.51995474}
train | step:  15600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012798246,
     'losses/train_semantic_loss': 0.48879692,
     'losses/train_total_loss': 0.48879692}
train | step:  15700 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012536162,
     'losses/train_semantic_loss': 0.540954,
     'losses/train_total_loss': 0.540954}
train | step:  15800 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001227347,
     'losses/train_semantic_loss': 0.5204768,
     'losses/train_total_loss': 0.5204768}
train | step:  15900 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00012010152,
     'losses/train_semantic_loss': 0.49348858,
     'losses/train_total_loss': 0.49348858}
train | step:  16000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011746189,
     'losses/train_semantic_loss': 0.4716842,
     'losses/train_total_loss': 0.4716842}
saved checkpoint to results/exp_004/ckpt-16000.
train | step:  16100 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.000114815666,
     'losses/train_semantic_loss': 0.51538336,
     'losses/train_total_loss': 0.51538336}
train | step:  16200 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00011216264,
     'losses/train_semantic_loss': 0.5004225,
     'losses/train_total_loss': 0.5004225}
train | step:  16300 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010950263,
     'losses/train_semantic_loss': 0.4719736,
     'losses/train_total_loss': 0.4719736}
train | step:  16400 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010683544,
     'losses/train_semantic_loss': 0.49297833,
     'losses/train_total_loss': 0.49297833}
train | step:  16500 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0001041608,
     'losses/train_semantic_loss': 0.5142849,
     'losses/train_total_loss': 0.5142849}
train | step:  16600 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.00010147853,
     'losses/train_semantic_loss': 0.4975797,
     'losses/train_total_loss': 0.4975797}
train | step:  16700 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.8788325e-05,
     'losses/train_semantic_loss': 0.48860452,
     'losses/train_total_loss': 0.48860452}
train | step:  16800 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.608998e-05,
     'losses/train_semantic_loss': 0.486051,
     'losses/train_total_loss': 0.486051}
train | step:  16900 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.338314e-05,
     'losses/train_semantic_loss': 0.47802112,
     'losses/train_total_loss': 0.47802112}
train | step:  17000 | steps/sec:    1.1 | output: 
    {'learning_rate': 9.066759e-05,
     'losses/train_semantic_loss': 0.49691585,
     'losses/train_total_loss': 0.49691585}
saved checkpoint to results/exp_004/ckpt-17000.
train | step:  17100 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.7942986e-05,
     'losses/train_semantic_loss': 0.49980986,
     'losses/train_total_loss': 0.49980986}
train | step:  17200 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.520896e-05,
     'losses/train_semantic_loss': 0.49699375,
     'losses/train_total_loss': 0.49699375}
train | step:  17300 | steps/sec:    1.1 | output: 
    {'learning_rate': 8.2465136e-05,
     'losses/train_semantic_loss': 0.48305753,
     'losses/train_total_loss': 0.48305753}
train | step:  17400 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.971114e-05,
     'losses/train_semantic_loss': 0.47641358,
     'losses/train_total_loss': 0.47641358}
train | step:  17500 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.694654e-05,
     'losses/train_semantic_loss': 0.4960297,
     'losses/train_total_loss': 0.4960297}
train | step:  17600 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.417084e-05,
     'losses/train_semantic_loss': 0.49013433,
     'losses/train_total_loss': 0.49013433}
train | step:  17700 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.138355e-05,
     'losses/train_semantic_loss': 0.50430644,
     'losses/train_total_loss': 0.50430644}I0914 23:34:57.620612 140208644908864 controller.py:466] train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.4897802,
     'losses/train_total_loss': 0.4897802}
I0914 23:36:28.865205 140208644908864 controller.py:466] train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.51265466,
     'losses/train_total_loss': 0.51265466}
I0914 23:38:01.017024 140208644908864 controller.py:466] train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.48192134,
     'losses/train_total_loss': 0.48192134}
I0914 23:38:01.707410 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-18000.
I0914 23:39:34.286590 140208644908864 controller.py:466] train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.49423745,
     'losses/train_total_loss': 0.49423745}
I0914 23:41:06.496687 140208644908864 controller.py:466] train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.48569444,
     'losses/train_total_loss': 0.48569444}
I0914 23:42:38.586879 140208644908864 controller.py:466] train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.46774617,
     'losses/train_total_loss': 0.46774617}
I0914 23:44:11.195786 140208644908864 controller.py:466] train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.49200055,
     'losses/train_total_loss': 0.49200055}
I0914 23:45:43.108826 140208644908864 controller.py:466] train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.47332612,
     'losses/train_total_loss': 0.47332612}
I0914 23:47:15.089234 140208644908864 controller.py:466] train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.47911793,
     'losses/train_total_loss': 0.47911793}
I0914 23:48:46.516671 140208644908864 controller.py:466] train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.478764,
     'losses/train_total_loss': 0.478764}
I0914 23:50:18.373241 140208644908864 controller.py:466] train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.51653016,
     'losses/train_total_loss': 0.51653016}
I0914 23:51:50.032046 140208644908864 controller.py:466] train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.4824997,
     'losses/train_total_loss': 0.4824997}
I0914 23:53:21.782685 140208644908864 controller.py:466] train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.4776798,
     'losses/train_total_loss': 0.4776798}
I0914 23:53:22.509295 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-19000.
I0914 23:54:55.130364 140208644908864 controller.py:466] train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.51794815,
     'losses/train_total_loss': 0.51794815}
I0914 23:56:26.522199 140208644908864 controller.py:466] train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.49690163,
     'losses/train_total_loss': 0.49690163}
I0914 23:57:58.416381 140208644908864 controller.py:466] train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.484805,
     'losses/train_total_loss': 0.484805}
I0914 23:59:30.039056 140208644908864 controller.py:466] train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.47171333,
     'losses/train_total_loss': 0.47171333}
I0915 00:01:01.910068 140208644908864 controller.py:466] train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.46940482,
     'losses/train_total_loss': 0.46940482}
I0915 00:02:34.100745 140208644908864 controller.py:466] train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.46309894,
     'losses/train_total_loss': 0.46309894}
I0915 00:04:06.276607 140208644908864 controller.py:466] train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.46892858,
     'losses/train_total_loss': 0.46892858}
I0915 00:05:38.983453 140208644908864 controller.py:466] train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.4646452,
     'losses/train_total_loss': 0.4646452}
I0915 00:07:11.092285 140208644908864 controller.py:466] train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.4485592,
     'losses/train_total_loss': 0.4485592}
I0915 00:08:43.138294 140208644908864 controller.py:466] train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.4762947,
     'losses/train_total_loss': 0.4762947}
I0915 00:08:43.815355 140208644908864 controller.py:495] saved checkpoint to results/exp_004/ckpt-20000.
I0915 00:08:43.815891 140208644908864 controller.py:282]  eval | step:  20000 | running complete evaluation...
I0915 00:09:14.019080 140208644908864 loop_fns.py:81] The dataset iterator is exhausted after 400 steps.
I0915 00:09:14.044301 140208644908864 controller.py:295]  eval | step:  20000 | eval time:   30.2 sec | output: 
    {'evaluation/iou/IoU': 0.745595,
     'losses/eval_semantic_loss': 0.41504547,
     'losses/eval_total_loss': 0.41504547}

train | step:  17800 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.858411e-05,
     'losses/train_semantic_loss': 0.4897802,
     'losses/train_total_loss': 0.4897802}
train | step:  17900 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.577192e-05,
     'losses/train_semantic_loss': 0.51265466,
     'losses/train_total_loss': 0.51265466}
train | step:  18000 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.29463e-05,
     'losses/train_semantic_loss': 0.48192134,
     'losses/train_total_loss': 0.48192134}
saved checkpoint to results/exp_004/ckpt-18000.
train | step:  18100 | steps/sec:    1.1 | output: 
    {'learning_rate': 6.0106497e-05,
     'losses/train_semantic_loss': 0.49423745,
     'losses/train_total_loss': 0.49423745}
train | step:  18200 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.7251673e-05,
     'losses/train_semantic_loss': 0.48569444,
     'losses/train_total_loss': 0.48569444}
train | step:  18300 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.4380973e-05,
     'losses/train_semantic_loss': 0.46774617,
     'losses/train_total_loss': 0.46774617}
train | step:  18400 | steps/sec:    1.1 | output: 
    {'learning_rate': 5.1493324e-05,
     'losses/train_semantic_loss': 0.49200055,
     'losses/train_total_loss': 0.49200055}
train | step:  18500 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.8587568e-05,
     'losses/train_semantic_loss': 0.47332612,
     'losses/train_total_loss': 0.47332612}
train | step:  18600 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.5662342e-05,
     'losses/train_semantic_loss': 0.47911793,
     'losses/train_total_loss': 0.47911793}
train | step:  18700 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2716143e-05,
     'losses/train_semantic_loss': 0.478764,
     'losses/train_total_loss': 0.478764}
train | step:  18800 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.9747174e-05,
     'losses/train_semantic_loss': 0.51653016,
     'losses/train_total_loss': 0.51653016}
train | step:  18900 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.6753318e-05,
     'losses/train_semantic_loss': 0.4824997,
     'losses/train_total_loss': 0.4824997}
train | step:  19000 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.373209e-05,
     'losses/train_semantic_loss': 0.4776798,
     'losses/train_total_loss': 0.4776798}
saved checkpoint to results/exp_004/ckpt-19000.
train | step:  19100 | steps/sec:    1.1 | output: 
    {'learning_rate': 3.068043e-05,
     'losses/train_semantic_loss': 0.51794815,
     'losses/train_total_loss': 0.51794815}
train | step:  19200 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.7594608e-05,
     'losses/train_semantic_loss': 0.49690163,
     'losses/train_total_loss': 0.49690163}
train | step:  19300 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.4469862e-05,
     'losses/train_semantic_loss': 0.484805,
     'losses/train_total_loss': 0.484805}
train | step:  19400 | steps/sec:    1.1 | output: 
    {'learning_rate': 2.1299958e-05,
     'losses/train_semantic_loss': 0.47171333,
     'losses/train_total_loss': 0.47171333}
train | step:  19500 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.8076556e-05,
     'losses/train_semantic_loss': 0.46940482,
     'losses/train_total_loss': 0.46940482}
train | step:  19600 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.4787565e-05,
     'losses/train_semantic_loss': 0.46309894,
     'losses/train_total_loss': 0.46309894}
train | step:  19700 | steps/sec:    1.1 | output: 
    {'learning_rate': 1.1414367e-05,
     'losses/train_semantic_loss': 0.46892858,
     'losses/train_total_loss': 0.46892858}
train | step:  19800 | steps/sec:    1.1 | output: 
    {'learning_rate': 7.924459e-06,
     'losses/train_semantic_loss': 0.4646452,
     'losses/train_total_loss': 0.4646452}
train | step:  19900 | steps/sec:    1.1 | output: 
    {'learning_rate': 4.2466136e-06,
     'losses/train_semantic_loss': 0.4485592,
     'losses/train_total_loss': 0.4485592}
train | step:  20000 | steps/sec:    1.1 | output: 
    {'learning_rate': 0.0,
     'losses/train_semantic_loss': 0.4762947,
     'losses/train_total_loss': 0.4762947}
saved checkpoint to results/exp_004/ckpt-20000.
 eval | step:  20000 | running complete evaluation...
 eval | step:  20000 | eval time:   30.2 sec | output: 
    {'evaluation/iou/IoU': 0.745595,
     'losses/eval_semantic_loss': 0.41504547,
     'losses/eval_total_loss': 0.41504547}
